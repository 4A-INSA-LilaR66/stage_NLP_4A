{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25573dac",
   "metadata": {
    "id": "25573dac"
   },
   "source": [
    "Notebook : BERT fine-tuning\n",
    "------------------------------------\n",
    "-------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f9ce72f",
   "metadata": {
    "id": "6f9ce72f"
   },
   "source": [
    "## 1.Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "WkeWoorE7FH7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WkeWoorE7FH7",
    "outputId": "5d1a8116-3974-44ad-d67c-be32ec32e495"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Requirement already satisfied: transformers==2.8.0 in /usr/local/lib/python3.7/dist-packages (2.8.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from transformers==2.8.0) (1.21.6)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==2.8.0) (4.64.0)\n",
      "Collecting tokenizers==0.5.2\n",
      "  Using cached tokenizers-0.5.2-cp37-cp37m-manylinux1_x86_64.whl (5.6 MB)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==2.8.0) (2.23.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==2.8.0) (2022.6.2)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==2.8.0) (3.8.0)\n",
      "Requirement already satisfied: boto3 in /usr/local/lib/python3.7/dist-packages (from transformers==2.8.0) (1.24.67)\n",
      "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (from transformers==2.8.0) (0.1.97)\n",
      "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers==2.8.0) (0.0.53)\n",
      "Requirement already satisfied: s3transfer<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from boto3->transformers==2.8.0) (0.6.0)\n",
      "Requirement already satisfied: botocore<1.28.0,>=1.27.67 in /usr/local/lib/python3.7/dist-packages (from boto3->transformers==2.8.0) (1.27.67)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from boto3->transformers==2.8.0) (1.0.1)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.28.0,>=1.27.67->boto3->transformers==2.8.0) (2.8.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /usr/local/lib/python3.7/dist-packages (from botocore<1.28.0,>=1.27.67->boto3->transformers==2.8.0) (1.25.11)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.28.0,>=1.27.67->boto3->transformers==2.8.0) (1.15.0)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==2.8.0) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==2.8.0) (2022.6.15)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==2.8.0) (2.10)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==2.8.0) (7.1.2)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==2.8.0) (1.1.0)\n",
      "Installing collected packages: tokenizers\n",
      "  Attempting uninstall: tokenizers\n",
      "    Found existing installation: tokenizers 0.12.1\n",
      "    Uninstalling tokenizers-0.12.1:\n",
      "      Successfully uninstalled tokenizers-0.12.1\n",
      "Successfully installed tokenizers-0.5.2\n",
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Requirement already satisfied: tokenizers in /usr/local/lib/python3.7/dist-packages (0.5.2)\n",
      "Collecting tokenizers\n",
      "  Using cached tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
      "Installing collected packages: tokenizers\n",
      "  Attempting uninstall: tokenizers\n",
      "    Found existing installation: tokenizers 0.5.2\n",
      "    Uninstalling tokenizers-0.5.2:\n",
      "      Successfully uninstalled tokenizers-0.5.2\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "transformers 2.8.0 requires tokenizers==0.5.2, but you have tokenizers 0.12.1 which is incompatible.\u001b[0m\n",
      "Successfully installed tokenizers-0.12.1\n"
     ]
    }
   ],
   "source": [
    "#install libraries\n",
    "#-------------------------------------------------\n",
    "!pip install transformers==2.8.0 #for training bert\n",
    "!pip install --upgrade tokenizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41125841",
   "metadata": {
    "id": "41125841"
   },
   "outputs": [],
   "source": [
    "#import libraries\n",
    "#-------------------------------------------------\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from sklearn.utils import shuffle #shuffle pandas dataframe\n",
    "\n",
    "#---- download/unzip datas\n",
    "import os\n",
    "import zipfile\n",
    "import tarfile\n",
    "\n",
    "#----- data cleaning\n",
    "import re #to find integers & floats in a string \n",
    "import string #for text cleaning\n",
    "from string import digits\n",
    "#import unidecode\n",
    "#from spellchecker import SpellChecker #spell checker\n",
    "\n",
    "#----- machine learning splitting datasets\n",
    "from sklearn.model_selection import train_test_split #split train/test data\n",
    "\n",
    "#----- for BERT fine-tuning\n",
    "#import tensorflow as tf\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler #DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from transformers import BertTokenizer, BertModel, BertConfig\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "\n",
    "import random\n",
    "import time\n",
    "\n",
    "#---- Do not display warnings of tokenization\n",
    "import logging \n",
    "logging.getLogger('transformers.tokenization_utils').disabled = True\n",
    "\n",
    "#----- evaluate the performance of the model\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "#---- load an already fine-tuned model for resume training\n",
    "import shutil\n",
    "#----- write in xlsx file\n",
    "import openpyxl\n",
    "from openpyxl import load_workbook\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "T_YJKJ_0oyUb",
   "metadata": {
    "id": "T_YJKJ_0oyUb"
   },
   "source": [
    "### List of global variables\n",
    "\n",
    "List of global variables used in this notebook, defined progressively throughout the notebook\n",
    "\n",
    "\n",
    "Variables for saving information: \n",
    "- MY_FOLDER_______________________2.1\n",
    "- PATH______________________________2.1\n",
    "- NAMES____________________________2.2\n",
    "- URLS______________________________2.2\n",
    "- DFs_______________________________2.2\n",
    "- MIX_______________________________2.4\n",
    "\n",
    "Variables to train the model:\n",
    "- NOW_______________________________2.5\n",
    "- MAX_LEN__________________________4.2\n",
    "- BERT_MODEL_NAME_______________4.1\n",
    "- BATCH_SIZE_______________________4.3 \n",
    "- NUM_LABELS______________________4.4.a\n",
    "- EPS________________________________4.4.c\n",
    "- LR__________________________________4.4.c\n",
    "- NUM_EPOCHS______________________4.5.a\n",
    "\n",
    "Variables to retrieve saved information: \n",
    "- RESUME \n",
    "- CKP_NAME\n",
    "- FULL_RUN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ve-RTpQp6Ac6",
   "metadata": {
    "id": "ve-RTpQp6Ac6"
   },
   "source": [
    "### Main documentation\n",
    "\n",
    "For this notebook, I adapted the code found here:\n",
    "\n",
    "https://skimai.com/fine-tuning-bert-for-sentiment-analysis/ \n",
    "\n",
    "http://mccormickml.com/2019/07/22/BERT-fine-tuning/#2-loading-cola-dataset \n",
    "\n",
    "https://towardsdatascience.com/how-to-apply-transformers-to-any-length-of-text-a5601410af7f\n",
    "\n",
    "if the last link doesn't work try: \n",
    "- https://arxiv.org/abs/1908.10063\n",
    "- https://github.com/jamescalam/transformers/blob/main/course/language_classification/03_long_text_sentiment.ipynb\n",
    "- https://github.com/jamescalam/transformers/blob/main/course/language_classification/04_window_method_in_pytorch.ipynb\n",
    "- https://www.udemy.com/course/nlp-with-transformers/?couponCode=JUN2022\n",
    "\n",
    "https://towardsdatascience.com/building-a-multi-label-text-classifier-using-bert-and-tensorflow-f188e0ecdc5d\n",
    "\n",
    "https://medium.com/analytics-vidhya/multi-label-text-classification-using-transformers-bert-93460838e62b\n",
    "\n",
    "https://colab.research.google.com/drive/1PHv-IRLPCtv7oTcIGbsgZHqrB5LPvB7S#scrollTo=i0yQnuSFsjDp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "014b3b30",
   "metadata": {
    "id": "014b3b30"
   },
   "source": [
    "## 2.Datasets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mDerXoXcykh0",
   "metadata": {
    "id": "mDerXoXcykh0"
   },
   "source": [
    "### 2.1. Working directory "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gmPLyApXvA9R",
   "metadata": {
    "id": "gmPLyApXvA9R"
   },
   "source": [
    "> To access the datasets for the first time: \n",
    "\n",
    "Go to the **Shared Drive** > **Dashborad project**  and find the folder **Notebook_dashboard_project**. \n",
    "\n",
    "Right click on the folder **Notebook_dashboard_project** > **Add Shorcut** and add the shorcut in **My Drive**. You can choose to put the shorcut in **My Drive** directly or in the folder of your choice which we will call **MY_FOLDER** \n",
    "\n",
    "If you chose a special folder, change the name of the variable `MY_FOLDER` in the cell below to match the name of your folder as follows: `/my_folder_name`. \n",
    "\n",
    "Run the cell below and allow access to your drive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4-bvzHACrzk-",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4-bvzHACrzk-",
    "outputId": "d2eb0346-6161-4945-8419-4f43dd5b6360"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
      "\n",
      "dataset_path: /content/drive/My Drive/Notebook_dashboard_project/1_RawDatasets\n",
      "\n",
      "Elements in the folder \"1_RawDatasets\":\n",
      "------------------------------------------\n",
      "'all_kindle_review .csv'\n",
      "'Amazon Kindle Book Review for Sentiment Analysis.zip'\n",
      " amazon_review_full_csv\n",
      " amazon_review_full_csv.tar.gz\n",
      " data.csv\n",
      "'Financial Sentiment Analysis.zip'\n",
      "'Generic Sentiment Multidomain Sentiment Dataset.zip'\n",
      "'IMDB dataset Sentiment analysis.zip'\n",
      " Laptop_Train_v2.csv\n",
      " Reddit_Data.csv\n",
      "'SemEval 2014 Task 4 AspectBasedSentimentAnalysis.zip'\n",
      " Train.csv\n",
      "'Twitter and Reddit Sentimental analysis Dataset.zip'\n"
     ]
    }
   ],
   "source": [
    "MY_FOLDER = \"\" \n",
    "\n",
    "#---- to upload datasets from your drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "#---- go to the \"1_RawDatasets\" folder\n",
    "PATH = '/content/drive/My Drive/' + \"Notebook_dashboard_project\" +  MY_FOLDER \n",
    "dataset_path = PATH + \"/1_RawDatasets\"\n",
    "os.chdir(dataset_path)\n",
    "#---- list all elements in the \"datasets\" folder\n",
    "print('\\ndataset_path:', dataset_path)\n",
    "print('\\nElements in the folder \"1_RawDatasets\":')\n",
    "print('------------------------------------------')\n",
    "!ls "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b2244a",
   "metadata": {
    "id": "d6b2244a"
   },
   "source": [
    "### 2.2. Download datasets\n",
    "\n",
    "Find below a list of possible datasets to use to fine-tune our model.\\\n",
    "We aim to produce as general a dataset as possible"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc9437f7",
   "metadata": {
    "id": "cc9437f7"
   },
   "source": [
    "<font color = \"red\">__Dataset 1:__  </font> <font color = \"blue\"> Amazon Kindle Book Review for Sentiment Analysis </font>\\\n",
    "Can find dataset here: https://www.kaggle.com/datasets/meetnagadia/amazon-kindle-book-review-for-sentiment-analysis\n",
    "\n",
    "__Desciption:__\n",
    "- <font color = \"red\"> 5-score </font> dataset of product reviews from Amazon Kindle Store category from May 1996 - July 2014. \n",
    "- Contains total of 982619 entries. \n",
    "- Each reviewer has at least 5 reviews and each product has at least 5 reviews in this dataset.\n",
    "- Columns: \n",
    "    - asin - ID of the product, like B000FA64PK\n",
    "    -helpful - helpfulness rating of the review - example: 2/3.\n",
    "    -overall - rating of the product.\n",
    "    -reviewText - text of the review (heading).\n",
    "    -reviewTime - time of the review (raw).\n",
    "    -reviewerID - ID of the reviewer, like A3SPTOKDG7WBLN\n",
    "    -reviewerName - name of the reviewer.\n",
    "    -summary - summary of the review (description).\n",
    "    -unixReviewTime - unix timestamp.\n",
    "- No NaN/missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "iTAzrHiwplX3",
   "metadata": {
    "id": "iTAzrHiwplX3"
   },
   "source": [
    "<font color = \"red\">__Dataset 2:__  </font><font color = \"blue\"> Amazon Review Full Score Dataset </font>\\\n",
    "Can find dataset here: https://drive.google.com/drive/folders/0Bz8a_Dbh9Qhbfll6bVpmNUtUcFdjYmF2SEpmZUZUcVNiMUw1TWN6RDV3a0JHT3kxLVhVR2M?resourcekey=0-TLwzfR2O-D2aPitmn5o9VQ \\\n",
    "Name of the file to download: <font color = \"blue\"> amazon_review_full_csv.tar.gz </font>\n",
    "\n",
    "__Description:__\n",
    "\n",
    "The Amazon reviews full score dataset consists of reviews from amazon collected over a period of 18 years. \n",
    "- the file *train.csv* constains 3,000,000 training samples labelled with a score from 1 to 5.\n",
    "- the file *test.csv* constains 650,000 training samples labelled with a score from 1 to 5.\n",
    "\n",
    "In each file, there are 3 columns, corresponding to  <font color = \"red\"> class index (1 to 5) </font>, review title and review text. \n",
    "\n",
    "The reviews are on products such as: \n",
    "*Books, Electronics, Movies and TV, CDs and Vinyl, Clothing, Shoes and Jewelry, Home and Kitchen, Kindle Store, \n",
    "Sports and Outdoors, Cell Phones and Accessories, Health and Personal Care, Toys and Games, Video Games, Tools and Home Improvement, Beauty, Apps for Android, Office Products, Pet Supplies, Automotive, Grocery and Gourmet Food, Baby, Musical Instruments and Instrument, \n",
    "Amazon Instant Video*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8d93db8",
   "metadata": {
    "id": "f8d93db8"
   },
   "source": [
    "<font color = \"red\">__Dataset 3:__  </font><font color = \"blue\"> SemEval 2014 Task 4 AspectBasedSentimentAnalysis </font>\\\n",
    "Can find dataset here: https://www.kaggle.com/datasets/charitarth/semeval-2014-task-4-aspectbasedsentimentanalysis\n",
    "\n",
    "__Description:__ \\\n",
    "Two domain-specific datasets for laptops and restaurants, consisting of over 6K sentences with fine-grained aspect-level human annotations have been provided for training.\n",
    "- Laptop reviews: This dataset consists of over 3K English sentences extracted from customer reviews of laptops. Experienced human annotators tagged the aspect terms of the sentences (Subtask 1) and their polarities (Subtask 2). This dataset will be used only for Subtasks 1 and 2. Part of this dataset will be reserved as test data. Labels are <font color = \"red\">positive, negative and neutral</font>.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3isoeC4eFpex",
   "metadata": {
    "id": "3isoeC4eFpex"
   },
   "source": [
    "<font color = \"red\">__Dataset 4:__  </font><font color = \"blue\"> Financial Sentiment Analysis</font>\\\n",
    "Can find dataset here: https://www.kaggle.com/datasets/sbhatti/financial-sentiment-analysis\n",
    "\n",
    "\n",
    "__Description:__\n",
    "\n",
    "The following data is intended for advancing financial sentiment analysis research. It's two datasets (FiQA, Financial PhraseBank) combined into one easy-to-use CSV file. It provides financial sentences with sentiment labels. The file contains 5842 texts labelled <font color = \"red\"> positive, negative, neutral </font>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "P9YsWl81seYJ",
   "metadata": {
    "id": "P9YsWl81seYJ"
   },
   "source": [
    "<font color = \"red\">__Dataset 5:__  </font><font color = \"blue\"> IMDB dataset Sentiment analysis </font>\\\n",
    "Can find dataset here: https://www.kaggle.com/datasets/columbine/imdb-dataset-sentiment-analysis-in-csv-format\n",
    "\n",
    "__Description:__\n",
    "\n",
    "The dataset has 40k training samples labelled as <font color = \"red\">1 & 0 </font> for positive & negative reviews.\n",
    "The dataset is comprised of tab-separated files with phrases from the Rotten Tomatoes dataset.\n",
    "Note : all the movie review are long sentence(most of them are longer than 200 words.)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Djo1mKYBFHrB",
   "metadata": {
    "id": "Djo1mKYBFHrB"
   },
   "source": [
    "__________\n",
    "<font color = \"red\">__Dataset:__  </font><font color = \"blue\"> Generic Sentiment Multidomain Sentiment Dataset </font>\\\n",
    "Can find dataset here: https://www.kaggle.com/datasets/akgeni/generic-sentiment-multidomain-sentiment-dataset\n",
    "\n",
    "\n",
    "__Description:__\n",
    "\n",
    "This datasets contains combined Mobile reviews, Twitter sentiment, Yelp review, Toxic reviews and few more to cover multiple domain of sentiment analysis.\n",
    "\n",
    "0->Negative \\\n",
    "1->Neutral \\\n",
    "2->Positive \\\n",
    "\n",
    "Train data size : 50k \\\n",
    "Test data size : 10k\n",
    "\n",
    "> <font color = \"red\">Problem: </font> This dataset is already a mix of several datasets. Maybe it woulb be better to do our own mix to be able to put exactly what we want inside.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51da8053",
   "metadata": {
    "id": "51da8053"
   },
   "source": [
    "<font color = \"red\">__Dataset:__  </font><font color = \"blue\"> Twitter and Reddit Sentimental analysis Dataset </font>\\\n",
    "Can find dataset here: https://www.kaggle.com/datasets/cosmos98/twitter-and-reddit-sentimental-analysis-dataset\n",
    "\n",
    "__Desciption:__ \\\n",
    "The first dataset consists of Tweets from Twitter with Sentimental Label and the other from Reddit which Consists of Comments with its Sentimental Label. \\\n",
    "These tweets and Comments Were Made on Narendra Modi and Other Leaders as well as Peoples Opinion Towards the Next Prime Minister of The Nation (In Context with General Elections Held In India - 2019).\\\n",
    "All the Tweets and Comments From twitter and Reddit are Cleaned using Pythons re and also NLP with a Sentimental Label to each ranging from -1 to 1: \n",
    "-  0 Indicating it is a Neutral Tweet/Comment\n",
    "- 2.1 Indicating a Postive Sentiment\n",
    "- 3.-1 Indicating a Negative Tweet/Comment\n",
    "\n",
    "Content\n",
    "- Twitter.csv Dataset has around 163K Tweets along with Sentiment Labels.\n",
    "- Reddit.csv Dataset has around 37K Comments along with its Sentimental Label\n",
    "- So Generally Each Dataset has two columns, the first column has the cleaned tweets and Comments and the Second one indicates its Sentimental Label \n",
    "\n",
    "> <font color = \"red\">Problem: </font> The problem with the Reddit dataset (I didn't look at the tweets) is that not all the texts are in the same language. The Reddit texts look like Tweets (very short sentences with no arugumentation, lots of insults and abbreviations...) which is perhaps not adapted to our problem. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5mv8TD5OEBLy",
   "metadata": {
    "id": "5mv8TD5OEBLy"
   },
   "source": [
    "<font color = \"red\">__Dataset:__  </font><font color = \"blue\"> Twitter Tweets Sentiment Dataset </font>\\\n",
    "Can find dataset here: https://www.kaggle.com/datasets/yasserh/twitter-tweets-sentiment-dataset?resource=download\n",
    "\n",
    "__Desciption:__ \\\n",
    "\n",
    "This dataset contains 3,000 000 tweets with their labelled sentiment: positive, negative, neutral.\n",
    "\n",
    "> <font color = \"red\">Problem: </font> The problem the tweets is that they are very short with no arugumentation, lots of insults and abbreviations... which is perhaps not adapted to our problem. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ap_ZChdmz4lL",
   "metadata": {
    "id": "ap_ZChdmz4lL"
   },
   "outputs": [],
   "source": [
    "def buildDataset(num_labels = 3):\n",
    "  \"\"\"\n",
    "  This function extracts the datasets used in BERT fine-tuning. \n",
    "  The datasets are different depending on the number of labels we want: \n",
    "  num_labels = 3 -> builds datasets for positive,neutral,negative labels\n",
    "  num_labels = 2 -> builds datasets for positive,negative labels\n",
    "  \"\"\"\n",
    "  print(\"Start of extraction in the case of {} labels...\".format(num_labels))\n",
    "  print(\"\")\n",
    "\n",
    "  ALL_NAMES = [] # list containing the names of each dataset\n",
    "  ALL_URLS  = [] # list containing the urls to dowload each dataset\n",
    "  DFs   = [] # list containing the complete dataframes of each dataset\n",
    "\n",
    "  # =======================================\n",
    "  # Fill dataset information \n",
    "  # =======================================\n",
    "  #********** CASE 3 LABELS **********\n",
    "  if num_labels == 3:\n",
    "    #----- instantiates information for datasets of format \".zip\"\n",
    "    ALL_NAMES.append (\"Amazon Kindle Book Review for Sentiment Analysis\")\n",
    "    ALL_URLS.append(\"https://www.kaggle.com/datasets/meetnagadia/amazon-kindle-book-review-for-sentiment-analysis\")\n",
    "\n",
    "    ALL_NAMES.append(\"SemEval 2014 Task 4 AspectBasedSentimentAnalysis\")\n",
    "    ALL_URLS.append(\"https://www.kaggle.com/datasets/charitarth/semeval-2014-task-4-aspectbasedsentimentanalysis\")\n",
    "\n",
    "    ALL_NAMES.append(\"Financial Sentiment Analysis\")\n",
    "    ALL_URLS.append(\"https://www.kaggle.com/datasets/sbhatti/financial-sentiment-analysis\")\n",
    "\n",
    "    #ALL_NAMES.append(\"Generic Sentiment Multidomain Sentiment Dataset\")\n",
    "    #ALL_URLS.append(\"https://www.kaggle.com/datasets/akgeni/generic-sentiment-multidomain-sentiment-dataset\")\n",
    "\n",
    "    #ALL_NAMES.append(\"Twitter and Reddit Sentimental analysis Dataset\")\n",
    "    #ALL_URLS.append(\" https://www.kaggle.com/datasets/cosmos98/twitter-and-reddit-sentimental-analysis-dataset\")\n",
    "\n",
    "    #ALL_NAMES.append(\"Twitter Tweets Sentiment Dataset\")\n",
    "    #ALL_URLS.append(\"https://www.kaggle.com/datasets/yasserh/twitter-tweets-sentiment-dataset?resource=download\")\n",
    "\n",
    "    #----- instantiates information for datasets of format \".tar.gz\"\n",
    "    ALL_NAMES.append(\"amazon_review_full_csv\")\n",
    "    ALL_URLS.append(\"https://drive.google.com/drive/folders/0Bz8a_Dbh9Qhbfll6bVpmNUtUcFdjYmF2SEpmZUZUcVNiMUw1TWN6RDV3a0JHT3kxLVhVR2M?resourcekey=0-TLwzfR2O-D2aPitmn5o9VQ\")\n",
    "\n",
    "    isZip = np.array([True]*3 + [False]) #indices if the file is in \".zip\" format \n",
    "    infos = [0]*3 #number of the file to extract in the folder\n",
    "\n",
    "  #********** CASE 2 LABELS **********\n",
    "  elif num_labels == 2:\n",
    "    #----- instantiates information for datasets of format \".zip\"\n",
    "    ALL_NAMES.append (\"Amazon Kindle Book Review for Sentiment Analysis\")\n",
    "    ALL_URLS.append(\"https://www.kaggle.com/datasets/meetnagadia/amazon-kindle-book-review-for-sentiment-analysis\")\n",
    "\n",
    "    ALL_NAMES.append(\"IMDB dataset Sentiment analysis\")\n",
    "    ALL_URLS.append(\"https://www.kaggle.com/datasets/columbine/imdb-dataset-sentiment-analysis-in-csv-format\")\n",
    "\n",
    "    #----- instantiates information for datasets of format \".tar.gz\"\n",
    "    ALL_NAMES.append(\"amazon_review_full_csv\")\n",
    "    ALL_URLS.append(\"https://drive.google.com/drive/folders/0Bz8a_Dbh9Qhbfll6bVpmNUtUcFdjYmF2SEpmZUZUcVNiMUw1TWN6RDV3a0JHT3kxLVhVR2M?resourcekey=0-TLwzfR2O-D2aPitmn5o9VQ\")\n",
    "\n",
    "    isZip = np.array([True]*2 + [False]) #indices if the file is in \".zip\" format\n",
    "    infos = [0,1] #number of the file to extract in the folder\n",
    "\n",
    "  # =======================================\n",
    "  # Extract datasets of format \".zip\" and put them into dataFrame\n",
    "  # =======================================\n",
    "  for i in range (len(ALL_NAMES)): # for each selected dataset\n",
    "\n",
    "    if isZip[i]: #format \".zip\"\n",
    "      #----- Extract the content of zip file named \"NAMES[i]\" in directory \"datasets\"\n",
    "      with zipfile.ZipFile(ALL_NAMES[i] + '.zip', 'r') as zipObj:\n",
    "        zipinfos = zipObj.infolist()\n",
    "        #zipObj.extractall(directory) #extract all directory\n",
    "        zipObj.extract(zipinfos[infos[i]].filename)\n",
    "\n",
    "      #----- Append new dataframe to dataframe list DFs\n",
    "      DFs.append(pd.read_csv(zipinfos[infos[i]].filename))\n",
    "\n",
    "  # =======================================\n",
    "  # Extract datasets of format \".tar.gz\" and put them into dataFrame\n",
    "  # =======================================\n",
    "  tar = tarfile.open(ALL_NAMES[np.where(isZip == False)[0][0]] + \".tar.gz\", \"r:gz\")\n",
    "  #tar.extractall() ### uncomment if this is the first extraction\n",
    "  os.chdir(tar.name[:-7])\n",
    "  DFs.append(pd.read_csv(\"train.csv\",header = None))\n",
    "  tar.close()\n",
    "  os.chdir(dataset_path)\n",
    "\n",
    "  totComment = 0 # number of comments in total\n",
    "  for i in range (len(ALL_NAMES)):\n",
    "    print(\"Shape of dataset {}: {} rows, {} columns\".format('\"'+ALL_NAMES[i]+'\"',DFs[i].shape[0],DFs[i].shape[1]))\n",
    "    totComment += DFs[i].shape[0]\n",
    "\n",
    "  print(\"\\nNumber of comments between all datasets:\", totComment)\n",
    "  print(\"\")\n",
    "  print(\"Extraction done!\")\n",
    "  return (DFs,ALL_NAMES,ALL_URLS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wIm6ZzjBvtHF",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wIm6ZzjBvtHF",
    "outputId": "853838e5-0a62-4ae6-bfd5-311222cd8dbd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start of extraction in the case of 3 labels...\n",
      "\n",
      "Shape of dataset \"Amazon Kindle Book Review for Sentiment Analysis\": 12000 rows, 11 columns\n",
      "Shape of dataset \"SemEval 2014 Task 4 AspectBasedSentimentAnalysis\": 2358 rows, 6 columns\n",
      "Shape of dataset \"Financial Sentiment Analysis\": 5842 rows, 2 columns\n",
      "Shape of dataset \"amazon_review_full_csv\": 3000000 rows, 3 columns\n",
      "\n",
      "Number of comments between all datasets: 3020200\n",
      "\n",
      "Extraction done!\n"
     ]
    }
   ],
   "source": [
    "DFs,ALL_NAMES,ALL_URLS = buildDataset(num_labels = 3)\n",
    "#DFs,ALL_NAMES,ALL_URLS = buildDataset(num_labels = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0fadfc4",
   "metadata": {
    "id": "d0fadfc4"
   },
   "source": [
    "### 2.3. Harmonize datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "130d2e9f",
   "metadata": {
    "id": "130d2e9f"
   },
   "outputs": [],
   "source": [
    "# =======================================\n",
    "# Harmonize the datasets for 3 labels\n",
    "# =======================================\n",
    "def harmonize_3labels(DFs):\n",
    "  \"\"\"\n",
    "  This function harmonizes datasets in the case of 3 labels (positive,neutral,negative)\n",
    "  \"\"\"\n",
    "  DFs_ = [] # list containing the harmonized dataframes initially stored in DFs\n",
    "\n",
    "  i = 0\n",
    "  #----------[ START harmonize dataframe\n",
    "  DFs_.append(DFs[i][[\"reviewText\",\"rating\"]].copy())\n",
    "  DFs_[i].rename(columns = {\"reviewText\": \"comments\", \"rating\": \"label\"},inplace = True)\n",
    "  #transforms ratings from 1 to 5 to: 0 -> negative, 1 -> neutral, 2 -> positive\n",
    "  DFs_[i][\"label\"].iloc[np.where(DFs_[i][\"label\"] <= 2)] = 0 #if rating <= 2 assign negative (value 0)\n",
    "  DFs_[i][\"label\"].iloc[np.where(DFs_[i][\"label\"] >= 4)] = 2  #if rating >= 4 assign positive (value 2)\n",
    "  DFs_[i][\"label\"].iloc[np.where(DFs_[i][\"label\"] == 3)] = 1  #if rating == 3 assign neutral (value 1)\n",
    "  ###I don't know why but the 3 above lines cerates a warning\n",
    "  i+= 1\n",
    "  #----------] END harmonize dataframe \n",
    "\n",
    "  #----------[ START harmonize dataframe\n",
    "  DFs_.append(DFs[i][[\"Sentence\",\"polarity\"]].copy())\n",
    "  DFs_[i].rename(columns = {\"Sentence\": \"comments\",\"polarity\": \"label\"},inplace = True)\n",
    "  #transforms ratings from positive,neutral,negative \n",
    "  DFs_[i][\"label\"].iloc[np.where(DFs_[i][\"label\"] == \"negative\")] = 0 #if rating = negative assign value 0\n",
    "  DFs_[i][\"label\"].iloc[np.where(DFs_[i][\"label\"] == \"positive\")] = 2 #if rating = positive assign value 2\n",
    "  DFs_[i][\"label\"].iloc[np.where(DFs_[i][\"label\"] == \"neutral\")] = 1 #if rating = neutral assign value 1\n",
    "  #drop rows with label \"conflict\"\n",
    "  rows = DFs_[i].iloc[np.where(DFs_[i][\"label\"]==\"conflict\")].index #row with label \"conflict\"\n",
    "  DFs_[i].drop(labels=rows,axis=0,inplace = True) #drop rows with label \"conflict\"\n",
    "\n",
    "  #In this df, a comment can have several labels depending on who marked the review.\n",
    "  #We therefore take the most common label. \n",
    "  comments = DFs_[i][\"comments\"].drop_duplicates().values #list contaning all the comments in one copy\n",
    "  labels = [] #final label associated to the comment\n",
    "  for c in comments: #loop trough all comments\n",
    "      idx = np.where(DFs_[i][\"comments\"] == c) #indexes where the comments = c\n",
    "      labels_c = list(DFs_[i][\"label\"].iloc[idx].values) #labels associated with comments c\n",
    "      labels.append(max(set(labels_c), key=labels_c.count)) #most common label for comment c\n",
    "      \n",
    "  df3new = pd.DataFrame(comments) #create dataframe with comments in one copy\n",
    "  df3new.rename(columns = {0:\"comments\"},inplace = True) \n",
    "  df3new [\"label\"] = labels #associate to each comments its most common label\n",
    "\n",
    "  DFs_[i] = df3new #update df\n",
    "  i+= 1\n",
    "  #----------] END harmonize dataframe\n",
    "\n",
    "  #----------[ START harmonize dataframe\n",
    "  DFs_.append(DFs[i][[\"Sentence\",\"Sentiment\"]].copy())\n",
    "  DFs_[i].rename(columns = {\"Sentence\": \"comments\",\"Sentiment\": \"label\"},inplace = True)\n",
    "  DFs_[i][\"label\"].iloc[np.where(DFs_[i][\"label\"] == \"negative\")] = 0 #if rating = negative assign value 0\n",
    "  DFs_[i][\"label\"].iloc[np.where(DFs_[i][\"label\"] == \"positive\")] = 2 #if rating = positive assign value 2\n",
    "  DFs_[i][\"label\"].iloc[np.where(DFs_[i][\"label\"] == \"neutral\")] = 1 #if rating = neutral assign value 1\n",
    "  i+= 1\n",
    "  #----------] END harmonize dataframe\n",
    "\n",
    "  #----------[ START harmonize dataframe\n",
    "  DFs_.append(DFs[i][[2,0]].copy())\n",
    "  DFs_[i].rename(columns = {2: \"comments\",0: \"label\"},inplace = True)\n",
    "  #transforms ratings from 1 to 5 to: 0 -> negative, 1 -> neutral, 2 -> positive\n",
    "  DFs_[i][\"label\"].iloc[np.where(DFs_[i][\"label\"] <= 2)] = 0 #if rating <= 2 assign negative (value 0)\n",
    "  DFs_[i][\"label\"].iloc[np.where(DFs_[i][\"label\"] >= 4)] = 2  #if rating >= 4 assign positive (value 2)\n",
    "  DFs_[i][\"label\"].iloc[np.where(DFs_[i][\"label\"] == 3)] = 1  #if rating == 3 assign neutral (value 1)\n",
    "  #----------] END harmonize dataframe\n",
    "  return DFs_\n",
    "\n",
    "# =======================================\n",
    "# Harmonize the datasets for 2 labels\n",
    "# =======================================\n",
    "def harmonize_2labels(DFs):\n",
    "  \"\"\"\n",
    "  This function harmonizes datasets in the case of 2 labels (positive,negative)\n",
    "  \"\"\"\n",
    "  DFs_ = [] # list containing the harmonized dataframes initially stored in DFs\n",
    "  i = 0\n",
    "\n",
    "  #----------[ START harmonize dataframe\n",
    "  DFs_.append(DFs[i][[\"reviewText\",\"rating\"]].copy())\n",
    "  DFs_[i].rename(columns = {\"reviewText\": \"comments\", \"rating\": \"label\"},inplace = True)\n",
    "  #transforms ratings from 1 to 5 to: 0 -> negative, 1 -> positive\n",
    "  DFs_[i][\"label\"].iloc[np.where(DFs_[i][\"label\"] <= 3)] = 0 #if rating <= 3 assign negative (value 0)\n",
    "  DFs_[i][\"label\"].iloc[np.where(DFs_[i][\"label\"] > 3 )] = 1  #if rating > 3 assign positive (value 1)\n",
    "  #After observing this dataset, I took 3 as negative since \n",
    "  #I want to detect the negative comments which are not always strong. \n",
    "  ###I don't know why but the 3 above lines cerates a warning\n",
    "  i+= 1\n",
    "  #----------] END harmonize dataframe\n",
    "\n",
    "  #----------[ START harmonize dataframe\n",
    "  DFs_.append(DFs[i][[\"text\",\"label\"]].copy())\n",
    "  DFs_[i].rename(columns = {\"text\": \"comments\"},inplace = True)\n",
    "  i+= 1\n",
    "  #----------] END harmonize dataframe\n",
    "\n",
    "  #----------[ START harmonize dataframe\n",
    "  DFs_.append(DFs[i][[2,0]].copy())\n",
    "  DFs_[i].rename(columns = {2: \"comments\",0: \"label\"},inplace = True)\n",
    "  #transforms ratings from 1 to 5 to: 0 -> negative, 1 -> positive\n",
    "  DFs_[i][\"label\"].iloc[np.where(DFs_[i][\"label\"] <= 3)] = 0 #if rating <= 3 assign negative (value 0)\n",
    "  DFs_[i][\"label\"].iloc[np.where(DFs_[i][\"label\"] > 3 )] = 1  #if rating > 3 assign positive (value 1)\n",
    "  #After observing this dataset, I took 3 as negative since \n",
    "  #I want to detect the negative comments which are not always strong. \n",
    "  #----------] END harmonize dataframe\n",
    "  return DFs_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "UaiHDIfmLQja",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UaiHDIfmLQja",
    "outputId": "cef96472-b5e9-473e-9088-b3cc8737501c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/pandas/core/indexing.py:1732: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_block(indexer, value, name)\n"
     ]
    }
   ],
   "source": [
    "DFs_ = harmonize_3labels(DFs)\n",
    "#DFs_ = harmonize_2labels(DFs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7uZOl89bo_Ly",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7uZOl89bo_Ly",
    "outputId": "3f989dfe-02b3-4a12-95fb-3b8ec55a5dfc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of dataset \"Amazon Kindle Book Review for Sentiment Analysis\" after harmonization: 12000 rows, 11 columns\n",
      "Shape of dataset \"SemEval 2014 Task 4 AspectBasedSentimentAnalysis\" after harmonization: 1456 rows, 6 columns\n",
      "Shape of dataset \"Financial Sentiment Analysis\" after harmonization: 5842 rows, 2 columns\n",
      "Shape of dataset \"amazon_review_full_csv\" after harmonization: 3000000 rows, 3 columns\n",
      "\n",
      "Number of comments between all datasets: 3019298\n"
     ]
    }
   ],
   "source": [
    "totComment = 0 # number of comments in total\n",
    "for i in range (len(ALL_NAMES)):\n",
    "  print(\"Shape of dataset {} after harmonization: {} rows, {} columns\".format('\"'+ALL_NAMES[i]+'\"',DFs_[i].shape[0],DFs[i].shape[1]))\n",
    "  totComment += DFs_[i].shape[0]\n",
    "\n",
    "print(\"\\nNumber of comments between all datasets:\", totComment)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4982e6da",
   "metadata": {
    "id": "4982e6da"
   },
   "source": [
    "### 2.4. Mix datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9769ad6e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9769ad6e",
    "outputId": "2e2e624f-58bd-4b26-859d-da5797747ba3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Select randomly 0 comments of dataset 0 wich represents 0.0 %.\n",
      "Select randomly 0 comments of dataset 1 wich represents 0.0 %.\n",
      "Select randomly 0 comments of dataset 2 wich represents 0.0 %.\n",
      "Select randomly 6000 comments of dataset 3 wich represents 0.2 %.\n",
      "\n",
      "Shape of the new dataset:  (6000, 2)\n",
      "\n",
      "MIX:  6000 comments of dataset df3 (0.2%)\n",
      "NAMES:  amazon_review_full_csv\n",
      "URLS:  https://drive.google.com/drive/folders/0Bz8a_Dbh9Qhbfll6bVpmNUtUcFdjYmF2SEpmZUZUcVNiMUw1TWN6RDV3a0JHT3kxLVhVR2M?resourcekey=0-TLwzfR2O-D2aPitmn5o9VQ\n"
     ]
    }
   ],
   "source": [
    "def computeMix(DFs_,percentage,per = [],num = []):\n",
    "  \"\"\"\n",
    "  This function creates a mix of different datasets by selecting a certain \n",
    "  percentage or number of rows of each datasets at random.\n",
    "  ---> input: \n",
    "  - DFs_ (list of dataframes): contains the different datasets for which we\n",
    "  will select rows at random. \n",
    "  - percentage (bool): indicates if we want to operate the selction by \n",
    "  percentage or by number of rows\n",
    "  - per (list of the same size as DFs_): list to specify percentage to \n",
    "  select from each dataset. \n",
    "  - num (list of the same size as DFs_): list to specify numbers of rows \n",
    "  to select from each dataset. \n",
    "  \"\"\"\n",
    "  DFs_samples = [] # list containing dataframes which are\n",
    "                   # random samples of dataframes stored in list DFs_\n",
    "  mix = []   # list of strings containing info about the realised mixed\n",
    "  names = [] # list containing the names of the datasets mixed \n",
    "  urls = []  # list containing the urls of the datasets mixed \n",
    "\n",
    "  #----- Random selection of per[i]% of each dataset\n",
    "  for i in range(len(DFs)):\n",
    "    # number of comments in each df:\n",
    "    nbComments = DFs_[i].shape[0]\n",
    "    \n",
    "    if percentage == True:\n",
    "      # sample each df according to per[i] value: \n",
    "      DFs_samples.append(DFs_[i].sample(n=int(nbComments*per[i]),axis='rows')) \n",
    "      current_per = str(per[i]*100) #percentage of the selected dataset\n",
    "      current_nbComm = str(int(nbComments*per[i])) #number of comments selected\n",
    "\n",
    "      # if per[i] != 0 update lists mix, names and urls:\n",
    "      if per[i] != 0:\n",
    "        mix.append(current_per+  \"% of dataset df\" + str(i) + \" (\" +  current_nbComm + \" comments)\")\n",
    "        names.append(ALL_NAMES[i])\n",
    "        urls.append(ALL_URLS[i])\n",
    "\n",
    "      # print final dataframes mix:\n",
    "      print(\"Select randomly {}% of dataset {} wich represents {} comments.\".format(current_per,i,current_nbComm))\n",
    "      \n",
    "    else:\n",
    "      # sample each df according to num[i] value: \n",
    "      DFs_samples.append(DFs_[i].sample(n=num[i],axis='rows')) \n",
    "      current_per = str(round(100*num[i]/nbComments,1)) #percentage of the selected dataset\n",
    "      current_nbComm = str(num[i]) #number of comments selected\n",
    "\n",
    "      # if num[i] != 0 update lists mix, names and urls:\n",
    "      if num[i] != 0:\n",
    "        mix.append(current_nbComm + \" comments of dataset df\" + str(i) + \" (\" + current_per + \"%)\")\n",
    "        names.append(ALL_NAMES[i])\n",
    "        urls.append(ALL_URLS[i])\n",
    "        \n",
    "      # print final dataframes mix:\n",
    "      print(\"Select randomly {} comments of dataset {} wich represents {} %.\".format(current_nbComm,i,current_per))\n",
    "\n",
    "  MIX   = \" + \".join(mix) \n",
    "  NAMES = \" + \".join(names)\n",
    "  URLS  = \" + \".join(urls)\n",
    "  #----- Concatenate all dataframes extracts\n",
    "  data = pd.concat(DFs_samples)\n",
    "  #----- Shuffle the rows of the concatenated dataframe and order row indexes\n",
    "  data = data.sample(frac=1).reset_index(drop=True)\n",
    "  #----- Assign correct type to variables\n",
    "  data[\"label\"]=pd.Categorical(data[\"label\"],ordered=False) \n",
    "  #----- Prints\n",
    "  print(\"\\nShape of the new dataset: \", data.shape)\n",
    "  print(\"\")\n",
    "  print(\"MIX: \" , MIX)\n",
    "  print(\"NAMES: \" , NAMES)\n",
    "  print(\"URLS: \" , URLS)\n",
    "  return data,MIX,NAMES,URLS\n",
    "\n",
    "data,MIX,NAMES,URLS = computeMix(DFs_,\n",
    "                                 percentage = False,\n",
    "                                 per = [],\n",
    "                                 num = [0000,0,0000,6000]\n",
    "                                 )\n",
    "\n",
    "# RUN PLAN 3 labels: \n",
    "# num = [2000,0,2000,2000] -> done\n",
    "# num = [4000,0,1000,1000] -> done\n",
    "# num = [1000,0,4000,1000] -> done \n",
    "# num = [1000,0,1000,4000] -> done \n",
    "# num = [6000,0,0000,0000] -> done \n",
    "# num = [0000,0,5842, 158] -> done\n",
    "# num = [0000,0,0000,6000] -> done\n",
    "\n",
    "# RUN PLAN 2 labels: \n",
    "# num = [2000,2000,2000] -> done\n",
    "# num = [4000,1000,1000] -> done\n",
    "# num = [1000,4000,1000] -> done\n",
    "# num = [1000,1000,4000] -> done\n",
    "# num = [6000,0000,0000] -> done\n",
    "# num = [0000,6000,0000] -> done\n",
    "# num = [0000,0000,6000] -> done\n",
    "\n",
    "# RUN PLAN to see influence of number of comments on miniLabel dataset:\n",
    "# -------- 3 labels --------   \n",
    "# We saw that the best resultas were obtained with only \n",
    "# \"amazon_review_full_csv\" mix for rule 1 and rule 2\n",
    "# num = [0000,0000,0000,18000] -> done\n",
    "# -------- 2 labels --------   \n",
    "# We saw that the bests resultas (in the top 3) were obtained with \n",
    "# a mixs of dataset and what stands out most for the 2 rules is \n",
    "# 1.\"amazon_review_full_csv\" and 2.\"IMDB dataset Sentiment analysis\"  \n",
    "# num = [0000,6000,12000] -> done"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "xrA_YXbHOHF_",
   "metadata": {
    "id": "xrA_YXbHOHF_"
   },
   "source": [
    "- Start with 5000 comments (on the same dataset or mixed samples) see results and then increase to 10000 comments to see if the BERT result change. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2jbwzQymcuNE",
   "metadata": {
    "id": "2jbwzQymcuNE"
   },
   "source": [
    "### 2.5. Clean datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ea4ecf",
   "metadata": {
    "id": "63ea4ecf"
   },
   "outputs": [],
   "source": [
    "def cleanTextLight(txt):\n",
    "    \"\"\"\n",
    "    This function cleans the input text. \n",
    "    \"\"\"\n",
    "    nbLinks = 0\n",
    "    \n",
    "    if (pd.isna(txt) == False): #if there is a text\n",
    "        txt = str(txt) #convert to string to avoid problems\n",
    "        if (re.search('[a-zA-Z]', txt) != None): #if there is at least a letter in the text\n",
    "            #----- Count and removes url links\n",
    "            nbLinks = len(re.findall(r'(https?://[^\\s]+)', txt)) #count the number of url links in the text\n",
    "            txt = re.sub(r'(https?://[^\\s]+)',' ', txt)#removes all url links\n",
    "            #----- Removes digits \n",
    "            txt = re.sub('\\w*\\d\\w*', '', txt) #remove any word with a digit in it\n",
    "            #----- Removes unknown characters (but do not remove punctuation)\n",
    "            txt = re.sub('[^A-Za-z0-9\\.!?\\']+', ' ', txt)\n",
    "            #removes any spectial characters but keeps letters, digits and the following punctuation: [.!?']\n",
    "            #----- Removes unwanted text\n",
    "            txt = re.sub('\\n', ' ', txt) #removes \\n characters\n",
    "            #txt = unidecode.unidecode(txt) #transforms character with accent into character without accent\n",
    "            txt = re.sub(' +', ' ', txt) #removes extra blank text\n",
    "    return txt,nbLinks\n",
    "\n",
    "f_cleanLight = lambda x: cleanTextLight(x)[0] #to apply cleanTextLight on the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "iCnCmGSSnXjN",
   "metadata": {
    "id": "iCnCmGSSnXjN"
   },
   "outputs": [],
   "source": [
    "data[\"comments\"] = data[\"comments\"].apply(f_cleanLight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vCBhsTlDWfcx",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "vCBhsTlDWfcx",
    "outputId": "c5b026ae-71d2-471d-d57c-eee8716d4cce"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-45b305b9-c3b4-4466-b462-2f11b165dcc9\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comments</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Great full sound for the price. No flats or sh...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>yea it's fun to play with and teaches alot abo...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>An excellent reference book on cape bulbs. A w...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I had read White Fang with my graders recently...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The description of this item totally omits the...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-45b305b9-c3b4-4466-b462-2f11b165dcc9')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-45b305b9-c3b4-4466-b462-2f11b165dcc9 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-45b305b9-c3b4-4466-b462-2f11b165dcc9');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "                                            comments label\n",
       "0  Great full sound for the price. No flats or sh...     2\n",
       "1  yea it's fun to play with and teaches alot abo...     2\n",
       "2  An excellent reference book on cape bulbs. A w...     2\n",
       "3  I had read White Fang with my graders recently...     0\n",
       "4  The description of this item totally omits the...     0"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4561ee9a",
   "metadata": {
    "id": "4561ee9a"
   },
   "source": [
    "### 2.6. Split dataset between train and validation sets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc3e0fb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5bc3e0fb",
    "outputId": "eeb5235a-7d63-458a-8d14-d51945a28c71"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of comments to train the model:  5400\n",
      "number of comments to evaluate the model:  600\n",
      "\n",
      "Current time:  2022-08-11_15:47:14\n"
     ]
    }
   ],
   "source": [
    "X = data[\"comments\"].values\n",
    "y = data[\"label\"].values\n",
    "\n",
    "#X_train: comments to train the model\n",
    "#y_train: labels associated with comments in X_train\n",
    "#X_val: comments to evaluate the model\n",
    "#y_val: labels associated with comments in X_val\n",
    "TEST_SIZE = 0.1\n",
    "X_train, X_val, y_train, y_val =  train_test_split(X, y, test_size=TEST_SIZE, random_state=2022)\n",
    "\n",
    "print(\"number of comments to train the model: \",len(X_train))\n",
    "print(\"number of comments to evaluate the model: \",len(X_val))\n",
    "\n",
    "# Time of the creation of the train and validation sets \n",
    "NOW = time.strftime(\"%Y-%m-%d_%H:%M:%S\")\n",
    "print(\"\\nCurrent time: \",NOW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "r7GrLvrjmFz2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 92
    },
    "id": "r7GrLvrjmFz2",
    "outputId": "f22ad7fb-982e-45ba-b67c-bbd458cc4163"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'\\ntrain_name = \"2022-07-25_13:42:49_train_0.9\"\\nval_name = \"2022-07-25_13:42:49_val_0.1\"\\n\\nos.chdir(PATH + \"/2_DataFrame_pkl\") #go to correct folder \\nX_train =  pd.read_pickle(train_name + \\'.pkl\\')[\"comments\"].values\\ny_train =  pd.read_pickle(train_name + \\'.pkl\\')[\"labels\"].values\\nX_val =  pd.read_pickle(val_name + \\'.pkl\\')[\"comments\"].values\\ny_val =  pd.read_pickle(val_name + \\'.pkl\\')[\"labels\"].values\\nos.chdir(PATH) #return to main folder \\n'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#----- Pickle train and validation datasets for reproductibility \n",
    "\n",
    "os.chdir(PATH + \"/2_DataFrame_pkl\") #go to correct folder \n",
    "pd.DataFrame({\"comments\" : X_train,\"labels\" : y_train}).to_pickle(NOW + \"_train_\" + str(1-TEST_SIZE) + \".pkl\") #pickle train dataset\n",
    "pd.DataFrame({\"comments\" : X_val,\"labels\" : y_val}).to_pickle(NOW + \"_val_\" + str(TEST_SIZE) + \".pkl\") #pickle val dataset\n",
    "os.chdir(PATH) #return to main folder \n",
    "\n",
    "\n",
    "#----- Rerieve train and validation datasets \n",
    "\"\"\"\n",
    "train_name = \"2022-07-25_13:42:49_train_0.9\"\n",
    "val_name = \"2022-07-25_13:42:49_val_0.1\"\n",
    "\n",
    "os.chdir(PATH + \"/2_DataFrame_pkl\") #go to correct folder \n",
    "X_train =  pd.read_pickle(train_name + '.pkl')[\"comments\"].values\n",
    "y_train =  pd.read_pickle(train_name + '.pkl')[\"labels\"].values\n",
    "X_val =  pd.read_pickle(val_name + '.pkl')[\"comments\"].values\n",
    "y_val =  pd.read_pickle(val_name + '.pkl')[\"labels\"].values\n",
    "os.chdir(PATH) #return to main folder \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f8426d2",
   "metadata": {
    "id": "5f8426d2"
   },
   "source": [
    "## 3.Set up GPU for training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee63b61a",
   "metadata": {
    "id": "ee63b61a"
   },
   "source": [
    "Google Colab offers free GPUs and TPUs. Since we’ll be training a large neural network it’s best to take advantage of this (in this case we’ll attach a GPU), otherwise training will take a very long time.\n",
    "\n",
    " A GPU can be added by going to the menu and selecting: <font color = \"red\"> **`Edit 🡒 Notebook Settings 🡒 Hardware accelerator 🡒 (GPU)`** </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "JkODS6Diu8NL",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JkODS6Diu8NL",
    "outputId": "787b1078-fc4e-4f34-acc8-c0a51b844ee0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) available.\n",
      "Device name: Tesla T4\n"
     ]
    }
   ],
   "source": [
    "# Import available GPU\n",
    "if torch.cuda.is_available():       \n",
    "    device = torch.device(\"cuda\")\n",
    "    print(f'There are {torch.cuda.device_count()} GPU(s) available.')\n",
    "    print('Device name:', torch.cuda.get_device_name(0))\n",
    "\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "phG2Jlrz4CmP",
   "metadata": {
    "id": "phG2Jlrz4CmP"
   },
   "source": [
    "Baseline: TF+IDF + Naives Bayes Classifier (not tested for now)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "NE5goicJ4Q8u",
   "metadata": {
    "id": "NE5goicJ4Q8u"
   },
   "source": [
    "## 4.Fine-tuning BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hM8qjOl_4xc9",
   "metadata": {
    "id": "hM8qjOl_4xc9"
   },
   "source": [
    "### 4.1. Download Tokenizer\n",
    "\n",
    "In order to apply the pre-trained BERT, we must use the tokenizer provided by the library. This is because (1) the model has a specific, fixed vocabulary and (2) the BERT tokenizer has a particular way of handling out-of-vocabulary word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "OeJqK18V-O1L",
   "metadata": {
    "id": "OeJqK18V-O1L"
   },
   "outputs": [],
   "source": [
    "BERT_MODEL_NAME = 'bert-base-uncased'\n",
    "# could also try: RoBERTA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cenrFpM94zT1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cenrFpM94zT1",
    "outputId": "7a91f34b-6cc1-4f58-f648-b02c75f72e3c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading BERT tokenizer bert-base-uncased...\n",
      "Done!\n",
      "\n",
      "Size of BertTokenizer vocabulary:  30522\n",
      "Size of BertModel vocabulary:  30522\n"
     ]
    }
   ],
   "source": [
    "#Load the BERT tokenizer\n",
    "print('Loading BERT tokenizer ' + BERT_MODEL_NAME + '...')\n",
    "tokenizer = BertTokenizer.from_pretrained(BERT_MODEL_NAME, do_lower_case=True)\n",
    "print('Done!')\n",
    "\n",
    "#Verify that the size of vocabulary are in same in BertTokenozer and BertModel\n",
    "print(\"\")\n",
    "print(\"Size of BertTokenizer vocabulary: \", tokenizer.vocab_size)\n",
    "config = BertConfig.from_pretrained(BERT_MODEL_NAME)\n",
    "print(\"Size of BertModel vocabulary: \",config.vocab_size)\n",
    "# documentation BertConfig:\n",
    "# https://colab.research.google.com/drive/1IPgcACm38dIUaj9RqTWw9xbwwywIOpXf#scrollTo=BKOm2rX1bHHR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "JLqtQsmr8OgE",
   "metadata": {
    "id": "JLqtQsmr8OgE"
   },
   "source": [
    "Apply the tokenizer to one sentence just to see the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "r0PwFrfs7lVA",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "r0PwFrfs7lVA",
    "outputId": "cf82cec0-c265-4555-8741-a144acc60b46"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Original:  [CLS] My dog is [MASK] and likes playing [SEP] [PAD] [PAD]\n",
      "Tokenized:  ['[CLS]', 'my', 'dog', 'is', '[MASK]', 'and', 'likes', 'playing', '[SEP]', '[PAD]', '[PAD]']\n",
      "Token IDs:  [101, 2026, 3899, 2003, 103, 1998, 7777, 2652, 102, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "#Print the original sentence.\n",
    "sentence = \"This is a test to see how BERT tokenizer works\"\n",
    "sentence = \"[CLS] My dog is [MASK] and likes playing [SEP] [PAD] [PAD]\"\n",
    "print(' Original: ', sentence)\n",
    "#Print the sentence split into tokens.\n",
    "print('Tokenized: ', tokenizer.tokenize(sentence))\n",
    "#Print the sentence mapped to token ids.\n",
    "print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(sentence)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6sfYxGbU8ZqT",
   "metadata": {
    "id": "6sfYxGbU8ZqT"
   },
   "source": [
    "When we actually convert all of our sentences, we’ll use the `tokenize.encode` function to handle both steps, rather than calling `tokenize` and `convert_tokens_to_ids` separately."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "C83EHHO79g1A",
   "metadata": {
    "id": "C83EHHO79g1A"
   },
   "source": [
    "### 4.2. Tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0q1YWNFU93We",
   "metadata": {
    "id": "0q1YWNFU93We"
   },
   "source": [
    "The cleaning of the text has already been done beforehand. \n",
    "The level of text pre-processing here should be light because BERT has been trained with whole sentences.\n",
    "\n",
    "In addition, we are required to: \n",
    "\n",
    "**1. Add special tokens to the start and end of each sentence**\n",
    "\n",
    "- Token `[SEP]` :  At the end of every sentence, we need to append the special `[SEP]` token.\n",
    "\n",
    "- Token `[CLS]`: For classification tasks, we must prepend the special `[CLS]` token to the beginning of every sentence.\n",
    "\n",
    "**2.  Pad & truncate all sentences to a single constant length**\n",
    "\n",
    "BERT has two constraints:\n",
    "- All sentences must be padded or truncated to a single, fixed length. \n",
    "- The maximum sentence length is 512 tokens.\n",
    "\n",
    "\n",
    "The BERT model receives a fixed length of sentence as input. For sentences that are shorter than this maximum length, we will have to add paddings (empty tokens) to the sentences to make up the length\n",
    "Padding is done with a special `[PAD]` token.  \n",
    "\n",
    "**3. Explicitly specify what are padding tokens with the \"attention mask\"**\n",
    "\n",
    "The “Attention Mask” is an array of 1 and 0 indicating which tokens are padding and which aren’t. This mask tells the “Self-Attention” mechanism in BERT not to incorporate these `[PAD]` tokens into its interpretation of the sentence.\n",
    "\n",
    "\n",
    "*A brief explanation can be found in tutorial\n",
    "http://mccormickml.com/2019/07/22/BERT-fine-tuning/#2-loading-cola-dataset\n",
    "part 3.2. Required Formatting*  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mifnqUkmF4bK",
   "metadata": {
    "id": "mifnqUkmF4bK"
   },
   "source": [
    "> Before tokenizing, we need to specify the maximum length of our sentences."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9dt_ZTyPx8X",
   "metadata": {
    "id": "d9dt_ZTyPx8X"
   },
   "source": [
    "As we saw, BERT cannot process texts that exceed 512 tokens. \n",
    "Without further pre-processing, BERT will select the first 512 tokens. It is therefore necessary to truncate the text to 512 tokens while trying to preserve as much information as possible. \n",
    "\n",
    "One of the simplest, possible approaches suggested in the paper https://arxiv.org/pdf/1905.05583.pdf (page 5/10) which has proven to be efficient in their problem is to select the beginning and the end of the text. Indeed, the main sentiment is often located in the beginning and end of a text. \n",
    "\n",
    "Once BERT is fine-tuned, we can apply it to our problem which also involves long text. One idea is to divide the text into sentences or windows of 512 tokens and predict the sentiment of each window. The majority sentiment will then be taken as the sentiment of the text. \n",
    "\n",
    "I don't think this approach (cutting the text into windows of 512 tokens and taking the most common sentiment) is suitable for the pre-tuning phase. Indeed, we have a label for the whole text but we do not have a label for each window of text. And the label of the beginning of the text could be different from the label of the end of the text, which could be different from the global label, which could bias, in my opinion, the fine-tuning of BERT.\n",
    "\n",
    "see also: https://stackoverflow.com/questions/58636587/how-to-use-bert-for-long-text-classification\n",
    "\n",
    "https://towardsdatascience.com/how-to-apply-transformers-to-any-length-of-text-a5601410af7f\n",
    "\n",
    "https://www.mdpi.com/1424-8220/22/11/4157/htm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ounl25A9vlx9",
   "metadata": {
    "id": "ounl25A9vlx9"
   },
   "source": [
    "_________________________________________________\n",
    "\n",
    "<font color = \"red\"> /.\\ Beware of confusion over the term **\"sentence\"** /.\\ </font>\n",
    "\n",
    "\n",
    "BERT model is designed in such a way that the \"sentence\" has to start with the [CLS] token and end with the [SEP] token. \n",
    "\n",
    "- If we are working on question answering or language translation then we have to use [SEP] token in between the 2 sentences to make separation. The input must be of the shape: \\\n",
    "<font color = \"green\"> [CLS] sentence 1 [SEP] sentence 2 [SEP] </font> \\\n",
    "(https://www.analyticsvidhya.com/blog/2021/09/an-explanatory-guide-to-bert-tokenizer/) \n",
    "\n",
    "- However, even though the BERT paper uses the term sentence quite often, it is not referring to a linguistic sentence. The paper defines a sentence as \"*an arbitrary span of contiguous text, rather than an actual linguistic sentence*\". **It is therefore completely fine to pass whole paragraphs to BERT**  (https://stackoverflow.com/questions/64881478/passing-multiple-sentences-to-bert + https://github.com/huggingface/transformers/issues/65) \\\n",
    "The [SEP] token is usually used to give the model a hint that the text that follows has a different role than the text before. For question answering, the question should be semantically treated differently than the paragraph. Entity extraction, on the other hand, is usually performed without the [SEP] token. Thus, the input should be: \\\n",
    " <font color = \"green\"> [CLS] text (less than 512 tokens) [SEP] </font>\n",
    "\n",
    "- Finally, if we have long documents (more than 512 tokens) an other method than just taking the beginning and the end of the text is to split the document into shorter sequences and feed these sequences into a BERT model. We obtain the [CLS] embedding for each sequence and merge the embeddings (ie case where there is several [CLS] tokens) (https://zephyrnet.com/classifying-long-text-documents-using-bert/ + https://andriymulyar.com/blog/bert-document-classification + https://discuss.huggingface.co/t/multiple-texts-as-inputs-to-transformers-models/2222/2 + https://www.researchgate.net/figure/Hierarchical-model-for-stance-classification-A-pre-trained-BERT-model-is-used-to-encode_fig1_334081699). Then the input is: \\\n",
    "<font color = \"green\"> [CLS] text (less than 512 tokens) [SEP]\\\n",
    "[CLS] text (less than 512 tokens) [SEP] \\\n",
    "... \\\n",
    "[CLS] text (less than 512 tokens) [SEP] </font>\n",
    "_________________________________________________\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "-iH3z2VbF67i",
   "metadata": {
    "id": "-iH3z2VbF67i"
   },
   "outputs": [],
   "source": [
    "def computeMaxLen(data):\n",
    "  \"\"\"\n",
    "  This function computes the maximum number of tokens in the text.\n",
    "  ---> input:\n",
    "  - data (dataframe): to compute the length of the text data[\"comments\"] \n",
    "  ---> output:\n",
    "  - maximum length of comments (= number of tokens)\n",
    "  \"\"\"\n",
    "  # Retrieve all comments \n",
    "  allComments = data[\"comments\"].values\n",
    "\n",
    "  # Encode our data\n",
    "  encodedComments = [tokenizer.encode(comm, add_special_tokens=True) for comm in allComments] #list of tokens for each comments\n",
    "\n",
    "  # Find the maximum length\n",
    "  max_len = max([len(comm) for comm in encodedComments])\n",
    "  print('Max length = max number of tokens in our dataset: ', max_len)\n",
    "\n",
    "  return max_len\n",
    "\n",
    "#MAX_LEN = computeMaxLen(data)\n",
    "MAX_LEN = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "CNHLUraPMY0y",
   "metadata": {
    "id": "CNHLUraPMY0y"
   },
   "outputs": [],
   "source": [
    "def preprocessingForBert_long(data):\n",
    "  \"\"\"\n",
    "  This function performs required preprocessing steps for pretrained BERT \n",
    "  for long texts (more than 510 tokens).\n",
    "  ---> input: data (np.array): Array of texts to be processed.\n",
    "  ---> ouput: \n",
    "  - input_ids (torch.Tensor): Tensor of token ids to be fed to a model.\n",
    "  - attention_masks (torch.Tensor): Tensor of indices specifying which\n",
    "  tokens should be attended to by the model.\n",
    "\n",
    "  If the input text exceeds 510 tokens (text without SEP and CLS tokens) then the \n",
    "  firsts 'nbFirst' and lasts 'nbLast' tokens are selected to match a length of 510 tokens. \n",
    "  \"\"\"\n",
    "\n",
    "  chunksize = 512 # define target chunksize\n",
    "  nbFirst = 128 # number of tokens to take from the beginning of the text\n",
    "  nbLast = 382  # number of tokens to take from the end of the text\n",
    "                # nbFirst + nbLast = 510 (SEP and CLS tokens not present)\n",
    "\n",
    "  # Create empty lists to store outputs\n",
    "  input_ids = [] \n",
    "  attention_masks = [] \n",
    "\n",
    "  for comment in data:\n",
    "\n",
    "    # create dictionary of 'input_ids' (=tokens) and 'attention_mask' \n",
    "    encoded_c = tokenizer.encode_plus(comment, add_special_tokens=False) \n",
    "    \n",
    "    # if the number of tokens exceeds 510 then the firsts 'nbFirst'\n",
    "    # and lasts 'nbLast' tokens are selected \n",
    "    if len(encoded_c.get(\"input_ids\")) > chunksize - 2: #-2 since SEP and CLS tokens are not present yet\n",
    "      firstTok = encoded_c.get(\"input_ids\")[:nbFirst]\n",
    "      lastTok = encoded_c.get(\"input_ids\")[-nbLast:]\n",
    "      firstMask = encoded_c.get(\"attention_mask\")[:nbFirst]\n",
    "      lastMask = encoded_c.get(\"attention_mask\")[-nbLast:]\n",
    "\n",
    "      tokens = firstTok + lastTok\n",
    "      masks = firstMask + lastMask\n",
    "    else: # otherwise, let the tokens inchanged\n",
    "      tokens =  encoded_c.get(\"input_ids\")\n",
    "      masks = encoded_c.get(\"attention_mask\")\n",
    "\n",
    "    # add SEP (token ID 101) and CLS (token ID 102)\n",
    "    tokens = [101] + tokens + [102]\n",
    "\n",
    "    # add attention tokens to attention mask\n",
    "    masks = [1] + masks + [1]\n",
    "\n",
    "    # get required padding length\n",
    "    pad_len = chunksize  - len(tokens)\n",
    "\n",
    "    # if padding length is more than 0 (ie the number of tokens < 512)\n",
    "    # we must add padding so that each token has a size of 512\n",
    "    if pad_len > 0: \n",
    "      tokens = tokens + [0] * pad_len #add 0s (which  is the token ID for [PAD])\n",
    "      masks  = masks  + [0] * pad_len #add 0s (which  is the token ID for [PAD])\n",
    "\n",
    "    # Add the tokens of the encoded comment to the list.    \n",
    "    input_ids.append(tokens) \n",
    "\n",
    "    # And its attention mask (simply differentiates padding from non-padding).\n",
    "    attention_masks.append(masks) \n",
    "\n",
    "  # Convert lists to tensors\n",
    "  input_ids = torch.tensor(input_ids)\n",
    "  attention_masks = torch.tensor(attention_masks)\n",
    "\n",
    "  return input_ids,attention_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "PZpiGlDH9odY",
   "metadata": {
    "id": "PZpiGlDH9odY"
   },
   "outputs": [],
   "source": [
    "def preprocessingForBert_short(data): \n",
    "  \"\"\"\n",
    "  This function performs required preprocessing steps for pretrained BERT \n",
    "  for short texts (less than 510 tokens)\n",
    "  ---> input: data (np.array): Array of texts to be processed.\n",
    "  ---> ouput: \n",
    "  - input_ids (torch.Tensor): Tensor of token ids to be fed to a model.\n",
    "  - attention_masks (torch.Tensor): Tensor of indices specifying which\n",
    "  tokens should be attended to by the model.\n",
    "  \"\"\"\n",
    "  \n",
    "  # Create empty lists to store outputs\n",
    "  input_ids = []\n",
    "  attention_masks = []\n",
    "\n",
    "  # For every comment...\n",
    "  for comment in data:\n",
    "      # `encode_plus` will:\n",
    "      #    (1) Tokenize the comment\n",
    "      #    (2) Add the `[CLS]` and `[SEP]` token to the start and end\n",
    "      #    (3) Truncate/Pad comment to max length\n",
    "      #    (4) Map tokens to their IDs\n",
    "      #    (5) Create attention mask\n",
    "      #    (6) Return a dictionary of outputs\n",
    "      encoded_comment = tokenizer.encode_plus(\n",
    "          text=comment,              # Preprocess comment\n",
    "          add_special_tokens=True,   # Add `[CLS]` and `[SEP]`\n",
    "          max_length=MAX_LEN,        # Max length to truncate/pad\n",
    "          #padding='max_length',      # Pad comment to max length\n",
    "          pad_to_max_length = True,\n",
    "          #return_tensors='pt',      # Return PyTorch tensor\n",
    "          return_attention_mask=True # Return attention mask\n",
    "          )\n",
    "      \n",
    "      # Add the outputs to the lists\n",
    "      input_ids.append(encoded_comment.get('input_ids'))\n",
    "      attention_masks.append(encoded_comment.get('attention_mask'))\n",
    "\n",
    "  # Convert lists to tensors\n",
    "  input_ids = torch.tensor(input_ids)\n",
    "  attention_masks = torch.tensor(attention_masks)\n",
    "\n",
    "  return input_ids, attention_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "BXinuWjlKgai",
   "metadata": {
    "id": "BXinuWjlKgai"
   },
   "outputs": [],
   "source": [
    "#Test of the function preprocessingForBert\n",
    "#---------------------------------------------\n",
    "#c = [df_1[\"comments\"].iloc[3], \"A test\"]\n",
    "#input_ids,attention_masks = preprocessingForBert_long(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "YcCsd1XS76rD",
   "metadata": {
    "id": "YcCsd1XS76rD"
   },
   "source": [
    "\n",
    "Now let us tokenize our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "VQmpQWmH75Zs",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 358
    },
    "id": "VQmpQWmH75Zs",
    "outputId": "3070a584-3ea9-4c9b-9ba8-36b0f22e544a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The maximum length of the dataset is  2000\n",
      "Therefore, we use the function preprocessingForBert_long\n",
      "\n",
      "Now run the function preprocessingForBert_long on the train set and the validation set:\n",
      "\n",
      "Tokenizing data...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-9634f2dc469d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Now run the function \"\u001b[0m  \u001b[0;34m+\u001b[0m \u001b[0mpreprocessing_for_bert\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" on the train set and the validation set:\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Tokenizing data...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mtrain_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_masks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocessing_for_bert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0mval_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_masks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocessing_for_bert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Done!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"The maximum length of the dataset is \", MAX_LEN)\n",
    "# if maximum length is > 512 tokens (with SEP and CLS tokens)\n",
    "# we use the function preprocessingForBert_long\n",
    "if MAX_LEN > 512:\n",
    "  print(\"Therefore, we use the function preprocessingForBert_long\\n\")\n",
    "  preprocessing_for_bert = preprocessingForBert_long\n",
    "else: # otherwise we use the function preprocessingForBert_short\n",
    "  print(\"Therefore, we use the function preprocessingForBert_short\\n\")\n",
    "  preprocessing_for_bert = preprocessingForBert_short\n",
    "\n",
    "# Run function `preprocessing_for_bert` on the train set and the validation set\n",
    "print(\"Now run the function \"  + preprocessing_for_bert.__name__ + \" on the train set and the validation set:\\n\")\n",
    "print('Tokenizing data...')\n",
    "train_inputs, train_masks = preprocessing_for_bert(X_train)\n",
    "val_inputs, val_masks = preprocessing_for_bert(X_val)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "MQUhLisk5tGA",
   "metadata": {
    "id": "MQUhLisk5tGA"
   },
   "source": [
    "### 4.3. Create PyTorch DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "YNHiFWjA5rhF",
   "metadata": {
    "id": "YNHiFWjA5rhF"
   },
   "source": [
    "We will create an iterator for our dataset using the torch DataLoader class. This will help save on memory during training and boost the training speed.\n",
    "\n",
    "The torch DataLoader combines a dataset and a sampler, and provides an iterable over the given dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "VmQcV5EdW3i8",
   "metadata": {
    "id": "VmQcV5EdW3i8"
   },
   "source": [
    "__batch_size__: (see ML lecture) is the size of the batch present in every neural network for the gradient computation. (also define what is an epoch using the ML course and explain simply how works a Neural Network with backward gradient propagation).\n",
    "\n",
    "https://datascience.stackexchange.com/questions/85973/bert-minimal-batch-size \\\n",
    "https://stats.stackexchange.com/questions/153531/what-is-batch-size-in-neural-network\n",
    "\n",
    "\n",
    "The BERT authors (from Appendix A.3 of the BERT paper https://arxiv.org/pdf/1810.04805.pdf) recommend fine-tuning for 4 epochs over the following hyperparameter options:\n",
    "-  batch sizes: 8, 16, 32, 64, 128\n",
    "- learning rates: 3e-4, 1e-4, 5e-5, 3e-5\n",
    "\n",
    "We can train our model across all combinations of these hyperparameters. That will take a total of (5 batch sizes) $\\times$ (4 learning rates) $\\times$ (2 models) = 40 runs for a grid search. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nywMmiWAQnwJ",
   "metadata": {
    "id": "nywMmiWAQnwJ"
   },
   "source": [
    "**A neural network is trained with a Backpropagation algorithm**\n",
    "- Stochastic gradient descent is an optimization algorithm for minimizing the loss of a predictive model with regard to a training dataset.\n",
    "- Back-propagation is an automatic differentiation algorithm for calculating gradients for the weights in a neural network graph structure.\n",
    "- Stochastic gradient descent + the back-propagation of error algorithms together are used to train neural network models.\n",
    "\n",
    "https://machinelearningmastery.com/difference-between-backpropagation-and-stochastic-gradient-descent/\n",
    "\n",
    "https://www.quora.com/What-is-the-difference-between-the-Adam-Optimizer-and-the-back-propagation-algorithm\n",
    "\n",
    "\n",
    "The stochasticity of the SGD algorithm lies in the computation of the gradient. Indeed, we consider **batch learning**: at each step, $m$ training examples are randomly chosen without replacement and the mean of the $m$ corresponding gradients is used to update the parameters. An **epoch** corresponds to a pass through all the learning data, for example if the batch size $m$ is $1/100$ times the sample size $n$, an epoch corresponds to 100 batches. We iterate the process on a certain number nb of epochs that is fixed in advance. (ML lesson)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lyTpFmMYk-En",
   "metadata": {
    "id": "lyTpFmMYk-En"
   },
   "outputs": [],
   "source": [
    "## For fine-tuning BERT, the authors of BERT recommend a batch size of 8, 16 or 32.\n",
    "BATCH_SIZE = 8 \n",
    "\n",
    "# in our problem, we will see that a BATCH_SIZE of 32 produces a 'CUDA out of memory' error\n",
    "# while BATCH_SIZE 8 or 16 are suitable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Y75aB2oM4cfL",
   "metadata": {
    "id": "Y75aB2oM4cfL"
   },
   "outputs": [],
   "source": [
    "# Convert other data types to torch.Tensor\n",
    "train_labels = torch.tensor(y_train)\n",
    "val_labels = torch.tensor(y_val)\n",
    "\n",
    "# Create the DataLoader for our training set\n",
    "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
    "train_sampler = RandomSampler(train_data) #The purpose of samplers is to determine how batches should be formed.\n",
    "                                          #Samples elements randomly without replacement from a shuffled dataset. \n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=BATCH_SIZE)\n",
    "# the \"train_data\" were sampled with \"RandomSampler\" to form batches of size \"BATCH_SIZE\". \n",
    "# \"train_dataloader\" therefore contains batches of size \"BATCH_SIZE\" each.\n",
    "# There is (len(train_data)//BATCH_SIZE) + 1 batches in \"train_dataloader\" \n",
    "\n",
    "# Create the DataLoader for our validation set\n",
    "val_data = TensorDataset(val_inputs, val_masks, val_labels)\n",
    "val_sampler = SequentialSampler(val_data)\n",
    "val_dataloader = DataLoader(val_data, sampler=val_sampler, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b6aNTx7xmGb",
   "metadata": {
    "id": "8b6aNTx7xmGb"
   },
   "outputs": [],
   "source": [
    "#----- Save dataloader for later use\n",
    "os.chdir(PATH + '/3_DataLoader_pt') #go to correct folder \n",
    "torch.save(train_dataloader, NOW + \"_train_dataloader.pt\")\n",
    "torch.save(val_dataloader, NOW + \"_val_dataloader.pt\")\n",
    "os.chdir(PATH) #return to main folder "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "FCu9-RihKMCg",
   "metadata": {
    "id": "FCu9-RihKMCg"
   },
   "source": [
    "\n",
    "*RandomSampler: Every Sampler subclass has to provide an __iter__ method, providing a way to iterate over indices of dataset elements, and a __len__ method that returns the length of the returned iterators. RandomSampler samples elements randomly. If without replacement, then sample from a shuffled dataset (value by default). If with replacement, then user can specify ``num_samples`` to draw.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "m4OcTAk6Ym4z",
   "metadata": {
    "id": "m4OcTAk6Ym4z"
   },
   "source": [
    "### 4.4. Create functions to train the model\n",
    "\n",
    "Now that our input data is properly formatted, it’s time to **fine tune the BERT model**.\n",
    "\n",
    "BERT-base consists of 12 transformer layers, each transformer layer takes in a list of token embeddings, and produces the same number of embeddings with the same hidden size (or dimensions) on the output. The output of the final transformer layer of the `[CLS]` token is used as the features of the sequence to feed a classifier. \n",
    "\n",
    "For this task, we first want to modify the pre-trained BERT model to give outputs for classification, and then we want to continue training the model on our dataset until that the entire model, end-to-end, is well-suited for our task.\n",
    "\n",
    "Thankfully, the huggingface pytorch implementation includes a set of interfaces designed for a variety of NLP tasks. Though these interfaces are all built on top of a trained BERT model, each has different top layers and output types designed to accomodate their specific NLP task.\\\n",
    "Here is the current list of classes provided for fine-tuning:\n",
    "- BertModel\n",
    "- BertForPreTraining\n",
    "- BertForMaskedLM\n",
    "- BertForNextSentencePrediction\n",
    "- BertForSequenceClassification \n",
    "- BertForTokenClassification\n",
    "- BertForQuestionAnswering\n",
    "\n",
    "*find doc for these models here: https://huggingface.co/transformers/v2.2.0/model_doc/bert.html*\n",
    "\n",
    "The transformers library has the `BertForSequenceClassification` class which is designed for classification tasks. This is the normal BERT model with an **added single linear layer on top for classification**. As we feed input data, the entire pre-trained BERT model and the additional untrained classification layer is trained on our specific task.\n",
    "\n",
    "However, we will **create a new class so we can specify our own choice of classifiers.** (ie implement ourselves our `BertForSequenceClassification`)\n",
    "\n",
    "\n",
    "Below we will create a BertClassifier class with a BERT model to extract the last hidden layer of the [CLS] token and a single-hidden-layer feed-forward neural network as our classifier.\n",
    "\n",
    "Let’s load BERT (before adding our own last layer of neurons)! There are a few different pre-trained BERT models available. `bert-base-uncased` means the version that has only lowercase letters (“uncased”) and is the smaller version of the two (“base” vs “large”).\n",
    "\n",
    "*The documentation for from_pretrained can be found her https://huggingface.co/transformers/v2.2.0/main_classes/model.html#transformers.PreTrainedModel.from_pretrained, \\\n",
    "with the additional parameters defined here https://huggingface.co/transformers/v2.2.0/main_classes/configuration.html#transformers.PretrainedConfig*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "zSQrOiIuzw4H",
   "metadata": {
    "id": "zSQrOiIuzw4H"
   },
   "source": [
    "\n",
    "#### a. Class BertClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "uhH1yIvp5CsQ",
   "metadata": {
    "id": "uhH1yIvp5CsQ"
   },
   "outputs": [],
   "source": [
    "# we will use the BERT base model(the smaller one)\n",
    "#NUM_LABELS = 3 # we need labels positive,neutral,negative\n",
    "NUM_LABELS = 2 # we need labels positive,negative\n",
    "\n",
    "# Create the BertClassfier class\n",
    "class BertClassifier(nn.Module):\n",
    "  \"\"\"\n",
    "  Bert Model for Classification Tasks. \n",
    "  \"\"\"\n",
    "  def __init__(self, freeze_bert=False):\n",
    "    \"\"\"\n",
    "    Parameters of this class: \n",
    "    - bert: a BertModel object\n",
    "    - classifier: a torch.nn.Module classifier (torch.nn.Module = base class for all neural network modules)\n",
    "    - freeze_bert (bool): Set \"False\" to fine-tune the BERT model\n",
    "    \"\"\"\n",
    "    super(BertClassifier, self).__init__() #inherits the methods from class BertClassifier (nn.Module)\n",
    "\n",
    "    # Instantiate BERT model (pre-trained BERT model)\n",
    "    self.bert = BertModel.from_pretrained(BERT_MODEL_NAME)\n",
    "\n",
    "   # Specify hidden size of BERT, hidden size of our classifier, and number of labels\n",
    "    D_in = self.bert.config.hidden_size # number of neurons in the input layer of our classifier (here 768)\n",
    "                                        #     BERT model encodes everything it needs for the classification \n",
    "                                        #     step into a single 768-value embedding vector. \n",
    "    H = 50                              # number of neurons in the hidden layer of our classifier (### why 50 ??)\n",
    "    D_out = NUM_LABELS                  # number of neurons in the output layer of our classifier\n",
    "\n",
    "\n",
    "    # Here we can specify our own classifier:\n",
    "    # Instantiate an one-layer feed-forward classifier\n",
    "    self.classifier = nn.Sequential( #sequential container. Modules will be added to it in the order they are passed in the constructor.\n",
    "        nn.Linear(D_in, H), # apply a linear transformation (y=xAT+b) with b: bias and A : weigts to be trained\n",
    "        nn.ReLU(), # apply activation function\n",
    "        #nn.Dropout(p=0.5), \n",
    "        nn.Linear(H, D_out) # apply a linear transformation (y=xAT+b) with b: bias and A : weigts to be trained\n",
    "    )\n",
    "\n",
    "    # Freeze the BERT model\n",
    "    if freeze_bert: # if the model is freezed, the parameters won't be update\n",
    "                    # ie : no gradient computation\n",
    "      for param in self.bert.parameters():\n",
    "        param.requires_grad = False #no gradient computation\n",
    "\n",
    "           \n",
    "  def forward(self, input_ids, attention_mask):\n",
    "    \"\"\"\n",
    "    Feed input to BERT and the classifier to compute logits. \n",
    "    \n",
    "    NOTE: the logits is the output of the neural network before going through the softmax/sigmoid activation function: \n",
    "    for optimization reasons, we will handle the softmax computation later.\n",
    "    That is to say, although we use softmax/sigmoid as the activation function in the last layer in our design, \n",
    "    for ease of computation, we take out logits separately. This is because it is more efficient to calculate softmax \n",
    "    and cross-entropy loss together. Remember that cross-entropy is a cost function, not used in forward propagation.    \n",
    "\n",
    "    ---> inputs: \n",
    "    - input_ids (torch.Tensor): an input tensor with shape (batc_size, max_length)\n",
    "    - attention_mask (torch.Tensor): a tensor that hold attention mask\n",
    "      information with shape (batch_size, max_length)\n",
    "    ---> outputs:\n",
    "    - logits (torch.Tensor): an output tensor with shape (batch_size,num_labels)\n",
    "    \"\"\"\n",
    "\n",
    "    # Feed input to BERT\n",
    "    outputs = self.bert(input_ids=input_ids,\n",
    "                        attention_mask=attention_mask)\n",
    "    # outputs contains: \n",
    "    # - arg 0: a sequence of hidden states of the last layer of the model\n",
    "    # of size: [nb of comments, nb of tokens of the comment, nb of hidden units in the feedforward-networks (768)]\n",
    "    # - arg 1: the pooled output = a summary of the content of the BERT model\n",
    "  \n",
    "    # Extract the last hidden state of the token `[CLS]` for classification task\n",
    "    last_hidden_state_cls = outputs[0][:, 0, :]\n",
    "\n",
    "    # Feed input to classifier to compute logits\n",
    "    logits = self.classifier(last_hidden_state_cls) #input layer of our own classifier = last hidden state of the token `[CLS]`\n",
    "    return logits #output of the neural network before going through the softmax/sigmoid activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "onuhNbDhUKt7",
   "metadata": {
    "id": "onuhNbDhUKt7"
   },
   "outputs": [],
   "source": [
    "from types import FunctionType\n",
    "def methods(cls):\n",
    "  \"\"\"This function displays the mothod present in a class\"\"\"\n",
    "  return [x for x, y in cls.__dict__.items() if type(y) == FunctionType]\n",
    "\n",
    "methods(BertClassifier) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "X7D1UuO07sJa",
   "metadata": {
    "id": "X7D1UuO07sJa"
   },
   "source": [
    "**Remarks in the above code:**\n",
    "\n",
    "**1)** Following pre-trained models are available to choose from.\n",
    "- BERT-Base, Uncased: 12-layer, 768-hidden, 12-heads, 110M parameters\n",
    "- BERT-Large, Uncased: 24-layer, 1024-hidden, 16-heads, 340M parameters\n",
    "- BERT-Base, Cased: 12-layer, 768-hidden, 12-heads , 110M parameters\n",
    "- BERT-Large, Cased: 24-layer, 1024-hidden, 16-heads, 340M parameters\n",
    "- BERT-Base, Multilingual Case: 104 languages, 12-layer, 768-hidden, 12-heads, 110M parameters\n",
    "- BERT-Base, Chinese: Chinese Simplified and Traditional, 12-layer, 768-hidden, 12-heads, 110M parameters\n",
    "\n",
    "We will use basic model: `uncased_L-12_H-768_A-12 `\n",
    "\n",
    "**2)** A feedforward neural network (FNN) is an artificial neural network wherein connections between the nodes do not form a cycle. As such, it is different from its descendant: recurrent neural networks. \n",
    "\n",
    "Here, we extract the output of the last transformer layer for the [CLS] token (= the last hidden state of the token `[CLS]`) and put it as an input on our own FNN with: \n",
    "- 768 neurons as input layers because it is specified in the BERT pretrained algorithm we use: BERT-Base with 768-hidden neurons.\n",
    "- 50 neurons as hidden layers <font color = 'red'> (this value was on the doc but I don't know why) </font>\n",
    "- 3 neurons as output layer because we need 3 classes (neutral,positive,negative).\n",
    "\n",
    "explication of the output corresponding to [CLS]: https://datascience.stackexchange.com/questions/66207/what-is-purpose-of-the-cls-token-and-why-is-its-encoding-output-important\n",
    "\n",
    "See the illustration below:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "TApRxQx6Dw89",
   "metadata": {
    "id": "TApRxQx6Dw89"
   },
   "source": [
    "\n",
    "![image.png](data:image/png;base64,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)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "z9ss2ecQFcH0",
   "metadata": {
    "id": "z9ss2ecQFcH0"
   },
   "source": [
    "In the function, we have the code below: \n",
    "\n",
    "     self.classifier = nn.Sequential(\n",
    "            nn.Linear(D_in, H),\n",
    "            nn.ReLU(), \n",
    "            #nn.Dropout(0.5),\n",
    "            nn.Linear(H, D_out) \n",
    "        )\n",
    "\n",
    "An artificial neuron is a function $f_j$ of the input $x = (x_1,...,x_d)$ weighted by a vector of connection weights $wj = (w_{j,1},...,w_{j,d})$, completed by a neuron bias $b_j$, and associated to an activation function $\\phi$, namely $y_j = f_j(x) = \\phi(〈w_j,x〉+ b_j)$ (see image below)\n",
    "\n",
    "`nn.Linear(in_features, out_features, bias=True)` applies a linear transformation  to the incoming data: $y=x A^T+b$ with $A$ the matrix of weigths and $b$ the biais to be trained (the weights and the biais are the parameters of the model to determine while training). Then as we apply an activation function $\\phi$, here the ReLU function (typical function to apply in the hidden layers of a neural network). Then again another set of weights and biais with the second `nn.Linear()` function.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "L9kt_75jDaMP",
   "metadata": {
    "id": "L9kt_75jDaMP"
   },
   "source": [
    "![image.png](data:image/png;base64,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)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "YjnrljJEzB5s",
   "metadata": {
    "id": "YjnrljJEzB5s"
   },
   "source": [
    "#### b. Functions to **save** the model's state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "L05wo69PrZeI",
   "metadata": {
    "id": "L05wo69PrZeI"
   },
   "outputs": [],
   "source": [
    "# Functions to save and load our fine-tuned BERT model \n",
    "# to resume training from where it left off. \n",
    "#----------------------------------------------------\n",
    "def save_ckp(state,name=\"\"):\n",
    "  \"\"\"\n",
    "  This function saves the state of the model to the specified checkpoint directory.\n",
    "  ---> input:\n",
    "  - state: current state of the model\n",
    "  - name (string): string involved in the construction of \"checkpoint_name\" \n",
    "  ---> ouput:\n",
    "  - checkpoint_name: name of the saved model\n",
    "  \"\"\"\n",
    "  checkpoint_dir  = PATH + '/5_Checkpoints_pt'\n",
    "  # save to pytorch format(.pt)\n",
    "  checkpoint_name =  NOW + name + '_checkpoint.pt' \n",
    "  #checkpoint_name = checkpoint_dir + '/' + NOW + name + '_checkpoint.pt' \n",
    "  #f_path = checkpoint_name\n",
    "  f_path = checkpoint_dir + '/' + checkpoint_name\n",
    "  torch.save(state, f_path)\n",
    "  return checkpoint_name\n",
    "\n",
    "def load_ckp(checkpoint_fpath, model):\n",
    "  \"\"\"\n",
    "  This function loads a fine-tune model to the specified checkpoint directory.\n",
    "  Now we can simply pass this model, to our training loop \n",
    "  so that the model resumes training from where it left off.\n",
    "  \"\"\"\n",
    "  checkpoint = torch.load(checkpoint_fpath,map_location=device) \n",
    "  model.load_state_dict(checkpoint['state_dict'])\n",
    "  return model, checkpoint['epoch']\n",
    "\n",
    "# documentation:\n",
    "# https://medium.com/analytics-vidhya/saving-and-loading-your-model-to-resume-training-in-pytorch-cb687352fa61\n",
    "# above function can be improved by saving the best model (see doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "h7QEpz-2MVCd",
   "metadata": {
    "id": "h7QEpz-2MVCd"
   },
   "source": [
    "#### c. Function to **initialize** the model\n",
    "\n",
    "To fine-tune our Bert Classifier, we need to create an optimizer. The authors recommend following hyper-parameters:\n",
    "- Batch size: 16 or 32\n",
    "- Learning rate (Adam): 5e-5, 3e-5 or 2e-5\n",
    "- Number of epochs: 2, 3, 4\n",
    "\n",
    "Huggingface provided the `run_glue.py` script (https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L109) , an examples of implementing the transformers library. In the script, the AdamW optimizer is used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "BPrakY9PUpwM",
   "metadata": {
    "id": "BPrakY9PUpwM"
   },
   "outputs": [],
   "source": [
    "def initialize_model(train_dataloader,epochs=4,resume_training=False,ckp_path=None,lr=5e-5,eps=1e-8):\n",
    "  \"\"\"\n",
    "  Initialize the Bert Classifier, the optimizer and the learning rate scheduler.\n",
    "  ---> input:\n",
    "  - train_dataloader: PyTorch train DataLoader\n",
    "  - epochs (integer): number of epochs to train the model\n",
    "  - resume_training (bool): if True, the model is initialized with an already fine-tuned model to \n",
    "    resume training from where it left off.\n",
    "  - ckp_path (string): path of the directory to retrieve the already fine-tuned model in case \n",
    "  resume_training = True.\n",
    "  - lr  (float): 5e-5 = Default learning rate in AdamW optimizer \n",
    "  - eps (float): 1e-8 = Default epsilon value in AdamW optimizer\n",
    "  ---> ouput: \n",
    "  - bert_classifier\n",
    "  - optimizer\n",
    "  - scheduler\n",
    "    \"\"\"\n",
    "  # Instantiate Bert Classifier (using our own BertClassifier class defined above)\n",
    "  bert_classifier = BertClassifier(freeze_bert=False)\n",
    "\n",
    "  # Tell PyTorch to run the model on GPU\n",
    "  bert_classifier.to(device)\n",
    "\n",
    "  #=======================================\n",
    "  # if we want to resume training, we initialise our model \n",
    "  # with the parameters of the an already fine-tuned model.\n",
    "  if resume_training:\n",
    "    # Load the already fine-tuned model\n",
    "    bert_classifier, start_epoch = load_ckp(ckp_path, bert_classifier)\n",
    "    print (\"Resumed model operational for further training.\\nThis model has already been trained with {} epochs.\".format(start_epoch))\n",
    "  #=======================================\n",
    "\n",
    "  # Create the optimizer (using AdamW optimizer)\n",
    "  optimizer = AdamW(bert_classifier.parameters(),\n",
    "                    lr=lr,    \n",
    "                    eps=eps)\n",
    "\n",
    "  # Total number of training steps\n",
    "  total_steps = len(train_dataloader) * epochs #nb of batches * nb of epochs\n",
    "\n",
    "  # Set up the learning rate scheduler\n",
    "  scheduler = get_linear_schedule_with_warmup(optimizer,\n",
    "                                              num_warmup_steps=0, # Default value\n",
    "                                              num_training_steps=total_steps)\n",
    "      #scheduler: creates a schedule with a learning rate that decreases linearly \n",
    "      #from the initial lr set in the optimizer to 0, after a warmup period during\n",
    "      #which it increases linearly from 0 to the initial lr set in the optimizer.\n",
    "      \n",
    "  return bert_classifier, optimizer, scheduler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "EymTUz9QO4jJ",
   "metadata": {
    "id": "EymTUz9QO4jJ"
   },
   "source": [
    "Remeber that stochastic gradient descent +  the back-propagation of error algorithms together are used to train neural network models. \n",
    "\n",
    "Thus, the **Adam optimization algorithm** is an extension to stochastic gradient descent that has recently seen broader adoption for deep learning applications in computer vision and natural language processing. It is used instead of the classical stochastic gradient descent procedure to update network weights iterative based in training data. \n",
    "https://machinelearningmastery.com/adam-optimization-algorithm-for-deep-learning/\n",
    "\n",
    "\n",
    "The **learning rate** is a hyperparameter used in the computation of the gradient (gradient present in every Neural Network) that controls how much to change the model in response to the estimated error each time the model weights are updated. Its calibration is very important for the con-\n",
    "vergence of the algorithm. If it is too small, the convergence is very slow and the optimization can be blocked on a local minimum. If the learning rate is too large, the network will oscillate around an optimum without stabilizing and converging. \n",
    "\n",
    "**epsilon** is a very small number to prevent any division by zero in the implementation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "PAMXeIEZ17CY",
   "metadata": {
    "id": "PAMXeIEZ17CY"
   },
   "source": [
    "#### d. Function to **train** the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ByZiSgvhRktA",
   "metadata": {
    "id": "ByZiSgvhRktA"
   },
   "source": [
    "We will train our Bert Classifier for 4 epochs (or maybe less...). In each epoch, we will train our model and evaluate its performance on the validation set. In more details, we will:\n",
    "\n",
    "Training:\n",
    "- Unpack our data from the dataloader and load the data onto the GPU\n",
    "- Zero out gradients calculated in the previous pass\n",
    "- Perform a forward pass to compute logits and loss\n",
    "- Perform a backward pass to compute gradients (loss.backward())\n",
    "- Clip the norm of the gradients to 1.0 to prevent \"exploding gradients\"\n",
    "- Update the model's parameters (optimizer.step())\n",
    "- Update the learning rate (scheduler.step())\n",
    "\n",
    "Evaluation:\n",
    "- Unpack our data and load onto the GPU\n",
    "- Forward pass\n",
    "- Compute loss and accuracy rate over the validation set\n",
    "\n",
    "The script below is commented with the details of our training and evaluation loop.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "JeXgK-edV86P",
   "metadata": {
    "id": "JeXgK-edV86P"
   },
   "outputs": [],
   "source": [
    "# Specify loss function\n",
    "loss_fn = nn.CrossEntropyLoss() # use cross-entropy because we are in a multi-class classification task\n",
    "\n",
    "def set_seed(seed_value=42):\n",
    "  \"\"\"\n",
    "  Set seed for reproducibility.\n",
    "  \"\"\"\n",
    "  random.seed(seed_value)\n",
    "  np.random.seed(seed_value)\n",
    "  torch.manual_seed(seed_value)\n",
    "  torch.cuda.manual_seed_all(seed_value)\n",
    "\n",
    "def train(model, train_dataloader, val_dataloader=None, epochs=4, evaluation=False,save_model=True):\n",
    "  \"\"\"\n",
    "  Train the BertClassifier model.\n",
    "  ---> input:\n",
    "  - model: the model from our bertClassifier class\n",
    "  - train_dataloader: PyTorch train DataLoader\n",
    "  - val_dataloader: PyTorch validation DataLoader if evaluation=True\n",
    "  - epochs (int): number of epochs to train the model\n",
    "  - evaluation (bool): if True, evaluate the model after each epoch on the validation set \n",
    "  if one is provided by variable \"val_dataloader\"\n",
    "  - save_model (bool): if True, saves all parameters of the model to resume training.\n",
    "  ---> ouput: \n",
    "  - the variable \"model\" (=our BertClassifier model) is modified (=trained) by this function.\n",
    "  - valLossList (list): list containing the \"val_loss\" value after each epoch\n",
    "  - valAccuList (list): list containing the \"val_accuracy\" value after each epoch\n",
    "  - checkpoint_name (string): name of the saved model\n",
    "  \"\"\"\n",
    "  valLossList = [] #to save val_loss value after each epoch\n",
    "  valAccuList = [] #to save val_accuracy value after each epoch\n",
    "\n",
    "  #----------[ START training loop for each epochs \n",
    "  print(\"Start training...\\n\")\n",
    "  for epoch_i in range(epochs):\n",
    "    # =======================================\n",
    "    #               Training\n",
    "    # =======================================\n",
    "    # Print the header of the result table\n",
    "    print(f\"{'Epoch':^7} | {'Batch':^7} | {'Train Loss':^12} | {'Val Loss':^10} | {'Val Acc':^9} | {'Elapsed':^9}\") #^7: size of the displayed cell\n",
    "    print(\"-\"*70)\n",
    "\n",
    "    # Measure the elapsed time of each epoch\n",
    "    t0_epoch, t0_batch = time.time(), time.time()\n",
    "\n",
    "    # Reset tracking variables at the beginning of each epoch\n",
    "    total_loss, batch_loss, batch_counts = 0, 0, 0\n",
    "\n",
    "    # Put the model into the training mode\n",
    "    model.train()\n",
    "\n",
    "    # For each batch of training data...\n",
    "    #-----[ START loop through each batch\n",
    "    for step, batch in enumerate(train_dataloader): # At each step, m = \"batch_size\" training examples are randomly chosen without replacement.\n",
    "                                                    # This samples are stored in the variable batch\n",
    "                                                    # There are as many steps as there are batches\n",
    "                                                    # here a batch contains m input_ids, m attention_masks and m labels\n",
    "      batch_counts +=1\n",
    "     \n",
    "      # Load batch to GPU\n",
    "      b_input_ids, b_attn_mask, b_labels = tuple(t.to(device) for t in batch) \n",
    "\n",
    "      # Zero out any previously calculated gradients\n",
    "      model.zero_grad()\n",
    "\n",
    "      # Perform a forward pass. This will return logits \n",
    "      # logits = output of the neural network before going through the softmax/sigmoid activation function\n",
    "      # it is the output of function \"forward\" in the class \"BertClassifier\"\n",
    "      logits = model(b_input_ids, b_attn_mask)\n",
    "\n",
    "      # Compute loss and accumulate the loss values\n",
    "      loss = loss_fn(logits, b_labels) \n",
    "      batch_loss += loss.item()\n",
    "      total_loss += loss.item()\n",
    "\n",
    "      # Perform a backward pass to calculate gradients\n",
    "      loss.backward()\n",
    "\n",
    "      # Clip the norm of the gradients to 1.0 to prevent \"exploding gradients\"\n",
    "      torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "      # Update parameters and the learning rate\n",
    "      optimizer.step() # update parameters\n",
    "      scheduler.step() # update learning rate \n",
    "\n",
    "      # Print the loss values and time elapsed for every 20 batches\n",
    "      if (step % 20 == 0 and step != 0) or (step == len(train_dataloader) - 1):\n",
    "        # Calculate time elapsed for 20 batches\n",
    "        time_elapsed = time.time() - t0_batch\n",
    "\n",
    "        # Print training results\n",
    "        print(f\"{epoch_i + 1:^7} | {step:^7} | {batch_loss / batch_counts:^12.6f} | {'-':^10} | {'-':^9} | {time_elapsed:^9.2f}\")\n",
    "\n",
    "        # Reset batch tracking variables\n",
    "        batch_loss, batch_counts = 0, 0\n",
    "        t0_batch = time.time()\n",
    "\n",
    "      #-----] END loop through each batch\n",
    "      \n",
    "    # Calculate the average loss over the entire training data\n",
    "    avg_train_loss = total_loss / len(train_dataloader)\n",
    "\n",
    "    print(\"-\"*70)\n",
    "    # =======================================\n",
    "    #               Evaluation\n",
    "    # =======================================\n",
    "    if evaluation == True:\n",
    "      # After the completion of each training epoch, measure the model's performance\n",
    "      # on our validation set.\n",
    "      val_loss, val_accuracy = evaluate(model, val_dataloader)\n",
    "      valLossList.append(val_loss)\n",
    "      valAccuList.append(val_accuracy)\n",
    "\n",
    "      # Print performance over the entire training data\n",
    "      time_elapsed = time.time() - t0_epoch\n",
    "        \n",
    "      print(f\"{epoch_i + 1:^7} | {'-':^7} | {avg_train_loss:^12.6f} | {val_loss:^10.6f} | {val_accuracy:^9.2f} | {time_elapsed:^9.2f}\")\n",
    "      print(\"-\"*70)\n",
    "    print(\"\\n\")\n",
    "\n",
    "    # =======================================\n",
    "    #              Checkpoint\n",
    "    # =======================================\n",
    "    # If save_model = True, \n",
    "    # After the completion of each epoch, saves de model in the desired location\n",
    "    # so that the fine-tuned model can be re-used later to resume training\n",
    "    if save_model: \n",
    "      checkpoint = {\n",
    "      'epoch': epoch_i + 1,\n",
    "      'state_dict': model.state_dict()}\n",
    "\n",
    "      if evaluation == True: # If evaluation = True, specify that the checkpoint  \n",
    "                             # is from a model trained on the train set only \n",
    "        check_name = \"_eval\" \n",
    "\n",
    "      else: # else, specify that the checkpoint is from a model\n",
    "            # trained on train set + validation set\n",
    "        check_name = \"_full\"\n",
    "\n",
    "      checkpoint_name = save_ckp(checkpoint,check_name)\n",
    "\n",
    "  #----------] END training loop for each epochs \n",
    "\n",
    "  print(\"Training complete!\")\n",
    "  return valLossList,valAccuList,checkpoint_name\n",
    "\n",
    "def evaluate(model, val_dataloader):\n",
    "  \"\"\"\n",
    "  After the completion of each training epoch, measure the model's performance\n",
    "  on our validation set.\n",
    "  \"\"\"\n",
    "  # Put the model into the evaluation mode. The dropout layers are disabled during\n",
    "  # the test time.\n",
    "  model.eval()\n",
    "\n",
    "  # Tracking variables\n",
    "  val_accuracy = []\n",
    "  val_loss = []\n",
    "\n",
    "  # For each batch in our validation set...\n",
    "  for batch in val_dataloader:\n",
    "    # Load batch to GPU\n",
    "    b_input_ids, b_attn_mask, b_labels = tuple(t.to(device) for t in batch)\n",
    "    \n",
    "    # Compute logits\n",
    "    with torch.no_grad(): #disabled gradient calculation\n",
    "      logits = model(b_input_ids, b_attn_mask)\n",
    "\n",
    "      # Compute loss\n",
    "      loss = loss_fn(logits, b_labels)\n",
    "      val_loss.append(loss.item())\n",
    "\n",
    "      # Get the predictions\n",
    "      preds = torch.argmax(logits, dim=1).flatten()\n",
    "\n",
    "      # Calculate the accuracy rate\n",
    "      accuracy = (preds == b_labels).cpu().numpy().mean() * 100\n",
    "      val_accuracy.append(accuracy)\n",
    "\n",
    "  # Compute the average accuracy and loss over the validation set.\n",
    "  val_loss = np.mean(val_loss)\n",
    "  val_accuracy = np.mean(val_accuracy)\n",
    "\n",
    "  return val_loss, val_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ZQ9FuQ5Q2hmv",
   "metadata": {
    "id": "ZQ9FuQ5Q2hmv"
   },
   "source": [
    "### 4.5. Train model on Train set + evaluation on Val set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "uNb0K2r3SU08",
   "metadata": {
    "id": "uNb0K2r3SU08"
   },
   "source": [
    "Now, let's start training our BertClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "CDZjIcBv3lGe",
   "metadata": {
    "id": "CDZjIcBv3lGe"
   },
   "source": [
    "#### a. Initialise model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad09Q2GUahgp",
   "metadata": {
    "id": "ad09Q2GUahgp"
   },
   "source": [
    "##### a.1 Initialise new model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Oj3OpIN6SUMz",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "ac59508ba83c485a8e34a6ce4f6293e6",
      "1c6373b7d4054fd098c22b3ce76dcdf9",
      "46929dc91a9e4c3883fa08c57b44f358",
      "c29dc12cbe4043ddad242c9a5f54518a",
      "2cadababb4174c7e987b56e402266b76",
      "a6a654f333534caea912de7e24879cd9",
      "1416b16857284c919e26571b7727250d",
      "a33c4dbf05f54c4abf0c491f70d21b63",
      "553be9992ac1461e886e38697c907c07",
      "9cf008d0995e4795ab843abbd97ed846",
      "86fdafd575604762a8a95a98111978c1"
     ]
    },
    "id": "Oj3OpIN6SUMz",
    "outputId": "8ea55864-496b-443e-9dcd-7002ad883e55"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac59508ba83c485a8e34a6ce4f6293e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "RESUME = False; CKP_NAME=\"\";  PHASE = 1 # do not change\n",
    "# =======================================\n",
    "# INITIALISE MODEL:\n",
    "# =======================================\n",
    "NUM_EPOCHS = 2\n",
    "\n",
    "#-- indicate the parameters in the AdamW optimizer\n",
    "EPS = 1e-8 # Default epsilon value in AdamW optimizer\n",
    "LR = 5e-5  # Default learning rate in AdamW optimizer \n",
    "#-- Set seed for reproducibility\n",
    "set_seed(42)   \n",
    "\n",
    "bert_classifier, optimizer, scheduler = initialize_model(train_dataloader, epochs=NUM_EPOCHS, lr=LR, eps=EPS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ViQfkSn-n1l",
   "metadata": {
    "id": "1ViQfkSn-n1l"
   },
   "source": [
    "##### a.2. Initialise with resumed model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lUejU8gl-SYV",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 401
    },
    "id": "lUejU8gl-SYV",
    "outputId": "a121c15b-fb04-423d-8701-07143bbbed71"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-69-f91b7e39e542>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;31m#----- Load train_dataloader and val_dataloader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPATH\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/3_DataLoader_pt'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#go to correct folder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0mtrain_dataloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader_name\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\".pt\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#load info\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0mval_dataloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_dataloader_name\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\".pt\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#load info\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPATH\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#return to main folder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    697\u001b[0m         \u001b[0mpickle_load_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'encoding'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 699\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    700\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m             \u001b[0;31m# The zipfile reader is going to advance the current file position.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'w'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_open_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '2022-07-28_16:40:30_train_dataloader.pt'"
     ]
    }
   ],
   "source": [
    "RESUME = True; FULL_RUN = False; PHASE = 1 # do not change\n",
    "# =======================================\n",
    "# RESUME MODEL:\n",
    "# =======================================\n",
    "# To do this, make sure to run the code in the sections:\n",
    "# 1\n",
    "# 2.1\n",
    "# 3\n",
    "# 4.4  /.\\ Beware to put the correct NUM_LABELS /.\\\n",
    "\n",
    "#----- Make sure that the DATES in the names below are the SAME: \n",
    "#-- name of the train_dataloader to resume:\n",
    "val_dataloader_name = \"2022-07-28_16:40:30_val_dataloader\" \n",
    "#-- name of the val_dataloader to resume:\n",
    "train_dataloader_name = \"2022-07-28_16:40:30_train_dataloader\"\n",
    "#-- name of the fine-tuned to resume:\n",
    "CKP_NAME = '2022-07-28_16:40:30_eval_checkpoint' \n",
    "\n",
    "#-- indicate the number of epochs to make in the next training:\n",
    "NUM_EPOCHS = 1\n",
    "\n",
    "#-- indicate the parameters in the AdamW optimizer\n",
    "EPS = 1e-8 # Default epsilon value in AdamW optimizer\n",
    "LR = 5e-5  # Default learning rate in AdamW optimizer \n",
    "\n",
    "#-- Redefine some global variables if not already defined: \n",
    "BERT_MODEL_NAME = 'bert-base-uncased'\n",
    "\n",
    "#----- Load train_dataloader and val_dataloader\n",
    "os.chdir(PATH + '/3_DataLoader_pt') #go to correct folder \n",
    "train_dataloader = torch.load(train_dataloader_name + \".pt\") #load info\n",
    "val_dataloader = torch.load(val_dataloader_name + \".pt\") #load info\n",
    "os.chdir(PATH) #return to main folder \n",
    "\n",
    "#----- Initlialize the model with resumed fine-tuned BERT model \n",
    "bert_classifier, optimizer, scheduler = initialize_model(\n",
    "      train_dataloader, epochs = NUM_EPOCHS ,resume_training = True,\n",
    "      ckp_path = PATH + '/5_Checkpoints_pt/' + CKP_NAME + \".pt\",lr=LR,eps=EPS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0BHYKBIgaOxA",
   "metadata": {
    "id": "0BHYKBIgaOxA"
   },
   "source": [
    "#### b. Train model on Train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tl3qqRQulGYF",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tl3qqRQulGYF",
    "outputId": "8d54c37e-a842-492a-89a9-6b3fef61fe96"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training...\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
      "----------------------------------------------------------------------\n",
      "   1    |   20    |   0.680802   |     -      |     -     |   15.41  \n",
      "   1    |   40    |   0.618168   |     -      |     -     |   15.10  \n",
      "   1    |   60    |   0.635223   |     -      |     -     |   15.47  \n",
      "   1    |   80    |   0.356148   |     -      |     -     |   15.40  \n",
      "   1    |   100   |   0.605691   |     -      |     -     |   15.08  \n",
      "   1    |   120   |   0.477335   |     -      |     -     |   14.98  \n",
      "   1    |   140   |   0.559744   |     -      |     -     |   14.98  \n",
      "   1    |   160   |   0.519840   |     -      |     -     |   15.12  \n",
      "   1    |   180   |   0.471557   |     -      |     -     |   15.21  \n",
      "   1    |   200   |   0.428075   |     -      |     -     |   15.16  \n",
      "   1    |   220   |   0.467264   |     -      |     -     |   15.11  \n",
      "   1    |   240   |   0.404632   |     -      |     -     |   15.03  \n",
      "   1    |   260   |   0.350929   |     -      |     -     |   15.11  \n",
      "   1    |   280   |   0.392276   |     -      |     -     |   15.08  \n",
      "   1    |   300   |   0.453622   |     -      |     -     |   15.14  \n",
      "   1    |   320   |   0.414761   |     -      |     -     |   15.14  \n",
      "   1    |   340   |   0.393778   |     -      |     -     |   15.22  \n",
      "   1    |   360   |   0.398360   |     -      |     -     |   15.22  \n",
      "   1    |   380   |   0.474726   |     -      |     -     |   15.10  \n",
      "   1    |   400   |   0.381361   |     -      |     -     |   15.00  \n",
      "   1    |   420   |   0.391506   |     -      |     -     |   15.02  \n",
      "   1    |   440   |   0.331377   |     -      |     -     |   15.18  \n",
      "   1    |   460   |   0.399050   |     -      |     -     |   15.25  \n",
      "   1    |   480   |   0.406350   |     -      |     -     |   15.18  \n",
      "   1    |   500   |   0.495312   |     -      |     -     |   15.06  \n",
      "   1    |   520   |   0.409848   |     -      |     -     |   15.03  \n",
      "   1    |   540   |   0.367546   |     -      |     -     |   15.10  \n",
      "   1    |   560   |   0.376798   |     -      |     -     |   15.18  \n",
      "   1    |   580   |   0.330663   |     -      |     -     |   15.20  \n",
      "   1    |   600   |   0.367395   |     -      |     -     |   15.13  \n",
      "   1    |   620   |   0.377715   |     -      |     -     |   15.04  \n",
      "   1    |   640   |   0.396331   |     -      |     -     |   15.02  \n",
      "   1    |   660   |   0.403333   |     -      |     -     |   15.14  \n",
      "   1    |   674   |   0.331539   |     -      |     -     |   10.65  \n",
      "----------------------------------------------------------------------\n",
      "   1    |    -    |   0.438626   |  0.417996  |   84.00   |  531.45  \n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
      "----------------------------------------------------------------------\n",
      "   2    |   20    |   0.253768   |     -      |     -     |   15.84  \n",
      "   2    |   40    |   0.177061   |     -      |     -     |   15.38  \n",
      "   2    |   60    |   0.235296   |     -      |     -     |   15.22  \n",
      "   2    |   80    |   0.250273   |     -      |     -     |   15.05  \n",
      "   2    |   100   |   0.129342   |     -      |     -     |   15.06  \n",
      "   2    |   120   |   0.317956   |     -      |     -     |   15.15  \n",
      "   2    |   140   |   0.195063   |     -      |     -     |   15.16  \n",
      "   2    |   160   |   0.263916   |     -      |     -     |   15.05  \n",
      "   2    |   180   |   0.155028   |     -      |     -     |   15.08  \n",
      "   2    |   200   |   0.304891   |     -      |     -     |   15.11  \n",
      "   2    |   220   |   0.257520   |     -      |     -     |   15.15  \n",
      "   2    |   240   |   0.222513   |     -      |     -     |   15.16  \n",
      "   2    |   260   |   0.286154   |     -      |     -     |   15.13  \n",
      "   2    |   280   |   0.370771   |     -      |     -     |   15.09  \n",
      "   2    |   300   |   0.262345   |     -      |     -     |   15.08  \n",
      "   2    |   320   |   0.263864   |     -      |     -     |   15.08  \n",
      "   2    |   340   |   0.212371   |     -      |     -     |   15.10  \n",
      "   2    |   360   |   0.210808   |     -      |     -     |   15.12  \n",
      "   2    |   380   |   0.323637   |     -      |     -     |   15.10  \n",
      "   2    |   400   |   0.253682   |     -      |     -     |   15.10  \n",
      "   2    |   420   |   0.217628   |     -      |     -     |   15.17  \n",
      "   2    |   440   |   0.341665   |     -      |     -     |   15.16  \n",
      "   2    |   460   |   0.197902   |     -      |     -     |   15.02  \n",
      "   2    |   480   |   0.269368   |     -      |     -     |   15.07  \n",
      "   2    |   500   |   0.244051   |     -      |     -     |   15.19  \n",
      "   2    |   520   |   0.153435   |     -      |     -     |   15.24  \n",
      "   2    |   540   |   0.255450   |     -      |     -     |   15.19  \n",
      "   2    |   560   |   0.212541   |     -      |     -     |   15.07  \n",
      "   2    |   580   |   0.250247   |     -      |     -     |   15.06  \n",
      "   2    |   600   |   0.155493   |     -      |     -     |   15.12  \n",
      "   2    |   620   |   0.299076   |     -      |     -     |   15.14  \n",
      "   2    |   640   |   0.291675   |     -      |     -     |   15.17  \n",
      "   2    |   660   |   0.225295   |     -      |     -     |   15.14  \n",
      "   2    |   674   |   0.290077   |     -      |     -     |   10.60  \n",
      "----------------------------------------------------------------------\n",
      "   2    |    -    |   0.245210   |  0.553890  |   84.50   |  531.62  \n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "FULL_RUN = False # do not change\n",
    "# =======================================\n",
    "# TRAIN MODEL:\n",
    "# =======================================\n",
    "NOW = time.strftime(\"%Y-%m-%d_%H:%M:%S\")\n",
    "\n",
    "valLossList,valAccuList,checkpoint_name = train(bert_classifier, train_dataloader, val_dataloader, epochs=NUM_EPOCHS, evaluation=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecC3GLZis8AI",
   "metadata": {
    "id": "ecC3GLZis8AI"
   },
   "source": [
    "__About the loss function:__ \\\n",
    "The loss funtion used in classification tasks is usually the **Cross-Entropy**. Minimizing this loss function is equivalent to maximizing the log-likelihood.  In python, this function is used as the following: \\\n",
    "\n",
    "- **input**: contains raw, unnormalized scores for each class \\\n",
    "i.e. contains the **logits** which are the outputs of a layer of a neural network before going through the softmax/sigmoid activation function ( = before computing the probability). \\\n",
    "\n",
    "  input has to be a *Tensor* of size: $N \\times C$ where: \\\n",
    "  $N$: size of the batch \\\n",
    "  $C$: number of classes.\n",
    "\n",
    "- **target**: contains the class indices that must be in the range $[0,C[$ so here the class indices must take the values: $0,1,2$\n",
    "\n",
    "  Target has to be a *Tensor* of size $C$\n",
    "\n",
    "- If provided, the optional argument **weight** should be a 1D *Tensor* assigning weight to each of the classes. This is particularly useful when you have an unbalanced training set.\n",
    "\n",
    "Python doc: https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2wFa6eQ7g_e3",
   "metadata": {
    "id": "2wFa6eQ7g_e3"
   },
   "source": [
    "#### c. Get predictions on Validation Set\n",
    "\n",
    "The prediction step is similar to the evaluation step that we did in the training loop, but simpler. We will perform a forward pass to compute logits and apply softmax to calculate probabilities.\n",
    "\n",
    "____________________\n",
    "\n",
    "*Reminder:* In **multi-class** classification each sample is assigned to one and only one label. In **multi-label** case each sample can belong to one or more than one class. \\\n",
    "Here we are in a **multi-class** classification problem.\n",
    "\n",
    "____________________\n",
    "\n",
    "\n",
    "__About the activation function for the last layer:__ \\\n",
    "\n",
    "For the last layer of the neural networks, there is 2 common activation functions:\n",
    "\n",
    "- sigmoid function: $\\sigma(x) = \\frac{1}{1+e^{-x}}$ \\\n",
    "> input domain: $]-\\infty, +\\infty[$ \\\n",
    "> output range: $[0, 1]$ \\\n",
    "\n",
    "  The sigmoid activation function is generally considered for binary classification since its output value is in $[0, 1]$.  \n",
    "  But this function can also be used in multi-label classification where we use sigmoid() instead of softmax() to get the probabilities. \\\n",
    "  In simple binary classification, there’s no big difference between sigmoid() and softmax(), however in case of multi-labels classification, sigmoid allows to deal with non-exclusive labels while softmax deals with exclusive classes.\n",
    "\n",
    "- softmax function: $\\sigma(x)_i = \\frac{e^{x_i}}{\\sum_{j=1}^{K}e^{x_j}}$\n",
    "> input: vector $x$ of $K$ real numbers \\\n",
    "> output: vector of probabilities = probability distribution of $K$ possible outcomes.\n",
    "\n",
    "  This is the activation function that we will use to compute the probabilities.\n",
    "\n",
    "\n",
    "**NOTE:** We will use this activation function for GETTING PREDICTIONS from our model but NOT for TRAINING our model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "WVrzmCpThSMP",
   "metadata": {
    "id": "WVrzmCpThSMP"
   },
   "outputs": [],
   "source": [
    "def bert_predict(model, test_dataloader):\n",
    "    \"\"\"\n",
    "    This function performs a forward pass on the trained BERT model to predict probabilities\n",
    "    on the test set.\n",
    "    ---> output: probs (array): probability for each comment to belong to each class\n",
    "    of size number of comments * number of classes (=3)\n",
    "    \"\"\"\n",
    "    # Put the model into the evaluation mode. The dropout layers are disabled during\n",
    "    # the test time.\n",
    "    model.eval()\n",
    "\n",
    "    all_logits = []\n",
    "\n",
    "    # For each batch in our test set...\n",
    "    for batch in test_dataloader:\n",
    "        # Load batch to GPU\n",
    "        b_input_ids, b_attn_mask = tuple(t.to(device) for t in batch)[:2]\n",
    "\n",
    "        # Compute logits\n",
    "        with torch.no_grad(): #no gradient computation\n",
    "            logits = model(b_input_ids, b_attn_mask)\n",
    "        all_logits.append(logits)\n",
    "    \n",
    "    # Concatenate logits from each batch\n",
    "    all_logits = torch.cat(all_logits, dim=0)\n",
    "\n",
    "    # Apply softmax to calculate probabilities\n",
    "    probs = F.softmax(all_logits, dim=1).cpu().numpy()\n",
    "\n",
    "    return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mbbzuo4ghSUg",
   "metadata": {
    "id": "mbbzuo4ghSUg"
   },
   "outputs": [],
   "source": [
    "# Compute predicted probabilities on the test set\n",
    "probs = bert_predict(bert_classifier, val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "PZIJ28j_nWDt",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "PZIJ28j_nWDt",
    "outputId": "9e2d07ec-9ff7-488a-88d0-5c7e5eb6e102"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'\\nprobs_name = \"\"\\n\\nos.chdir(PATH + \\'/4_ProbsValSet_pkl\\') #go to correct folder \\nprobs = pd.read_pickle(probs_name + \\'.pkl\\')\\n'"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#----- Pickle Probs results for later use \n",
    "os.chdir(PATH + '/4_ProbsValSet_pkl') #go to correct folder \n",
    "pd.DataFrame(probs).to_pickle(NOW + \"_probsVal.pkl\") #pickle dataset\n",
    "os.chdir(PATH) #return to main folder\n",
    "\n",
    "#----- Retrieve Probs results  \n",
    "\"\"\"\n",
    "probs_name = \"\"\n",
    "\n",
    "os.chdir(PATH + '/4_ProbsValSet_pkl') #go to correct folder \n",
    "probs = pd.read_pickle(probs_name + '.pkl')\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3uBROJOR2zlN",
   "metadata": {
    "id": "3uBROJOR2zlN"
   },
   "source": [
    "#### d. Evaluation on Validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "EtYCAVKxlx9i",
   "metadata": {
    "id": "EtYCAVKxlx9i"
   },
   "outputs": [],
   "source": [
    "def predictionRule(probs,rule=1,T=0.5):\n",
    "  \"\"\"\n",
    "  This function computes the final label for our dataset.\n",
    "  ---> input: \n",
    "  - probs (np.array): array of size (nb_comments * 3) containing \n",
    "  the probability that each comment belongs to each class.\n",
    "  - rule (integer): can take values 1 or 2 and indicates\n",
    "  which prediction rule to use.\n",
    "  ---> ouput: \n",
    "  - predLabel (np.array): array of size (nb_comments) containing the \n",
    "  predicted label (positive: 2, neutral: 1, negative: 0) for each comment.\n",
    "  * With rule = 1, the label predicted is the one with the highest probability. \n",
    "  * With rule = 2, the label predicted is also the one with the highest probability.\n",
    "  However, if the absolute difference between the probabilities is < T, \n",
    "  there is confusion between the probabilities and the label is put to 1 (neutral).\n",
    "  \"\"\"\n",
    "\n",
    "  ###### Rule 1 ######\n",
    "  predLabel = np.argmax(probs,axis = 1) \n",
    "  # for the first label prediction,\n",
    "  # the class with the highest probability is predicted\n",
    "  \n",
    "  ###### Rule 2 ######\n",
    "  if rule == 2: \n",
    "    if NUM_LABELS == 3:\n",
    "      diffs = np.array([abs(probs[:,0] - probs[:,1]),\n",
    "                        abs(probs[:,0] - probs[:,2]),\n",
    "                        abs(probs[:,1] - probs[:,2])]).T\n",
    "    elif NUM_LABELS == 2:\n",
    "      diffs = np.array([abs(probs[:,0] - probs[:,1])]).T\n",
    "\n",
    "    # col0: absolute difference between col0 and col1 of probs\n",
    "    # col1: absolute difference between col0 and col2 of probs\n",
    "    # col2: absolute difference between col1 and col2 of probs\n",
    "\n",
    "    toChange = np.all(diffs < T*np.ones((diffs.shape)),axis = 1) \n",
    "    # array containing true for the comments where the absolute difference\n",
    "    # between all 3 probabilities is < T\n",
    "\n",
    "    predLabel[np.where(toChange)] = 1 \n",
    "    # change the label to 1 (neutral) if the absolute difference between the probabilities is < T\n",
    "\n",
    "  return predLabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "IivIrF7svNBM",
   "metadata": {
    "id": "IivIrF7svNBM"
   },
   "outputs": [],
   "source": [
    "def evaluate_perf(probs,y_true,rule=1,T=0.5):\n",
    "  \"\"\"\n",
    "  This function evaluates the BERT classifier\n",
    "  ---> input:\n",
    "  - probs (np.array): probabilities of each comment belonging to each class \n",
    "  (output of bert prediction) of size number of comments * number of classes\n",
    "  - y_true (np.array): true labels \n",
    "  ---> output:\n",
    "  - y_pred (np.array) : predictions of the model: the class with the \n",
    "  highest probability is predicted\n",
    "  - crossT (dataframe): contigency table\n",
    "  - accuracy (scalar): accuracy of the prediction. The closer this value is to 1, the better the model.\n",
    "  - f1 (scalar): f1-score of the predictions. The closer this value is to 1, the better the model.\n",
    "  \"\"\"\n",
    "\n",
    "  #y_pred = np.argmax(probs,axis = 1) # the class with the highest probability is predicted\n",
    "  y_pred = predictionRule(probs,rule,T) # get the predicted labels\n",
    "\n",
    "  # put results into a dataFrame\n",
    "  dfResult = pd.DataFrame(y_pred); dfResult\n",
    "  dfResult.rename(columns = {0 : \"Prediction\"},inplace = True)\n",
    "  dfResult[\"True_label\"] = y_true\n",
    "  \n",
    "  # computation of the contigency table\n",
    "  crossT = pd.crosstab(index=dfResult[\"Prediction\"], columns=dfResult[\"True_label\"])\n",
    "\n",
    "  # computation of the accuracy\n",
    "  accuracy = accuracy_score(y_true, y_pred)\n",
    "  print(f'Accuracy: {accuracy*100:.2f}%')\n",
    "  \n",
    "  # computation of the f1-score\n",
    "  f1Score = f1_score(dfResult[\"True_label\"], dfResult[\"Prediction\"],average='macro')\n",
    "  print(f'F1-Score: {f1Score*100:.2f}%')\n",
    "\n",
    "  return y_pred, crossT, accuracy, f1Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bVysUzjvcOO",
   "metadata": {
    "id": "8bVysUzjvcOO"
   },
   "outputs": [],
   "source": [
    "# Evaluate the Bert classifier with the prediction rule 1\n",
    "#---------------------------------------------------------\n",
    "print(\"Evaluation of the Bert classifier with prediction rule 1:\")\n",
    "y_pred_val, crossT, accuracy_val, f1Score_val = evaluate_perf(probs,y_val)\n",
    "crossT_val = crossT.to_numpy().tolist() #convert crossT to list format for later use \n",
    "print(\"\\nContigency Table:\")\n",
    "crossT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e_IL659fxc2t",
   "metadata": {
    "id": "e_IL659fxc2t"
   },
   "outputs": [],
   "source": [
    "# Evaluate the Bert classifier with the prediction rule 2\n",
    "#---------------------------------------------------------\n",
    "def computeBest_T(T_grid,probs,y_val):\n",
    "  \"\"\"\n",
    "  This function computes the best threshold in the function \"predictionRule\" \n",
    "  with the rule 2. The best threshold is the one giving the highest Accuracy\n",
    "  and F1-Score in the function \"evaluate_perf\".\n",
    "  ---> input:\n",
    "  - T_grif (list): containing th thresholds to test\n",
    "  ---> ouput:\n",
    "  - best_T (float): value of the best threshold. \n",
    "  \"\"\"\n",
    "\n",
    "  accuracy_grid = [] # list containing the Accuracy for each trehshold in T_grid\n",
    "  F1Score_grid  = [] # list containing the F1-score for each trehshold in T_grid\n",
    "\n",
    "  for t in T_grid:\n",
    "    print(\"threshold: \", t)\n",
    "    a,b,accuracy_val_2, f1Score_val_2 = evaluate_perf(probs,y_val,rule=2,T=t)\n",
    "    print(\"\")\n",
    "    accuracy_grid.append(accuracy_val_2)\n",
    "    F1Score_grid.append(f1Score_val_2)\n",
    "\n",
    "  accuracy_grid = np.array(accuracy_grid)\n",
    "  F1Score_grid  = np.array(F1Score_grid)\n",
    "\n",
    "  best_T_Acc = np.argmax(accuracy_grid)\n",
    "  best_T_F1 = np.argmax(F1Score_grid)\n",
    "  return (T_grid[best_T_Acc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0WC0z3x6ccvN",
   "metadata": {
    "id": "0WC0z3x6ccvN"
   },
   "outputs": [],
   "source": [
    "T_grid = [.1,.2,.3,.4,.5,.6,.7,.8,.9] # grid of thresholds for the prediction rule 2 \n",
    "BEST_T = computeBest_T(T_grid,probs,y_val)\n",
    "print(\"BEST_T: \", BEST_T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "M5_COdlU1VXD",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "id": "M5_COdlU1VXD",
    "outputId": "06d648ba-7cf9-4433-9ef0-95c3282f246e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation of the Bert classifier with prediction rule 2 using the Best Threshold:\n",
      "Accuracy: 84.83%\n",
      "F1-Score: 84.43%\n",
      "\n",
      "Contigency Table:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-1384b497-b1db-44ea-89e0-40819a39fcdc\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>True_label</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Prediction</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>303</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>48</td>\n",
       "      <td>206</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1384b497-b1db-44ea-89e0-40819a39fcdc')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-1384b497-b1db-44ea-89e0-40819a39fcdc button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-1384b497-b1db-44ea-89e0-40819a39fcdc');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "True_label    0    1\n",
       "Prediction          \n",
       "0           303   43\n",
       "1            48  206"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the Bert classifier with the prediction rule 2 \n",
    "# using the Best Threshold found with function \"computeBest_T\"\n",
    "#---------------------------------------------------------\n",
    "print(\"Evaluation of the Bert classifier with prediction rule 2 using the Best Threshold:\")\n",
    "y_pred_val_2, crossT_2, accuracy_val_2, f1Score_val_2 = evaluate_perf(probs,y_val,rule=2,T=BEST_T)\n",
    "crossT_val_2 = crossT_2.to_numpy().tolist() #convert crossT_2 to list format for later use \n",
    "print(\"\\nContigency Table:\")\n",
    "crossT_2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9mZie3wxZNh",
   "metadata": {
    "id": "d9mZie3wxZNh"
   },
   "source": [
    "<font color = \"green\"> __You can know jump to section 4.7 and run the cell to save the parameters in an excel file.__ </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "qkPqG_1boWmQ",
   "metadata": {
    "id": "qkPqG_1boWmQ"
   },
   "source": [
    "__Description of the metrics used:__\n",
    "\n",
    "- The __accuracy score__:  accuracy_score computes the accuracy of correct predictions as follows: \n",
    "$$ \\text{accuracy}(y,\\hat y) = \\frac{1}{n_{\\text{samples}}} \\sum_{i=0}^{n_{\\text{samples}} -1} 1_{\\hat y_i = y_i} $$\n",
    "\n",
    "  where $\\hat y_i $ is the predicted value of the $i$-th sample and $y_i$ is the corresponding true value. \\\n",
    "  **This is the same metric as the Purity metric.** \\\n",
    "  The closer the accuracy is to 1, the better the model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9MybT_oi2dFa",
   "metadata": {
    "id": "9MybT_oi2dFa"
   },
   "source": [
    "### 4.6. Train model on the entire training data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vXnXJbqobFpf",
   "metadata": {
    "id": "vXnXJbqobFpf"
   },
   "source": [
    "Concatenate train set and validation set: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "RR7dx9NcjeBV",
   "metadata": {
    "id": "RR7dx9NcjeBV"
   },
   "outputs": [],
   "source": [
    "# Concatenate the train set and the test set\n",
    "full_train_data = torch.utils.data.ConcatDataset([train_data, val_data])\n",
    "full_train_sampler = RandomSampler(full_train_data)\n",
    "full_train_dataloader = DataLoader(full_train_data, sampler=full_train_sampler, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cP8FJedyz22q",
   "metadata": {
    "id": "cP8FJedyz22q"
   },
   "outputs": [],
   "source": [
    "#----- Save dataloader for later use\n",
    "os.chdir(PATH + '/3_DataLoader_pt') #go to correct folder \n",
    "torch.save(full_train_dataloader, NOW + \"_full_train_dataloader.pt\")\n",
    "os.chdir(PATH) #return to main folder "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "_wRmRnGoa-Wm",
   "metadata": {
    "id": "_wRmRnGoa-Wm"
   },
   "source": [
    "#### a. Initialise model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "PhqO8BfMbdTF",
   "metadata": {
    "id": "PhqO8BfMbdTF"
   },
   "source": [
    "##### a.1 Initialise new model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "huV6sF7YburY",
   "metadata": {
    "id": "huV6sF7YburY"
   },
   "outputs": [],
   "source": [
    "RESUME = False; CKP_NAME=\"\"; PHASE = 1 #do not change\n",
    "# =======================================\n",
    "# INITIALISE MODEL:\n",
    "# =======================================\n",
    "NUM_EPOCHS = 2\n",
    "\n",
    "#-- indicate the parameters in the AdamW optimizer\n",
    "EPS = 1e-8 # Default epsilon value in AdamW optimizer\n",
    "LR = 5e-5  # Default learning rate in AdamW optimizer \n",
    "#-- Set seed for reproducibility\n",
    "set_seed(42)   \n",
    "\n",
    "bert_classifier, optimizer, scheduler = initialize_model(full_train_dataloader,epochs=NUM_EPOCHS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "VuBaaZEjbyRc",
   "metadata": {
    "id": "VuBaaZEjbyRc"
   },
   "source": [
    "##### a.2. Initialise with resumed model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mON6iAVWb6Pi",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mON6iAVWb6Pi",
    "outputId": "a8c36033-a7f8-417c-e40f-888975696e18"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resumed model operational for further training.\n",
      "This model has already been trained with 2 epochs.\n"
     ]
    }
   ],
   "source": [
    "RESUME = True; FULL_RUN = True; PHASE = 1  #do not change\n",
    "# =======================================\n",
    "# RESUME MODEL:\n",
    "# =======================================\n",
    "# To do this, make sure to run the code in the sections:\n",
    "# 1\n",
    "# 2.1\n",
    "# 3\n",
    "# 4.4  /.\\ Beware to put the correct NUM_LABELS /.\\\n",
    "\n",
    "#----- Make sure that the DATES in the names below are the SAME: \n",
    "#-- name of the full_train_dataloader to resume:\n",
    "full_train_dataloader_name = \"2022-08-18_10:50:40_full_train_dataloader\"\n",
    "#-- name of the fine-tuned to resume:\n",
    "CKP_NAME = \"2022-08-18_10:50:40_full_checkpoint\"\n",
    "\n",
    "#-- indicate the number of epochs to make in the next training:\n",
    "NUM_EPOCHS = 2\n",
    "\n",
    "#-- indicate the parameters in the AdamW optimizer\n",
    "EPS = 1e-8 # Default epsilon value in AdamW optimizer\n",
    "LR = 5e-5  # Default learning rate in AdamW optimizer \n",
    "\n",
    "#-- Redefine some global variables if not already defined: \n",
    "BERT_MODEL_NAME = 'bert-base-uncased'\n",
    "\n",
    "#----- Load full_train_dataloader\n",
    "os.chdir(PATH + '/3_DataLoader_pt/bestModels/') #go to correct folder \n",
    "full_train_dataloader = torch.load(full_train_dataloader_name + \".pt\",map_location=device) #load info\n",
    "os.chdir(PATH) #return to main folder \n",
    "\n",
    "#----- Initlialize the model with resumed fine-tuned BERT model \n",
    "bert_classifier, optimizer, scheduler = initialize_model(\n",
    "      full_train_dataloader, epochs = NUM_EPOCHS ,resume_training = True,\n",
    "      ckp_path = PATH + '/5_Checkpoints_pt/bestModels/' + CKP_NAME + \".pt\",lr=LR,eps=EPS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1MDcE7J5dH0a",
   "metadata": {
    "id": "1MDcE7J5dH0a"
   },
   "source": [
    "####b. Train model on full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Dh1ipO9wdIKg",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Dh1ipO9wdIKg",
    "outputId": "6b3effaf-6224-40d2-cc82-8e9d8c9ac9cb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training...\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:155: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha) (Triggered internally at  ../torch/csrc/utils/python_arg_parser.cpp:1174.)\n",
      "  exp_avg.mul_(beta1).add_(1.0 - beta1, grad)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   1    |   20    |   0.660482   |     -      |     -     |   17.15  \n",
      "   1    |   40    |   0.596399   |     -      |     -     |   14.10  \n",
      "   1    |   60    |   0.471309   |     -      |     -     |   14.28  \n",
      "   1    |   80    |   0.542923   |     -      |     -     |   14.51  \n",
      "   1    |   100   |   0.443108   |     -      |     -     |   14.67  \n",
      "   1    |   120   |   0.313707   |     -      |     -     |   14.97  \n",
      "   1    |   140   |   0.444618   |     -      |     -     |   15.11  \n",
      "   1    |   160   |   0.362100   |     -      |     -     |   15.36  \n",
      "   1    |   180   |   0.485692   |     -      |     -     |   15.63  \n",
      "   1    |   200   |   0.448361   |     -      |     -     |   15.75  \n",
      "   1    |   220   |   0.484856   |     -      |     -     |   15.62  \n",
      "   1    |   240   |   0.358605   |     -      |     -     |   15.50  \n",
      "   1    |   260   |   0.402628   |     -      |     -     |   15.55  \n",
      "   1    |   280   |   0.431899   |     -      |     -     |   15.66  \n",
      "   1    |   300   |   0.325527   |     -      |     -     |   15.66  \n",
      "   1    |   320   |   0.560612   |     -      |     -     |   15.69  \n",
      "   1    |   340   |   0.450054   |     -      |     -     |   15.68  \n",
      "   1    |   360   |   0.354477   |     -      |     -     |   15.58  \n",
      "   1    |   380   |   0.462620   |     -      |     -     |   15.59  \n",
      "   1    |   400   |   0.365359   |     -      |     -     |   15.57  \n",
      "   1    |   420   |   0.463800   |     -      |     -     |   15.60  \n",
      "   1    |   440   |   0.409478   |     -      |     -     |   15.59  \n",
      "   1    |   460   |   0.443026   |     -      |     -     |   15.59  \n",
      "   1    |   480   |   0.298492   |     -      |     -     |   15.64  \n",
      "   1    |   500   |   0.359006   |     -      |     -     |   15.56  \n",
      "   1    |   520   |   0.475109   |     -      |     -     |   15.60  \n",
      "   1    |   540   |   0.338818   |     -      |     -     |   15.62  \n",
      "   1    |   560   |   0.306357   |     -      |     -     |   15.59  \n",
      "   1    |   580   |   0.373322   |     -      |     -     |   15.64  \n",
      "   1    |   600   |   0.501999   |     -      |     -     |   15.62  \n",
      "   1    |   620   |   0.344023   |     -      |     -     |   15.61  \n",
      "   1    |   640   |   0.395002   |     -      |     -     |   15.64  \n",
      "   1    |   660   |   0.394742   |     -      |     -     |   15.61  \n",
      "   1    |   680   |   0.420919   |     -      |     -     |   15.65  \n",
      "   1    |   700   |   0.492162   |     -      |     -     |   15.65  \n",
      "   1    |   720   |   0.385597   |     -      |     -     |   15.61  \n",
      "   1    |   740   |   0.511198   |     -      |     -     |   15.62  \n",
      "   1    |   760   |   0.383003   |     -      |     -     |   15.62  \n",
      "   1    |   780   |   0.467282   |     -      |     -     |   15.57  \n",
      "   1    |   800   |   0.341385   |     -      |     -     |   15.70  \n",
      "   1    |   820   |   0.420532   |     -      |     -     |   15.64  \n",
      "   1    |   840   |   0.353875   |     -      |     -     |   15.60  \n",
      "   1    |   860   |   0.342620   |     -      |     -     |   15.56  \n",
      "   1    |   880   |   0.690864   |     -      |     -     |   15.62  \n",
      "   1    |   900   |   0.375811   |     -      |     -     |   15.57  \n",
      "   1    |   920   |   0.490609   |     -      |     -     |   15.61  \n",
      "   1    |   940   |   0.334808   |     -      |     -     |   15.56  \n",
      "   1    |   960   |   0.367214   |     -      |     -     |   15.59  \n",
      "   1    |   980   |   0.387523   |     -      |     -     |   15.62  \n",
      "   1    |  1000   |   0.321326   |     -      |     -     |   15.59  \n",
      "   1    |  1020   |   0.379515   |     -      |     -     |   15.57  \n",
      "   1    |  1040   |   0.306723   |     -      |     -     |   15.59  \n",
      "   1    |  1060   |   0.451590   |     -      |     -     |   15.66  \n",
      "   1    |  1080   |   0.431487   |     -      |     -     |   15.64  \n",
      "   1    |  1100   |   0.377537   |     -      |     -     |   15.61  \n",
      "   1    |  1120   |   0.355635   |     -      |     -     |   15.57  \n",
      "   1    |  1140   |   0.361348   |     -      |     -     |   15.63  \n",
      "   1    |  1160   |   0.428108   |     -      |     -     |   15.62  \n",
      "   1    |  1180   |   0.391675   |     -      |     -     |   15.59  \n",
      "   1    |  1200   |   0.421083   |     -      |     -     |   15.57  \n",
      "   1    |  1220   |   0.436112   |     -      |     -     |   15.66  \n",
      "   1    |  1240   |   0.376901   |     -      |     -     |   15.56  \n",
      "   1    |  1260   |   0.406887   |     -      |     -     |   15.61  \n",
      "   1    |  1280   |   0.331824   |     -      |     -     |   15.58  \n",
      "   1    |  1300   |   0.391148   |     -      |     -     |   15.61  \n",
      "   1    |  1320   |   0.261559   |     -      |     -     |   15.64  \n",
      "   1    |  1340   |   0.403902   |     -      |     -     |   15.64  \n",
      "   1    |  1360   |   0.384516   |     -      |     -     |   15.63  \n",
      "   1    |  1380   |   0.430135   |     -      |     -     |   15.66  \n",
      "   1    |  1400   |   0.549256   |     -      |     -     |   15.61  \n",
      "   1    |  1420   |   0.228438   |     -      |     -     |   15.63  \n",
      "   1    |  1440   |   0.399053   |     -      |     -     |   15.60  \n",
      "   1    |  1460   |   0.360156   |     -      |     -     |   15.59  \n",
      "   1    |  1480   |   0.398827   |     -      |     -     |   15.61  \n",
      "   1    |  1500   |   0.350128   |     -      |     -     |   15.57  \n",
      "   1    |  1520   |   0.281670   |     -      |     -     |   15.61  \n",
      "   1    |  1540   |   0.318531   |     -      |     -     |   15.61  \n",
      "   1    |  1560   |   0.269696   |     -      |     -     |   15.59  \n",
      "   1    |  1580   |   0.574571   |     -      |     -     |   15.63  \n",
      "   1    |  1600   |   0.395326   |     -      |     -     |   15.61  \n",
      "   1    |  1620   |   0.311344   |     -      |     -     |   15.63  \n",
      "   1    |  1640   |   0.318043   |     -      |     -     |   15.62  \n",
      "   1    |  1660   |   0.431998   |     -      |     -     |   15.64  \n",
      "   1    |  1680   |   0.357147   |     -      |     -     |   15.61  \n",
      "   1    |  1700   |   0.311524   |     -      |     -     |   15.66  \n",
      "   1    |  1720   |   0.342403   |     -      |     -     |   15.58  \n",
      "   1    |  1740   |   0.296374   |     -      |     -     |   15.60  \n",
      "   1    |  1760   |   0.422933   |     -      |     -     |   15.63  \n",
      "   1    |  1780   |   0.460343   |     -      |     -     |   15.60  \n",
      "   1    |  1800   |   0.349731   |     -      |     -     |   15.64  \n",
      "   1    |  1820   |   0.295340   |     -      |     -     |   15.60  \n",
      "   1    |  1840   |   0.263819   |     -      |     -     |   15.57  \n",
      "   1    |  1860   |   0.342283   |     -      |     -     |   15.61  \n",
      "   1    |  1880   |   0.463659   |     -      |     -     |   15.58  \n",
      "   1    |  1900   |   0.367883   |     -      |     -     |   15.60  \n",
      "   1    |  1920   |   0.319157   |     -      |     -     |   15.57  \n",
      "   1    |  1940   |   0.389751   |     -      |     -     |   15.56  \n",
      "   1    |  1960   |   0.496273   |     -      |     -     |   15.59  \n",
      "   1    |  1980   |   0.278796   |     -      |     -     |   15.59  \n",
      "   1    |  2000   |   0.269059   |     -      |     -     |   15.55  \n",
      "   1    |  2020   |   0.338671   |     -      |     -     |   15.62  \n",
      "   1    |  2040   |   0.396327   |     -      |     -     |   15.61  \n",
      "   1    |  2060   |   0.332525   |     -      |     -     |   15.58  \n",
      "   1    |  2080   |   0.283714   |     -      |     -     |   15.58  \n",
      "   1    |  2100   |   0.408192   |     -      |     -     |   15.54  \n",
      "   1    |  2120   |   0.396179   |     -      |     -     |   15.57  \n",
      "   1    |  2140   |   0.354676   |     -      |     -     |   15.61  \n",
      "   1    |  2160   |   0.358408   |     -      |     -     |   15.58  \n",
      "   1    |  2180   |   0.308688   |     -      |     -     |   15.62  \n",
      "   1    |  2200   |   0.401034   |     -      |     -     |   15.59  \n",
      "   1    |  2220   |   0.277833   |     -      |     -     |   15.57  \n",
      "   1    |  2240   |   0.399803   |     -      |     -     |   15.57  \n",
      "   1    |  2249   |   0.348772   |     -      |     -     |   7.02   \n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
      "----------------------------------------------------------------------\n",
      "   2    |   20    |   0.147188   |     -      |     -     |   16.34  \n",
      "   2    |   40    |   0.240587   |     -      |     -     |   15.86  \n",
      "   2    |   60    |   0.341694   |     -      |     -     |   15.74  \n",
      "   2    |   80    |   0.250373   |     -      |     -     |   15.55  \n",
      "   2    |   100   |   0.245302   |     -      |     -     |   15.48  \n",
      "   2    |   120   |   0.245853   |     -      |     -     |   15.53  \n",
      "   2    |   140   |   0.149771   |     -      |     -     |   15.65  \n",
      "   2    |   160   |   0.319039   |     -      |     -     |   15.68  \n",
      "   2    |   180   |   0.278974   |     -      |     -     |   15.62  \n",
      "   2    |   200   |   0.158510   |     -      |     -     |   15.59  \n",
      "   2    |   220   |   0.329468   |     -      |     -     |   15.56  \n",
      "   2    |   240   |   0.172502   |     -      |     -     |   15.64  \n",
      "   2    |   260   |   0.186645   |     -      |     -     |   15.59  \n",
      "   2    |   280   |   0.273587   |     -      |     -     |   15.63  \n",
      "   2    |   300   |   0.228293   |     -      |     -     |   15.65  \n",
      "   2    |   320   |   0.330938   |     -      |     -     |   15.68  \n",
      "   2    |   340   |   0.243181   |     -      |     -     |   15.62  \n",
      "   2    |   360   |   0.272645   |     -      |     -     |   15.64  \n",
      "   2    |   380   |   0.269761   |     -      |     -     |   15.63  \n",
      "   2    |   400   |   0.241952   |     -      |     -     |   15.65  \n",
      "   2    |   420   |   0.298222   |     -      |     -     |   15.62  \n",
      "   2    |   440   |   0.287176   |     -      |     -     |   15.57  \n",
      "   2    |   460   |   0.269555   |     -      |     -     |   15.64  \n",
      "   2    |   480   |   0.145252   |     -      |     -     |   15.58  \n",
      "   2    |   500   |   0.174334   |     -      |     -     |   15.56  \n",
      "   2    |   520   |   0.186474   |     -      |     -     |   15.59  \n",
      "   2    |   540   |   0.167721   |     -      |     -     |   15.57  \n",
      "   2    |   560   |   0.239440   |     -      |     -     |   15.59  \n",
      "   2    |   580   |   0.227083   |     -      |     -     |   15.57  \n",
      "   2    |   600   |   0.265648   |     -      |     -     |   15.57  \n",
      "   2    |   620   |   0.233954   |     -      |     -     |   15.61  \n",
      "   2    |   640   |   0.252720   |     -      |     -     |   15.59  \n",
      "   2    |   660   |   0.240591   |     -      |     -     |   15.60  \n",
      "   2    |   680   |   0.191982   |     -      |     -     |   15.62  \n",
      "   2    |   700   |   0.185000   |     -      |     -     |   15.58  \n",
      "   2    |   720   |   0.286623   |     -      |     -     |   15.56  \n",
      "   2    |   740   |   0.238057   |     -      |     -     |   15.56  \n",
      "   2    |   760   |   0.164260   |     -      |     -     |   15.59  \n",
      "   2    |   780   |   0.119085   |     -      |     -     |   15.59  \n",
      "   2    |   800   |   0.205125   |     -      |     -     |   15.58  \n",
      "   2    |   820   |   0.319730   |     -      |     -     |   15.60  \n",
      "   2    |   840   |   0.090903   |     -      |     -     |   15.57  \n",
      "   2    |   860   |   0.193100   |     -      |     -     |   15.59  \n",
      "   2    |   880   |   0.195168   |     -      |     -     |   15.59  \n",
      "   2    |   900   |   0.060224   |     -      |     -     |   15.58  \n",
      "   2    |   920   |   0.260251   |     -      |     -     |   15.62  \n",
      "   2    |   940   |   0.282358   |     -      |     -     |   15.65  \n",
      "   2    |   960   |   0.279959   |     -      |     -     |   15.65  \n",
      "   2    |   980   |   0.302303   |     -      |     -     |   15.58  \n",
      "   2    |  1000   |   0.220493   |     -      |     -     |   15.65  \n",
      "   2    |  1020   |   0.113722   |     -      |     -     |   15.64  \n",
      "   2    |  1040   |   0.150211   |     -      |     -     |   15.64  \n",
      "   2    |  1060   |   0.190440   |     -      |     -     |   15.65  \n",
      "   2    |  1080   |   0.176346   |     -      |     -     |   15.57  \n",
      "   2    |  1100   |   0.164935   |     -      |     -     |   15.61  \n",
      "   2    |  1120   |   0.160454   |     -      |     -     |   15.55  \n",
      "   2    |  1140   |   0.369770   |     -      |     -     |   15.58  \n",
      "   2    |  1160   |   0.158469   |     -      |     -     |   15.60  \n",
      "   2    |  1180   |   0.253839   |     -      |     -     |   15.66  \n",
      "   2    |  1200   |   0.187125   |     -      |     -     |   15.64  \n",
      "   2    |  1220   |   0.201600   |     -      |     -     |   15.65  \n",
      "   2    |  1240   |   0.191095   |     -      |     -     |   15.62  \n",
      "   2    |  1260   |   0.202731   |     -      |     -     |   15.59  \n",
      "   2    |  1280   |   0.166666   |     -      |     -     |   15.62  \n",
      "   2    |  1300   |   0.277532   |     -      |     -     |   15.62  \n",
      "   2    |  1320   |   0.197114   |     -      |     -     |   15.65  \n",
      "   2    |  1340   |   0.294121   |     -      |     -     |   15.69  \n",
      "   2    |  1360   |   0.271590   |     -      |     -     |   15.64  \n",
      "   2    |  1380   |   0.158024   |     -      |     -     |   15.61  \n",
      "   2    |  1400   |   0.358409   |     -      |     -     |   15.59  \n",
      "   2    |  1420   |   0.347763   |     -      |     -     |   15.60  \n",
      "   2    |  1440   |   0.351566   |     -      |     -     |   15.56  \n",
      "   2    |  1460   |   0.337154   |     -      |     -     |   15.56  \n",
      "   2    |  1480   |   0.206626   |     -      |     -     |   15.57  \n",
      "   2    |  1500   |   0.240799   |     -      |     -     |   15.53  \n",
      "   2    |  1520   |   0.165417   |     -      |     -     |   15.62  \n",
      "   2    |  1540   |   0.185440   |     -      |     -     |   15.60  \n",
      "   2    |  1560   |   0.327249   |     -      |     -     |   15.58  \n",
      "   2    |  1580   |   0.221395   |     -      |     -     |   15.62  \n",
      "   2    |  1600   |   0.182906   |     -      |     -     |   15.59  \n",
      "   2    |  1620   |   0.163680   |     -      |     -     |   15.62  \n",
      "   2    |  1640   |   0.285058   |     -      |     -     |   15.61  \n",
      "   2    |  1660   |   0.229894   |     -      |     -     |   15.61  \n",
      "   2    |  1680   |   0.152010   |     -      |     -     |   15.63  \n",
      "   2    |  1700   |   0.163871   |     -      |     -     |   15.65  \n",
      "   2    |  1720   |   0.201541   |     -      |     -     |   15.60  \n",
      "   2    |  1740   |   0.293848   |     -      |     -     |   15.56  \n",
      "   2    |  1760   |   0.149775   |     -      |     -     |   15.57  \n",
      "   2    |  1780   |   0.089520   |     -      |     -     |   15.62  \n",
      "   2    |  1800   |   0.194730   |     -      |     -     |   15.57  \n",
      "   2    |  1820   |   0.284833   |     -      |     -     |   15.60  \n",
      "   2    |  1840   |   0.236528   |     -      |     -     |   15.60  \n",
      "   2    |  1860   |   0.212217   |     -      |     -     |   15.60  \n",
      "   2    |  1880   |   0.192857   |     -      |     -     |   15.55  \n",
      "   2    |  1900   |   0.340495   |     -      |     -     |   15.60  \n",
      "   2    |  1920   |   0.176412   |     -      |     -     |   15.61  \n",
      "   2    |  1940   |   0.430142   |     -      |     -     |   15.60  \n",
      "   2    |  1960   |   0.164400   |     -      |     -     |   15.58  \n",
      "   2    |  1980   |   0.305309   |     -      |     -     |   15.57  \n",
      "   2    |  2000   |   0.289232   |     -      |     -     |   15.56  \n",
      "   2    |  2020   |   0.192481   |     -      |     -     |   15.58  \n",
      "   2    |  2040   |   0.285157   |     -      |     -     |   15.62  \n",
      "   2    |  2060   |   0.143571   |     -      |     -     |   15.56  \n",
      "   2    |  2080   |   0.277106   |     -      |     -     |   15.59  \n",
      "   2    |  2100   |   0.239474   |     -      |     -     |   15.59  \n",
      "   2    |  2120   |   0.306153   |     -      |     -     |   15.54  \n",
      "   2    |  2140   |   0.111170   |     -      |     -     |   15.59  \n",
      "   2    |  2160   |   0.151698   |     -      |     -     |   15.58  \n",
      "   2    |  2180   |   0.233341   |     -      |     -     |   15.55  \n",
      "   2    |  2200   |   0.290871   |     -      |     -     |   15.58  \n",
      "   2    |  2220   |   0.186105   |     -      |     -     |   15.60  \n",
      "   2    |  2240   |   0.163252   |     -      |     -     |   15.60  \n",
      "   2    |  2249   |   0.198729   |     -      |     -     |   7.02   \n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "FULL_RUN = True  #do not change\n",
    "# =======================================\n",
    "# TRAIN MODEL:\n",
    "# =======================================\n",
    "NOW = time.strftime(\"%Y-%m-%d_%H:%M:%S\")    \n",
    "          \n",
    "LossList,AccuList,checkpoint_name = train(bert_classifier, full_train_dataloader, epochs=NUM_EPOCHS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nJmU12HOi_HP",
   "metadata": {
    "id": "nJmU12HOi_HP"
   },
   "source": [
    "### 4.7. <font color = \"red\" > Second fine-tuning on dashboardLabel\n",
    "> used to fine-tune again our model on 200 labeled comments from the dasboard data. These comments are *different* from the ones in miniLabel dataset wich we will use to evaluate our model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3j16xT2knp6",
   "metadata": {
    "id": "a3j16xT2knp6"
   },
   "source": [
    "#### a. Download & formats dashbordLabel dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "iA4R12MIjKhH",
   "metadata": {
    "id": "iA4R12MIjKhH"
   },
   "outputs": [],
   "source": [
    "# Work on the dashbordLabel dataset\n",
    "#---------------------------------------------\n",
    "# Download the dashbordLabel dataset\n",
    "os.chdir(PATH)\n",
    "data2 = pd.read_excel(\"data/dashbordLabel.xlsx\")\n",
    "\n",
    "# Clean the dataframe and assign correct type  \n",
    "data2.index = data2[\"Unnamed: 0\"].astype(int)\n",
    "data2.index.name = None\n",
    "data2.drop(\"Unnamed: 0\", axis = 1, inplace = True)\n",
    "data2[\"label\"] = data2[\"label\"].astype(int)\n",
    "data2[\"label\"]=pd.Categorical(data2[\"label\"],ordered=False) \n",
    "data2.drop (\"progress\", axis = 1, inplace = True)\n",
    "\n",
    "NAMES = \"dashbordLabel\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "JYm_Y0aBR4gI",
   "metadata": {
    "id": "JYm_Y0aBR4gI"
   },
   "source": [
    "We now have a \"dashbordLabel\" dataset which contains 200 labeled comments. \n",
    "\n",
    "We loaded the model that gave the best results on the \"miniLabel\" dataset (which we will call *bestModel*) in the case of 2 and 3 labels and resumed the training for a second fine-tuning but this time on the \"dashbordLabel\" dataset. \n",
    "\n",
    "It turns out that whatever the number of epochs used in the second fine-tuning (2,4,10,20 epochs) the results were not different from those of the first fine-tuning with the *bestModel*: the probabilities were exactly identical.\n",
    "This is because the number of comments on which we did the 2nd fine-tuning was too small (only 200 comments). \n",
    "\n",
    "We therefore decided to duplicate the \"dashbordLabel\" dataset several times by concatenating the same dataset several times and then shuffling it. \n",
    "\n",
    "With a fixed number of epochs: (2 epochs)\n",
    "\n",
    "- With a LR of 5e-2, the model overfitted and each row of the probability matrix was identical.\n",
    "\n",
    "- We then thought of using a much smaller learning rate than normal so that we do not wash away the weights learned on the old data. With a LR of 5e-10, the probabilities were very close to those obtained with the 1st *bestModel* fine-tuning and so the predictions were the same. The LR was too small and the model did not update the parameters enough.\n",
    "\n",
    "- Finally, a LR of 5e-5 (as recommended in the bert-paper) provided different probabilities and improved predictions.\n",
    "\n",
    "To be tested:\n",
    "- play with the LR but always staying within the 3 LR proposed by the bert paper. **DONE**\n",
    "- play with the number of epochs **DONE**\n",
    "- instead of concatenating copies of \"dashbordLabel\", try simple data-augmentation methods. See if it improves the results or not, for the same number of comments in data2\n",
    "- increase/decrease the size of data2 and see what is better. **DONE** (increase)\n",
    "- try to do a single fine-tuning by integrating \"dashbordLabel\" (several times duplicated or increased) to the Kaggle datasets and see if it improves the results \n",
    "\n",
    "\n",
    "Could also see: can you weight observations in a neural network?\n",
    "https://stats.stackexchange.com/questions/326532/can-you-weight-observations-in-a-neural-network\n",
    "\n",
    "https://machinelearningmastery.com/update-neural-network-models-with-more-data/ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e_Fyvd0_DoFQ",
   "metadata": {
    "id": "e_Fyvd0_DoFQ"
   },
   "source": [
    "#### b. Augment dataset\n",
    "\n",
    "Since the size of \"dashbordLabel\" is too small to make a difference in the 2nd fine-tuning, we must increase its size."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "JBNmz2aLDuun",
   "metadata": {
    "id": "JBNmz2aLDuun"
   },
   "source": [
    "##### <font color = 'red'> **Method 1:** </font> Concatenate several copies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "KxrpX6HCjCzD",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KxrpX6HCjCzD",
    "outputId": "f6a77b39-e1f8-4863-87f8-07d4718a07cc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIX:  7 copies of the 200 comments of dashbordLabel = 1400 comments\n"
     ]
    }
   ],
   "source": [
    "NUM_COPIES = 5 #number of copies of \"data2\" to make\n",
    "\n",
    "MIX = str(NUM_COPIES) + \" copies of the {} comments of dashbordLabel = {} comments\".format(len(data2),NUM_COPIES*len(data2))\n",
    "print(\"MIX: \",MIX)\n",
    "\n",
    "data2 = pd.concat([data2]*NUM_COPIES, axis=0) #concatenate all copies of \"data2\"\n",
    "data2 = shuffle(data2) #shuffle dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "NtgUbQ5tDyY7",
   "metadata": {
    "id": "NtgUbQ5tDyY7"
   },
   "source": [
    "##### <font color = 'red'> **Method 2:** </font> Text Data Augmentation\n",
    "\n",
    "\n",
    "\n",
    "Documentation: for text data augmentation for sentiment analysis (we have to make sure that the augmentation does not change the main sentiment of the texts)\n",
    "\n",
    "- https://computationalsocialnetworks.springeropen.com/track/pdf/10.1186/s40649-020-00080-x.pdf\n",
    "\n",
    "- https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9543519&casa_token=EnD1Wh4tj90AAAAA:KcT6IIJj8O73B8ZIVc0LVk10aj_K2DgVUD0vgbi5Yi7TjxI9O9gH492UDcC0gDD_9BlyFNAuafiD (best paper)\n",
    "\n",
    "- https://github.com/makcedward/nlpaug#augmenter (github repo)\n",
    "\n",
    "=> **conclusion of these papers**: USE **BT (back-translation)** for data augmentation in the case of **small** and **imbalanced** datasets with **BERT**.\n",
    "\n",
    "\n",
    "\n",
    "https://aclanthology.org/2021.emnlp-main.362.pdf -> new approach but maybe complicated\n",
    "\n",
    "\n",
    "However, increasing the text with the BT is not enough as we want to reach at least 5*200 comments = 1000 comments.\n",
    "We then use textual augmentation by Word embeddings which may not be the best solution but will increase the data further.  After several tests on our comments, I think that the method with Word embedding is still more efficient than the simple synonym replacement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "XhXbyFljDx5k",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XhXbyFljDx5k",
    "outputId": "e4e479f6-e364-4729-d3f9-2ee6b9c74ad4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting git+https://github.com/huggingface/transformers\n",
      "  Cloning https://github.com/huggingface/transformers to /tmp/pip-req-build-a71a7key\n",
      "  Running command git clone -q https://github.com/huggingface/transformers /tmp/pip-req-build-a71a7key\n",
      "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
      "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
      "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from transformers==4.22.0.dev0) (0.8.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers==4.22.0.dev0) (6.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers==4.22.0.dev0) (0.12.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.22.0.dev0) (3.7.1)\n",
      "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers==4.22.0.dev0) (4.12.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==4.22.0.dev0) (4.64.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.22.0.dev0) (2022.6.2)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.22.0.dev0) (2.23.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers==4.22.0.dev0) (21.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.22.0.dev0) (1.21.6)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.8.1->transformers==4.22.0.dev0) (4.1.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers==4.22.0.dev0) (3.0.9)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers==4.22.0.dev0) (3.8.1)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.22.0.dev0) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.22.0.dev0) (1.24.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.22.0.dev0) (2022.6.15)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.22.0.dev0) (2.10)\n",
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (0.0.53)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses) (7.1.2)\n",
      "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from sacremoses) (2022.6.2)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from sacremoses) (4.64.0)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses) (1.1.0)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses) (1.15.0)\n",
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (0.1.97)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"# Install Transformers from source with the following command:  \n",
    "# - We need to do this to use \"back_translation\" with \"nlpaug\", otherwise it does not work.\n",
    "# - May need to restart runtime environment since \"transformers==2.8.0\" version has  \n",
    "#   been previously loaded for BERT fine-tuning. \n",
    "#-------------------------------------------------\n",
    "!pip install git+https://github.com/huggingface/transformers\n",
    "\n",
    "# Install other libraries \n",
    "#-------------------------------------------------\n",
    "!pip install sacremoses\n",
    "!pip install sentencepiece\n",
    "\n",
    "# Install nlpaug library\n",
    "#-------------------------------------------------\n",
    "#!pip install numpy requests nlpaug\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "oefqtYVhFBCX",
   "metadata": {
    "id": "oefqtYVhFBCX"
   },
   "outputs": [],
   "source": [
    "\"\"\"#Import nlpaug library\n",
    "#-------------------------------------------------\n",
    "import nlpaug.augmenter.word as naw\n",
    "\n",
    "# Dowload the back_translation model.\n",
    "#-------------------------------------------------\n",
    "#---  Use english_german translation (default model) \n",
    "back_translation_aug_de = naw.BackTranslationAug(device = device.type,\n",
    "    from_model_name='facebook/wmt19-en-de', #english-deutch \n",
    "    to_model_name='facebook/wmt19-de-en'    #deutch-english \n",
    ")\n",
    "\n",
    "#--- Use english-french translation \n",
    "back_translation_aug_fr = naw.BackTranslationAug(device = device.type,\n",
    "    from_model_name='Helsinki-NLP/opus-mt-en-fr', #english-french \n",
    "    to_model_name='Helsinki-NLP/opus-mt-fr-en'    #french-english \n",
    ")\n",
    "\n",
    "#--- Use english-chinese translation \n",
    "back_translation_aug_zh = naw.BackTranslationAug(device = device.type,\n",
    "    from_model_name='Helsinki-NLP/opus-mt-en-zh', #english-chinese \n",
    "    to_model_name='Helsinki-NLP/opus-mt-zh-en'    #chinese-english \n",
    ")\n",
    "\n",
    "# documentation on naw.BackTranslationAug: \n",
    "# https://nlpaug.readthedocs.io/en/latest/augmenter/word/back_translation.html\n",
    "\n",
    "\n",
    "# Dowload the contextual word embeddings model.\n",
    "# Substitute word by contextual word embeddings (here with BERT)\n",
    "#-------------------------------------------------\n",
    "context_embedding_aug = naw.ContextualWordEmbsAug(device = device.type,\n",
    "    model_path='bert-base-uncased', action=\"substitute\")\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "knR96IPNFKGo",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "knR96IPNFKGo",
    "outputId": "af502ec8-56c1-458d-efe6-8a99537a5146"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing the imported augmenting methods: \n",
      "-----------------------------------------\n",
      "Original text:  The quick brown fox jumped over the lazy dog\n",
      "BT english-deutch:  ['The speedy brown fox leapt over the lazy dog']\n",
      "BT english-french:  ['The fast brown fox jumped on the lazy dog']\n",
      "BT english-chinese:  ['Fast brown fox skips a lazy dog, skips a lazy dog.']\n",
      "Context word embedding (BERT) : ['as frightened brown fox jumped over the lazy to']\n"
     ]
    }
   ],
   "source": [
    "\"\"\"text = 'The quick brown fox jumped over the lazy dog'\n",
    "print(\"Testing the imported augmenting methods: \")\n",
    "print(\"-----------------------------------------\")\n",
    "print(\"Original text: \",text)\n",
    "print(\"BT english-deutch: \",back_translation_aug_de.augment(text))\n",
    "print(\"BT english-french: \",back_translation_aug_fr.augment(text))\n",
    "print(\"BT english-chinese: \",back_translation_aug_zh.augment(text))\n",
    "print(\"Context word embedding (BERT) :\",context_embedding_aug.augment(text))\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vhGVx3JWFmLa",
   "metadata": {
    "id": "vhGVx3JWFmLa"
   },
   "outputs": [],
   "source": [
    "def augmentText(data2,method_aug):\n",
    "  \"\"\"\n",
    "  this function augments the text data with the method provided\n",
    "  ---> input:\n",
    "  - data2 (dataFrame): dataframe containing 2 columns {\"commments\", \"label\"}\n",
    "  - method_aug: method for text augmentation\n",
    "  ---> ouput:\n",
    "  - aug_data2 (dataFrame): dataframe with the same dimensions as data2 containing\n",
    "  the modified \"comments\" with the augmented method and the corresponding label\n",
    "  \"\"\"\n",
    "  aug = [] #list of the augmented comments in the same order as the comments in data2\n",
    "\n",
    "  print(\"Beginning of augmentation...\\n\")\n",
    "  for i in range(len(data2)):\n",
    "    if i % 10 == 0: #print every 10 comments \n",
    "      print(\"comment \",i)\n",
    "    text = data2.comments.iloc[i]\n",
    "    aug.append(method_aug.augment(text))  \n",
    "\n",
    "  aug_data2 = pd.DataFrame(aug)\n",
    "  aug_data2.rename(columns={0:\"comments\"},inplace=True)\n",
    "  aug_data2.index = data2.index\n",
    "  aug_data2[\"label\"] = data2[\"label\"].copy()\n",
    "  print(\"\\ndone!\")\n",
    "  return aug_data2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "owtZ2M_5Y79V",
   "metadata": {
    "id": "owtZ2M_5Y79V"
   },
   "outputs": [],
   "source": [
    "# Compute augmented datasets\n",
    "#---------------------------------------\n",
    "\"\"\"aug_eng_de = augmentText(data2,back_translation_aug_de); name_eng_de = \"200_eng-de\"\n",
    "#aug_eng_fr = augmentText(data2,back_translation_aug_fr); name_eng_fr = \"200_eng-fr\"\n",
    "#aug_eng_zh = augmentText(data2,back_translation_aug_zh); name_eng_fr = \"200_eng-zh\"\n",
    "#aug_embedding = augmentText(data2,context_embedding_aug); name_embedding = \"200_embeddings\"\n",
    "\n",
    "#----- Pickle dataset for later use \n",
    "os.chdir(PATH + '/7_Augmented_pkl') #go to correct folder \n",
    "pd.DataFrame(aug_eng_de).to_pickle(name_eng_de + \".pkl\") #pickle dataset\n",
    "os.chdir(PATH) #return to main folder\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "QcLWCWI6Z396",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QcLWCWI6Z396",
    "outputId": "11462886-dc33-4124-e732-ff398884252c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIX:  200_original+200_eng-de+200_eng-de+200_eng-fr+200_eng-fr+200_eng-zh+200_embeddings\n",
      "Size of the augmented dataset:  1400\n"
     ]
    }
   ],
   "source": [
    "# Augmenting pipeline\n",
    "#---------------------------------------\n",
    "aug_dataS = [] #list containing the dataframe which are augmented from data2\n",
    "\n",
    "#----- Retrieve augmented datasets \n",
    "os.chdir(PATH + '/7_Augmented_pkl') #go to correct folder \n",
    "\n",
    "#-- append data2\n",
    "MIX = \"200_original\"\n",
    "aug_dataS.append(data2)\n",
    "#-- append augment data english-deuth BT \n",
    "MIX += \"+200_eng-de\"\n",
    "aug_dataS.append(pd.read_pickle(\"200_eng-de\" + '.pkl'))\n",
    "\n",
    "MIX += \"+200_eng-de\"\n",
    "aug_dataS.append(pd.read_pickle(\"200_eng-de\" + '.pkl'))\n",
    "#-- append augment data english-french BT \n",
    "MIX += \"+200_eng-fr\"\n",
    "aug_dataS.append(pd.read_pickle(\"200_eng-fr\" + '.pkl'))\n",
    "\n",
    "MIX += \"+200_eng-fr\"\n",
    "aug_dataS.append(pd.read_pickle(\"200_eng-fr\" + '.pkl'))\n",
    "#-- append augment data english-chinese BT \n",
    "MIX += \"+200_eng-zh\"\n",
    "aug_dataS.append(pd.read_pickle(\"200_eng-zh\" + '.pkl'))\n",
    "#-- append augment data context word embedding \n",
    "MIX += \"+200_embeddings\"\n",
    "aug_dataS.append(pd.read_pickle(\"200_embeddings\" + '.pkl'))\n",
    "\n",
    "os.chdir(PATH) #return to main folder\n",
    "\n",
    "print(\"MIX: \",MIX)\n",
    "\n",
    "#----- Concatenate all datasets into data2\n",
    "data2 = pd.concat(aug_dataS, axis=0)\n",
    "\n",
    "print (\"Size of the augmented dataset: \", len(data2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "p2VZ_YRzk-Ti",
   "metadata": {
    "id": "p2VZ_YRzk-Ti"
   },
   "source": [
    "#### c. Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "o1jd7eT8kMWQ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "o1jd7eT8kMWQ",
    "outputId": "727ace3b-9582-40c1-80c1-90936441b4fb"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-3fe4133c-8bc8-4338-8d64-ba9fa8b9661b\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comments</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2664</th>\n",
       "      <td>so has progressed well and since has done work...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>implemented linear controls but no dataset or ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8745</th>\n",
       "      <td>math game and computation model is level one, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9829</th>\n",
       "      <td>met discussed project priority, proposal to fi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6837</th>\n",
       "      <td>the past week : jack : researched the open off...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3fe4133c-8bc8-4338-8d64-ba9fa8b9661b')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-3fe4133c-8bc8-4338-8d64-ba9fa8b9661b button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-3fe4133c-8bc8-4338-8d64-ba9fa8b9661b');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "                                               comments label\n",
       "2664  so has progressed well and since has done work...     1\n",
       "178   implemented linear controls but no dataset or ...     1\n",
       "8745  math game and computation model is level one, ...     0\n",
       "9829  met discussed project priority, proposal to fi...     0\n",
       "6837  the past week : jack : researched the open off...     1"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If we want 2 labels, we replace: 0 -> 0 and 1,2 -> 1 so that we have\n",
    "# labels (negative,positive) instead of (negative,neutral,positive)\n",
    "if NUM_LABELS == 2: \n",
    "  data2.label.iloc[np.where(data2.label != 0)] = 1\n",
    "data2.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "WFOmylNgl-F8",
   "metadata": {
    "id": "WFOmylNgl-F8"
   },
   "outputs": [],
   "source": [
    "2# Separate comments and labels\n",
    "#---------------------------------------------\n",
    "X_train2 = data2[\"comments\"].values\n",
    "y_train2 = data2[\"label\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3lXgGDeolNjs",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3lXgGDeolNjs",
    "outputId": "af505e81-3527-49f6-f3a2-7d4bf9423efb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now run the function preprocessingForBert_long on the dataset:\n",
      "\n",
      "Tokenizing data...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# Run function `preprocessing_for_bert` \n",
    "#---------------------------------------------\n",
    "preprocessing_for_bert = preprocessingForBert_long\n",
    "print(\"Now run the function \"  + preprocessing_for_bert.__name__ + \" on the dataset:\\n\")\n",
    "print('Tokenizing data...')\n",
    "train_inputs2, train_masks2 = preprocessing_for_bert(X_train2)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "JRYhZBTTmqx5",
   "metadata": {
    "id": "JRYhZBTTmqx5"
   },
   "source": [
    "#### d. Create Pytorch dataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6jjNsoarmtsk",
   "metadata": {
    "id": "6jjNsoarmtsk"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 8\n",
    "\n",
    "# Convert other data types to torch.Tensor\n",
    "train_labels2 = torch.tensor(y_train2)\n",
    "\n",
    "# Create the DataLoader for our training set\n",
    "train_data2 = TensorDataset(train_inputs2, train_masks2, train_labels2)\n",
    "train_sampler2 = RandomSampler(train_data2) \n",
    "train_dataloader2 = DataLoader(train_data2, sampler=train_sampler2, batch_size=BATCH_SIZE)\n",
    "\n",
    "# Save current time\n",
    "NOW = time.strftime(\"%Y-%m-%d_%H:%M:%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "orvpKSEmfg2V",
   "metadata": {
    "id": "orvpKSEmfg2V"
   },
   "outputs": [],
   "source": [
    "#----- Save dataloader for later use\n",
    "os.chdir(PATH + '/3_DataLoader_pt') #go to correct folder \n",
    "torch.save(train_dataloader2, NOW + \"_full_train_dataloader.pt\")\n",
    "os.chdir(PATH) #return to main folder "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "IZFmHVO9nY_D",
   "metadata": {
    "id": "IZFmHVO9nY_D"
   },
   "source": [
    "#### d. Resume the best model \n",
    "\n",
    "We resume the model that gave the best predictions on the \"miniLabel\" dataset to fine-tune further but this time, on our augmented \"dashbordLabel\" dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "S3TRwWjLXPXy",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S3TRwWjLXPXy",
    "outputId": "348234d0-6fce-4b51-e6da-7d0570bba04f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resumed model operational for further training.\n",
      "This model has already been trained with 2 epochs.\n"
     ]
    }
   ],
   "source": [
    "RESUME = True; FULL_RUN = True; PHASE = 2 #do not change\n",
    "# =======================================\n",
    "# RESUME MODEL:\n",
    "# =======================================\n",
    "# To do this, make sure to run the code in the sections:\n",
    "# 1\n",
    "# 2.1\n",
    "# 3\n",
    "# 4.4  /.\\ Beware to put the correct NUM_LABELS /.\\\n",
    "\n",
    "#-- name of the fine-tuned to resume:\n",
    "CKP_NAME = \"2022-08-09_09:30:18_full_checkpoint\"\n",
    "\n",
    "#-- indicate the number of epochs to make in the next training:\n",
    "NUM_EPOCHS = 2\n",
    "\n",
    "#-- indicate the parameters in the AdamW optimizer\n",
    "EPS = 1e-8 # Default epsilon value in AdamW optimizer\n",
    "LR = 5e-5  # Default learning rate in AdamW optimizer \n",
    "#values proposed by the BERT paper: 5e-5, 3e-5 or 2e-5\n",
    "\n",
    "#-- Redefine some global variables if not already defined: \n",
    "BERT_MODEL_NAME = 'bert-base-uncased'\n",
    "\n",
    "#----- Initlialize the model with resumed fine-tuned BERT model \n",
    "bert_classifier, optimizer, scheduler = initialize_model(\n",
    "      train_dataloader2, epochs = NUM_EPOCHS ,resume_training = True,\n",
    "      ckp_path = PATH + '/5_Checkpoints_pt/' + CKP_NAME + \".pt\",lr=LR,eps=EPS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "uRxWT93KoGRg",
   "metadata": {
    "id": "uRxWT93KoGRg"
   },
   "source": [
    "#### e. Train the model for a 2nd fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "TfktxdA0oF5U",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TfktxdA0oF5U",
    "outputId": "6eac8034-662a-4e4d-c291-c560be52dcad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training...\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
      "----------------------------------------------------------------------\n",
      "   1    |   20    |   0.313214   |     -      |     -     |   15.09  \n",
      "   1    |   40    |   0.144707   |     -      |     -     |   14.59  \n",
      "   1    |   60    |   0.292513   |     -      |     -     |   14.95  \n",
      "   1    |   80    |   0.189508   |     -      |     -     |   15.21  \n",
      "   1    |   100   |   0.441477   |     -      |     -     |   15.61  \n",
      "   1    |   120   |   0.113018   |     -      |     -     |   15.70  \n",
      "   1    |   140   |   0.043425   |     -      |     -     |   15.46  \n",
      "   1    |   160   |   0.059797   |     -      |     -     |   15.19  \n",
      "   1    |   174   |   0.139497   |     -      |     -     |   10.63  \n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
      "----------------------------------------------------------------------\n",
      "   2    |   20    |   0.036424   |     -      |     -     |   16.07  \n",
      "   2    |   40    |   0.034143   |     -      |     -     |   15.44  \n",
      "   2    |   60    |   0.006875   |     -      |     -     |   15.43  \n",
      "   2    |   80    |   0.037656   |     -      |     -     |   15.37  \n",
      "   2    |   100   |   0.068379   |     -      |     -     |   15.29  \n",
      "   2    |   120   |   0.066808   |     -      |     -     |   15.32  \n",
      "   2    |   140   |   0.037205   |     -      |     -     |   15.29  \n",
      "   2    |   160   |   0.037414   |     -      |     -     |   15.33  \n",
      "   2    |   174   |   0.006432   |     -      |     -     |   10.71  \n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "FULL_RUN = True  #do not change\n",
    "# =======================================\n",
    "# TRAIN MODEL:\n",
    "# =======================================\n",
    "LossList,AccuList,checkpoint_name= train(bert_classifier, train_dataloader2, epochs=NUM_EPOCHS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dVxQV5Ei5uiI",
   "metadata": {
    "id": "dVxQV5Ei5uiI"
   },
   "source": [
    "### 4.8. Save parameters in excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "KhVwKPXq6fk1",
   "metadata": {
    "id": "KhVwKPXq6fk1"
   },
   "outputs": [],
   "source": [
    "# =======================================\n",
    "# Open file and initalise variables\n",
    "# =======================================\n",
    "#----- Open xlsx file\n",
    "os.chdir(PATH) #go to correct folder \n",
    "wb = load_workbook(filename = PATH + \"/result/BERT_runs_2.xlsx\")\n",
    "#----- Get the current Active Sheet\n",
    "ws = wb.active #or wb['SHEET_NAME']\n",
    "#----- Specify row index\n",
    "row = 2\n",
    "#----- If there is no first run (true only at the first use) \n",
    "if not(ws.cell(row,1).value): \n",
    "  ws.cell(row,1).value = 1 \n",
    "else: #increase number of runs \n",
    "  ws.cell(row,1).value = ws.cell(row,1).value + 1 \n",
    "#----- Update row index according to the number of runs and update col\n",
    "row = int(ws.cell(row,1).value) + 2\n",
    "\n",
    "# =======================================\n",
    "# Write information\n",
    "# =======================================\n",
    "#--Write date \n",
    "ws.cell(row,2).value = NOW\n",
    "\n",
    "#--Write number of epochs\n",
    "ws.cell(row,11).value = NUM_EPOCHS\n",
    "\n",
    "#--Write eps value in AdamW optimizer\n",
    "ws.cell(row,12).value = EPS\n",
    "#--Write lr value in AdamW optimizer\n",
    "ws.cell(row,13).value = LR\n",
    "\n",
    "#--Write the number of labels\n",
    "ws.cell(row,23).value = NUM_LABELS\n",
    "\n",
    "#-----[ The model has been resumed \n",
    "if RESUME:\n",
    "  #--Write that the model was resumed\n",
    "  ws.cell(row,3).value = \"Y\"\n",
    "  ws.cell(row,4).value = CKP_NAME\n",
    "\n",
    "  #--If we are in the 2nd phase of fine-tuning (on \"dashbordLabel\"):\n",
    "  if PHASE == 2:\n",
    "    #--Write that we are using dataset \"dashbordLabel\"\n",
    "    ws.cell(row,6).value = str(NAMES)\n",
    "    #--Write dataset mix\n",
    "    ws.cell(row,8).value = MIX\n",
    "     #--Write BERT model name\n",
    "    ws.cell(row,9).value = BERT_MODEL_NAME\n",
    "    #--Write Batch size\n",
    "    ws.cell(row,10).value = BATCH_SIZE\n",
    "\n",
    "  if not(FULL_RUN): \n",
    "    \n",
    "    #--Write val_loss in BERT Pre-training (with valisation set)\n",
    "    ws.cell(row,14).value = str(valLossList)\n",
    "    #--Write val_accuracy in BERT Pre-training (with valisation set)\n",
    "    ws.cell(row,15).value = str(valAccuList)\n",
    "\n",
    "    ########## Prediction RULE 1 \n",
    "    #--Write Bert accuracy on validation set\n",
    "    ws.cell(row,16).value = accuracy_val\n",
    "    #--Write Bert Cross Table on validation set\n",
    "    ws.cell(row,17).value = str(crossT_val)\n",
    "    #--Write Bert F1-score on validation set\n",
    "    ws.cell(row,18).value = f1Score_val\n",
    "    ########## Prediction RULE 2 (BEST threshold) \n",
    "    #--Write Best trheshold \n",
    "    ws.cell(row,19).value = str(BEST_T)\n",
    "    #--Write Bert accuracy on validation set \n",
    "    ws.cell(row,20).value = accuracy_val_2\n",
    "    #--Write Bert Cross Table on validation set\n",
    "    ws.cell(row,21).value = str(crossT_val_2)\n",
    "    #--Write Bert F1-score on validation set\n",
    "    ws.cell(row,22).value = f1Score_val_2\n",
    "\n",
    "#-----]  \n",
    "\n",
    "#-----[ the model was not resumed\n",
    "else:\n",
    "  #--Write that the model was not resumed\n",
    "  ws.cell(row,3).value = \"N\"\n",
    "  ws.cell(row,4).value = \"\"\n",
    "\n",
    "  #--Write dataset names\n",
    "  ws.cell(row,6).value = str(NAMES)\n",
    "  #--Write dataset urls\n",
    "  ws.cell(row,7).value = str(URLS)\n",
    "  #--Write dataset mix\n",
    "  ws.cell(row,8).value = MIX\n",
    "\n",
    "  #--Write BERT model name\n",
    "  ws.cell(row,9).value = BERT_MODEL_NAME\n",
    "  #--Write Batch size\n",
    "  ws.cell(row,10).value = BATCH_SIZE\n",
    "  \n",
    "  #--Write if the model was trained on the full dataset\n",
    "  if FULL_RUN:\n",
    "    ws.cell(row,5).value = \"Full\"\n",
    "  else:\n",
    "    ws.cell(row,5).value = \"Train\"\n",
    "    \n",
    "    #--Write val_loss in BERT Pre-training (with valisation set)\n",
    "    ws.cell(row,14).value = str(valLossList)\n",
    "    #--Write val_accuracy in BERT Pre-training (with valisation set)\n",
    "    ws.cell(row,15).value = str(valAccuList)\n",
    "  \n",
    "    ########## Prediction RULE 1 \n",
    "    #--Write Bert accuracy on validation set\n",
    "    ws.cell(row,16).value = accuracy_val\n",
    "    #--Write Bert Cross Table on validation set\n",
    "    ws.cell(row,17).value = str(crossT_val)\n",
    "    #--Write Bert F1-score on validation set\n",
    "    ws.cell(row,18).value = f1Score_val\n",
    "    ########## Prediction RULE 2 (BEST threshold) \n",
    "    #--Write Best trheshold \n",
    "    ws.cell(row,19).value = str(BEST_T)\n",
    "    #--Write Bert accuracy on validation set \n",
    "    ws.cell(row,20).value = accuracy_val_2\n",
    "    #--Write Bert Cross Table on validation set\n",
    "    ws.cell(row,21).value = str(crossT_val_2)\n",
    "    #--Write Bert F1-score on validation set\n",
    "    ws.cell(row,22).value = f1Score_val_2\n",
    "\n",
    "#-----]\n",
    "\n",
    "# =======================================\n",
    "# WRITE now all changes into the file \n",
    "# =======================================\n",
    "wb.save(PATH + \"/result/BERT_runs_2.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cCKSHcKkeI0q",
   "metadata": {
    "id": "cCKSHcKkeI0q"
   },
   "outputs": [],
   "source": [
    "# =======================================\n",
    "# Update CKP_NAME name if the training has been RESUMED and there was a SECOND fine-tuning. \n",
    "# Otherwise, let inchanged. \n",
    "# This will be useful in the part were we work on the \"miniLabel\" dataset\n",
    "# =======================================\n",
    "if RESUME: \n",
    "    CKP_NAME = NOW + \"_full_checkpoint\" "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tGPrlmac_npp",
   "metadata": {
    "id": "tGPrlmac_npp"
   },
   "source": [
    "Interface to try to save every parameters for each run(same use as the excel file): **Comet**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "DTO9dsuqsaMw",
   "metadata": {
    "id": "DTO9dsuqsaMw"
   },
   "outputs": [],
   "source": [
    "#----- Empty cache to avoid memory problems\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "yn0228Ma6LJs",
   "metadata": {
    "id": "yn0228Ma6LJs"
   },
   "source": [
    "## 5.Apply BERT on our own Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eOxNdRLB4xo",
   "metadata": {
    "id": "5eOxNdRLB4xo"
   },
   "outputs": [],
   "source": [
    "# =======================================\n",
    "# Before running the cells below:\n",
    "# =======================================\n",
    "##### 1. Make sure you have fine-tuned a BERT model: \n",
    "# a) Resume a model in section 4.5.a.2. or section 4.6.a.2. (recommended)\n",
    "# b) Use a model fine-tuned in the same run of this Notebook.\n",
    "\n",
    "##### 2. Make sure to run the code in the sections:\n",
    "# 1\n",
    "# 2.1  \n",
    "# 2.5\n",
    "# 4.1\n",
    "# 4.2\n",
    "# 4.5.c. functions \"bert_predict\", \"predictionRule\", \"evaluate_perf\" and \"computeBest_T\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "KmtkqvqP_FJL",
   "metadata": {
    "id": "KmtkqvqP_FJL"
   },
   "source": [
    "### 5.1. Download our own datasets (3 options: A,B or C)\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sOFlgnwU86dg",
   "metadata": {
    "id": "sOFlgnwU86dg"
   },
   "source": [
    "#### Option A. Download the miniLabel (validation) dataset \n",
    "> used to **evaluate** our model on 30 comments from the dashboard data in order to perform model selection. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eSBlf3etbBif",
   "metadata": {
    "id": "eSBlf3etbBif"
   },
   "outputs": [],
   "source": [
    "# Work on the miniLabel(validation) dataset\n",
    "#---------------------------------------------\n",
    "# Download the miniLabel dataset\n",
    "os.chdir(PATH)\n",
    "dash_data = pd.read_excel(\"data/miniLabel.xlsx\")\n",
    "\n",
    "# Clean the dataframe and assign correct type  \n",
    "dash_data.index = dash_data[\"Unnamed: 0\"].astype(int)\n",
    "dash_data.index.name = None\n",
    "dash_data.drop(\"Unnamed: 0\", axis = 1, inplace = True)\n",
    "dash_data[\"label\"] = dash_data[\"label\"].astype(int)\n",
    "dash_data[\"label\"]=pd.Categorical(dash_data[\"label\"],ordered=False) \n",
    "dash_data.rename(columns = {\"label\": \"TrueLabel\"},inplace = True)\n",
    "\n",
    "# If we want 2 labels, we replace: 0 -> 0 and 1,2 -> 1 so that we have\n",
    "# labels (negative,positive) instead of (negative,neutral,positive)\n",
    "if NUM_LABELS == 2: \n",
    "  dash_data.TrueLabel.iloc[np.where(dash_data.TrueLabel != 0)] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "kIkdejQD9nvX",
   "metadata": {
    "id": "kIkdejQD9nvX"
   },
   "source": [
    "#### Option B. Download the Test dataset \n",
    "> used to **Test** our model on 50 comments from the dashboard data in order to asses performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "-zgIalNb9ybm",
   "metadata": {
    "id": "-zgIalNb9ybm"
   },
   "outputs": [],
   "source": [
    "# Work on the test dataset\n",
    "#---------------------------------------------\n",
    "# Download the Test dataset\n",
    "os.chdir(PATH)\n",
    "dash_data = pd.read_excel(\"data/testLabel.xlsx\")\n",
    "\n",
    "# Clean the dataframe and assign correct type  \n",
    "dash_data.index = dash_data[\"Unnamed: 0\"].astype(int)\n",
    "dash_data.index.name = None\n",
    "dash_data.drop(\"Unnamed: 0\", axis = 1, inplace = True)\n",
    "dash_data[\"label\"] = dash_data[\"label\"].astype(int)\n",
    "dash_data[\"label\"]=pd.Categorical(dash_data[\"label\"],ordered=False) \n",
    "dash_data.rename(columns = {\"label\": \"TrueLabel\"},inplace = True)\n",
    "\n",
    "# If we want 2 labels, we replace: 0 -> 0 and 1,2 -> 1 so that we have\n",
    "# labels (negative,positive) instead of (negative,neutral,positive)\n",
    "if NUM_LABELS == 2: \n",
    "  dash_data.TrueLabel.iloc[np.where(dash_data.TrueLabel != 0)] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4BJr1nS9W04",
   "metadata": {
    "id": "c4BJr1nS9W04"
   },
   "source": [
    "#### Option C. Download the entire Dashbord dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eCPkpRfi9WWP",
   "metadata": {
    "id": "eCPkpRfi9WWP"
   },
   "outputs": [],
   "source": [
    "# Read the excel containing the dahboard's information\n",
    "#--------------------------------------------------------\n",
    "MyData = '/data/Meetings&marks_anonyomized_v2.xlsx' #name of the excel file\n",
    "dashbord = pd.read_excel(PATH + MyData) #read the excel file and put it into a df\n",
    "idxNoNaN = np.where(dashbord[\"comments\"].isna() == False) #indices of non NaN comments in dashbord df\n",
    "dash_data = pd.DataFrame(dashbord[\"comments\"].iloc[idxNoNaN].copy()) #create df with only the comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5QEgIh2eh0US",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "5QEgIh2eh0US",
    "outputId": "89dc4c02-9a06-48b9-b3da-9bdd67a1713f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-834ade1b-20db-4de1-8cd4-4519648abcdf\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This is a test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Watch out for peer reviews journals looking fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Discussed general outline of paper i.e. resear...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ed emailed the progress report below in advanc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data preparation in terms of cleaning has been...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11784</th>\n",
       "      <td>Progress has stalled slightly due to losing co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11785</th>\n",
       "      <td>Your ethics and GDPR submission has been appro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11786</th>\n",
       "      <td>Rachel and Ryan making good progress. Design a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11787</th>\n",
       "      <td>Ethics document reviewed by Supervisor.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11788</th>\n",
       "      <td>All going well\\nAutocomplete working\\nLocally ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11356 rows × 1 columns</p>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-834ade1b-20db-4de1-8cd4-4519648abcdf')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-834ade1b-20db-4de1-8cd4-4519648abcdf button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-834ade1b-20db-4de1-8cd4-4519648abcdf');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "                                                comments\n",
       "0                                         This is a test\n",
       "1      Watch out for peer reviews journals looking fo...\n",
       "2      Discussed general outline of paper i.e. resear...\n",
       "3      Ed emailed the progress report below in advanc...\n",
       "5      Data preparation in terms of cleaning has been...\n",
       "...                                                  ...\n",
       "11784  Progress has stalled slightly due to losing co...\n",
       "11785  Your ethics and GDPR submission has been appro...\n",
       "11786  Rachel and Ryan making good progress. Design a...\n",
       "11787            Ethics document reviewed by Supervisor.\n",
       "11788  All going well\\nAutocomplete working\\nLocally ...\n",
       "\n",
       "[11356 rows x 1 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dash_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "LfwVAY_L_KGy",
   "metadata": {
    "id": "LfwVAY_L_KGy"
   },
   "source": [
    "### 5.2. Preprocessing our dataset (run for A,B,C)\n",
    "\n",
    "Before making predictions on our dataset, we need to redo processing and encoding steps done on the training data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "STv4UaPl9YCJ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 225
    },
    "id": "STv4UaPl9YCJ",
    "outputId": "82a179f4-4079-4521-dc27-7eb5ce509880"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dash_data contains 11356 non-NaN comments\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-e7547a18-c8b9-4e51-bfd5-797f1393ed01\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This is a test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Watch out for peer reviews journals looking fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Discussed general outline of paper i.e. resear...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ed emailed the progress report below in advanc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data preparation in terms of cleaning has been...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e7547a18-c8b9-4e51-bfd5-797f1393ed01')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-e7547a18-c8b9-4e51-bfd5-797f1393ed01 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-e7547a18-c8b9-4e51-bfd5-797f1393ed01');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "                                            comments\n",
       "0                                     This is a test\n",
       "1  Watch out for peer reviews journals looking fo...\n",
       "2  Discussed general outline of paper i.e. resear...\n",
       "3  Ed emailed the progress report below in advanc...\n",
       "5  Data preparation in terms of cleaning has been..."
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"dash_data contains {} non-NaN comments\".format(dash_data.shape[0]))\n",
    "dash_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "CanMzP5iAkz2",
   "metadata": {
    "id": "CanMzP5iAkz2"
   },
   "source": [
    "**Clean the comments in the dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "qA9fzpIi_Syd",
   "metadata": {
    "id": "qA9fzpIi_Syd"
   },
   "outputs": [],
   "source": [
    "#----- Clean the comments in the dataset\n",
    "dash_data[\"comments\"] = dash_data[\"comments\"].apply(f_cleanLight)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "C3-l8Sz6Arzd",
   "metadata": {
    "id": "C3-l8Sz6Arzd"
   },
   "source": [
    "**Apply tokenization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eI-x1y5qAf3_",
   "metadata": {
    "id": "eI-x1y5qAf3_"
   },
   "outputs": [],
   "source": [
    "#----- Compute MAX_LEN\n",
    "#MAX_LEN = computeMaxLen(dash_data) \n",
    "MAX_LEN = 3882"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ky4rwMXvBxaC",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ky4rwMXvBxaC",
    "outputId": "419bebad-a063-49cf-9945-6814878fff00"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now run the function preprocessingForBert_long to tokenize our dahboard data:\n",
      "\n",
      "Tokenizing data...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "#----- Tokenize data\n",
    "# since the maximum length of our comments exceeds 512 tokens,\n",
    "# we use the function preprocessingForBert_long\n",
    "preprocessing_for_bert = preprocessingForBert_long\n",
    "\n",
    "print(\"Now run the function \"  + preprocessing_for_bert.__name__ + \" to tokenize our dahboard data:\\n\")\n",
    "print('Tokenizing data...')\n",
    "dash_inputs, dash_masks = preprocessing_for_bert(dash_data[\"comments\"])\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8BsPp8bECw8H",
   "metadata": {
    "id": "8BsPp8bECw8H"
   },
   "source": [
    "**Create PyTorch DataLoader**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "XCSfaON9C2Yg",
   "metadata": {
    "id": "XCSfaON9C2Yg"
   },
   "outputs": [],
   "source": [
    "#----- Crate the DataLoader for our dashbord comments\n",
    "dash_dataset = TensorDataset(dash_inputs, dash_masks)\n",
    "dash_sampler = SequentialSampler(dash_dataset)\n",
    "\n",
    "# make sure that the BATCH_SIZE is the same as the one used  to train the model\n",
    "BATCH_SIZE = 8\n",
    "dash_dataloader = DataLoader(dash_dataset, sampler=dash_sampler, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6PqGJtIEQ1A",
   "metadata": {
    "id": "d6PqGJtIEQ1A"
   },
   "source": [
    "### 5.3. Get predictions (run for A,B,C)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "GmZpljCdiYKn",
   "metadata": {
    "id": "GmZpljCdiYKn"
   },
   "source": [
    "**Run** the cell RESUME MODEL only if you want to use for the predictions a **model previously fine-tuned**. \\\n",
    "**Do not run** this cell if you want to use for the predictions a model **fine-tuned in the same run of this Notebook**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lpxmanHK-Fl7",
   "metadata": {
    "id": "lpxmanHK-Fl7"
   },
   "outputs": [],
   "source": [
    "#----- GET PREDICTIONS on dashbord data: \n",
    "dash_probs = bert_predict(bert_classifier, dash_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Bxtt2poh_eWQ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "id": "Bxtt2poh_eWQ",
    "outputId": "ef832611-ae65-40a8-f2f8-59b3b80a1423"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'\\nprobs_name = \"dashProbs_from:2022-08-18_10:50:40_full_checkpoint\"\\n\\nCKP_NAME = \"2022-08-18_10:50:40_full_checkpoint\"\\n\\nos.chdir(PATH + \\'/6_ProbsDashbord_pkl\\') #go to correct folder \\ndash_probs = pd.read_pickle(probs_name + \\'.pkl\\').to_numpy()\\n'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#----- Pickle Probs results for later use \n",
    "NAME_DATA = \"dash\"        # if the dataset is the entire dashbord\n",
    "#NAME_DATA = \"miniLabel\"   # if the dataset is the miniLabel\n",
    "#NAME_DATA = \"testLabel\"   # if the dataset is the testLabel\n",
    "\n",
    "#if dash_probs were calculated from a resumed fine-tuned model:\n",
    "if CKP_NAME: \n",
    "  probs_name = NAME_DATA + \"Probs_from:\" + CKP_NAME + \".pkl\"\n",
    "#if dash_probs were calculated from a model fine-tuned in this notebook:\n",
    "else:\n",
    "  probs_name = NAME_DATA + \"Probs_from:\" + checkpoint_name[:-3] + \".pkl\"\n",
    "\n",
    "os.chdir(PATH + '/6_ProbsDashbord_pkl') #go to correct folder \n",
    "pd.DataFrame(dash_probs).to_pickle(probs_name) #pickle dataset\n",
    "os.chdir(PATH) #return to main folder\n",
    "\n",
    "\n",
    "#----- Retrieve Probs results  \n",
    "\"\"\"\n",
    "probs_name = \"dashProbs_from:2022-08-18_10:50:40_full_checkpoint\"\n",
    "\n",
    "CKP_NAME = \"2022-08-18_10:50:40_full_checkpoint\"\n",
    "\n",
    "os.chdir(PATH + '/6_ProbsDashbord_pkl') #go to correct folder \n",
    "dash_probs = pd.read_pickle(probs_name + '.pkl').to_numpy()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fIddcbTLsh-N",
   "metadata": {
    "id": "fIddcbTLsh-N"
   },
   "source": [
    "### 5.4. Option A only: On miniLabel dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "D853bsTOMT4C",
   "metadata": {
    "id": "D853bsTOMT4C"
   },
   "source": [
    "#### a. Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fNoBb08-JEc0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "id": "fNoBb08-JEc0",
    "outputId": "27200861-1f00-42c1-bd12-be8272717d0f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation of the Bert classifier with prediction rule 1 on miniLabel dataset:\n",
      "Accuracy: 96.00%\n",
      "F1-Score: 86.41%\n",
      "\n",
      "Contigency Table:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-4aac48d0-df88-42fe-a28f-f07a529a5638\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>True_label</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Prediction</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4aac48d0-df88-42fe-a28f-f07a529a5638')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-4aac48d0-df88-42fe-a28f-f07a529a5638 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-4aac48d0-df88-42fe-a28f-f07a529a5638');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "True_label  0   1\n",
       "Prediction       \n",
       "0           3   2\n",
       "1           0  45"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the Bert classifier with the prediction rule 1 on miniLabel dataset\n",
    "#-----------------------------------------------------------------------------\n",
    "print(\"Evaluation of the Bert classifier with prediction rule 1 on miniLabel dataset:\")\n",
    "BERTlabel_1, crossT, mini_accuracy, mini_f1Score = evaluate_perf(dash_probs,\n",
    "                                                                 dash_data[\"TrueLabel\"].values)\n",
    "mini_crossT = crossT.to_numpy().tolist() #convert crossT to list format for later use \n",
    "print(\"\\nContigency Table:\")\n",
    "crossT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tVtSu4NvI_Df",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 965
    },
    "id": "tVtSu4NvI_Df",
    "outputId": "43d3b87b-3f24-470c-ee84-8c3e2b948656"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "threshold:  0.1\n",
      "Accuracy: 24.00%\n",
      "F1-Score: 23.13%\n",
      "\n",
      "threshold:  0.2\n",
      "Accuracy: 24.00%\n",
      "F1-Score: 23.13%\n",
      "\n",
      "threshold:  0.3\n",
      "Accuracy: 26.00%\n",
      "F1-Score: 24.59%\n",
      "\n",
      "threshold:  0.4\n",
      "Accuracy: 34.00%\n",
      "F1-Score: 30.51%\n",
      "\n",
      "threshold:  0.5\n",
      "Accuracy: 36.00%\n",
      "F1-Score: 31.80%\n",
      "\n",
      "threshold:  0.6\n",
      "Accuracy: 42.00%\n",
      "F1-Score: 35.55%\n",
      "\n",
      "threshold:  0.7\n",
      "Accuracy: 54.00%\n",
      "F1-Score: 43.29%\n",
      "\n",
      "threshold:  0.8\n",
      "Accuracy: 58.00%\n",
      "F1-Score: 45.23%\n",
      "\n",
      "threshold:  0.9\n",
      "Accuracy: 70.00%\n",
      "F1-Score: 51.81%\n",
      "\n",
      "mini_BEST_T:  0.9\n",
      "\n",
      "Evaluation of the Bert classifier with prediction rule 2 using the Best Threshold on miniLabel dataset:\n",
      "Accuracy: 70.00%\n",
      "F1-Score: 51.81%\n",
      "\n",
      "Contigency Table:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-bc13654a-f829-4cab-84de-186e1d6ec989\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>True_label</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Prediction</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bc13654a-f829-4cab-84de-186e1d6ec989')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-bc13654a-f829-4cab-84de-186e1d6ec989 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-bc13654a-f829-4cab-84de-186e1d6ec989');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "True_label  0   1  2\n",
       "Prediction          \n",
       "0           1   2  0\n",
       "1           2  30  5\n",
       "2           0   6  4"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the Bert classifier with the prediction rule 2  on miniLabel dataset\n",
    "# using the Best Threshold found with function \"computeBest_T\"\n",
    "#---------------------------------------------------------\n",
    "T_grid = [.1,.2,.3,.4,.5,.6,.7,.8,.9] # grid of thresholds for the prediction rule 2 \n",
    "mini_BEST_T = computeBest_T(T_grid,dash_probs,dash_data[\"TrueLabel\"].values)\n",
    "print(\"mini_BEST_T: \", mini_BEST_T)\n",
    "print(\"\")\n",
    "\n",
    "print(\"Evaluation of the Bert classifier with prediction rule 2 using the Best Threshold on miniLabel dataset:\")\n",
    "BERTlabel_2, crossT_2, mini_accuracy_2, mini_f1Score_2 = evaluate_perf(dash_probs,\n",
    "                                                                       dash_data[\"TrueLabel\"].values,\n",
    "                                                                       rule=2,\n",
    "                                                                       T=mini_BEST_T)\n",
    "mini_crossT_2 = crossT_2.to_numpy().tolist() #convert crossT_2 to list format for later use \n",
    "print(\"\\nContigency Table:\")\n",
    "crossT_2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "meBYAeAbNCWw",
   "metadata": {
    "id": "meBYAeAbNCWw"
   },
   "source": [
    "#### b. Add predicted labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sDTtqSGSLsk-",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "sDTtqSGSLsk-",
    "outputId": "84d156dd-23fa-4b7d-c8c2-7feeb4029a7d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-41c6dc7b-10d7-4f44-914e-9d5043605f79\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comments</th>\n",
       "      <th>TrueLabel</th>\n",
       "      <th>BERTlabel_1</th>\n",
       "      <th>BERTlabel_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6537</th>\n",
       "      <td>Met on</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9214</th>\n",
       "      <td>Meeting took place on February. this was bette...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4311</th>\n",
       "      <td>A lot of research into tech has been done. How...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1729</th>\n",
       "      <td>Meeting took place April MVP Minimum Viable Pr...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7655</th>\n",
       "      <td>Raspberry setup and can be connected to router...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1366</th>\n",
       "      <td>Progress Login Reg reset password done Bootstr...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7326</th>\n",
       "      <td>At the end of exams week we had a zoom call to...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3726</th>\n",
       "      <td>The proposal was discussed. Connor to think ab...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1723</th>\n",
       "      <td>Meeting took place on Met with student to disc...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9302</th>\n",
       "      <td>Meeting happened before Christmas Discussed et...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5755</th>\n",
       "      <td>Made on progress segmentation and setting up e...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9848</th>\n",
       "      <td>First meeting and an individual project. Plan ...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>Bryan on balance a good amount of work has bee...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4490</th>\n",
       "      <td>Some hitches but now back on the track.</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10775</th>\n",
       "      <td>. There is no topic. .Topic must be narrow and...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3081</th>\n",
       "      <td>Currently looking at SNORT system. Problems in...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4536</th>\n",
       "      <td>Starting point Literature review finding relat...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>Monday November We have discussed with the stu...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11582</th>\n",
       "      <td>Upgraded mobile App Integrated code into Git M...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1070</th>\n",
       "      <td>Dillin has come back with an altered spec. He ...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5803</th>\n",
       "      <td>Use of 'walk forward validation' for implied ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8601</th>\n",
       "      <td>Meeting note for Observation that more trainin...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10981</th>\n",
       "      <td>Capstone Interim Review Your explanation of th...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7929</th>\n",
       "      <td>Meeting Discussion of tools for construction o...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9724</th>\n",
       "      <td>They are proposing some kind of evolutionary n...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5364</th>\n",
       "      <td>Data has been obtained to begin experiments. S...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10427</th>\n",
       "      <td>meeting May The prototype is working. Still w...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3871</th>\n",
       "      <td>Initial meeting to discuss idea. Interested in...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7024</th>\n",
       "      <td>Date General update meeting with progress revi...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>783</th>\n",
       "      <td>GUI working. Collisions working. Cell wall thi...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9880</th>\n",
       "      <td>Meeting happened before Christmas Discussed et...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7567</th>\n",
       "      <td>project pitch feedback</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4348</th>\n",
       "      <td>Met check function completed events importance...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>Meeting took place in week of Semester Discuss...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3971</th>\n",
       "      <td>The proposal is in reasonably good shape. Try ...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5501</th>\n",
       "      <td>Literature review presented and is very approp...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5369</th>\n",
       "      <td>We just recapped everything from the previous ...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7401</th>\n",
       "      <td>Started the final documentation. Working on th...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1824</th>\n",
       "      <td>October meeting. Proposed project discussed.</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11207</th>\n",
       "      <td>Meeting Dec Clearer idea of project.</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10422</th>\n",
       "      <td>meeting April Discuss development of business...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10430</th>\n",
       "      <td>Discussed ethics form. Showed them where to fi...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4066</th>\n",
       "      <td>Initial meeting for discussion of the idea. Th...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2944</th>\n",
       "      <td>We switched from the Dementia UK dataset to AD...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10218</th>\n",
       "      <td>Discussed mid term delivery document Challenge...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7710</th>\n",
       "      <td>Students have started putting content into the...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8406</th>\n",
       "      <td>Background modelling traffic datasets foregrou...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11767</th>\n",
       "      <td>Metamask is working. A lot of work was require...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7921</th>\n",
       "      <td>Happy with progress. Now looking at using supe...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8762</th>\n",
       "      <td>Different SA packages If using prices think a...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-41c6dc7b-10d7-4f44-914e-9d5043605f79')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-41c6dc7b-10d7-4f44-914e-9d5043605f79 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-41c6dc7b-10d7-4f44-914e-9d5043605f79');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "                                                comments TrueLabel  \\\n",
       "6537                                             Met on          1   \n",
       "9214   Meeting took place on February. this was bette...         0   \n",
       "4311   A lot of research into tech has been done. How...         2   \n",
       "1729   Meeting took place April MVP Minimum Viable Pr...         1   \n",
       "7655   Raspberry setup and can be connected to router...         1   \n",
       "1366   Progress Login Reg reset password done Bootstr...         1   \n",
       "7326   At the end of exams week we had a zoom call to...         1   \n",
       "3726   The proposal was discussed. Connor to think ab...         1   \n",
       "1723   Meeting took place on Met with student to disc...         1   \n",
       "9302   Meeting happened before Christmas Discussed et...         1   \n",
       "5755   Made on progress segmentation and setting up e...         1   \n",
       "9848   First meeting and an individual project. Plan ...         1   \n",
       "315    Bryan on balance a good amount of work has bee...         0   \n",
       "4490             Some hitches but now back on the track.         1   \n",
       "10775  . There is no topic. .Topic must be narrow and...         0   \n",
       "3081   Currently looking at SNORT system. Problems in...         1   \n",
       "4536   Starting point Literature review finding relat...         1   \n",
       "166    Monday November We have discussed with the stu...         1   \n",
       "11582  Upgraded mobile App Integrated code into Git M...         2   \n",
       "1070   Dillin has come back with an altered spec. He ...         1   \n",
       "5803    Use of 'walk forward validation' for implied ...         1   \n",
       "8601   Meeting note for Observation that more trainin...         1   \n",
       "10981  Capstone Interim Review Your explanation of th...         1   \n",
       "7929   Meeting Discussion of tools for construction o...         1   \n",
       "9724   They are proposing some kind of evolutionary n...         1   \n",
       "5364   Data has been obtained to begin experiments. S...         1   \n",
       "10427   meeting May The prototype is working. Still w...         1   \n",
       "3871   Initial meeting to discuss idea. Interested in...         2   \n",
       "7024   Date General update meeting with progress revi...         1   \n",
       "783    GUI working. Collisions working. Cell wall thi...         2   \n",
       "9880   Meeting happened before Christmas Discussed et...         1   \n",
       "7567                              project pitch feedback         1   \n",
       "4348   Met check function completed events importance...         1   \n",
       "997    Meeting took place in week of Semester Discuss...         1   \n",
       "3971   The proposal is in reasonably good shape. Try ...         2   \n",
       "5501   Literature review presented and is very approp...         2   \n",
       "5369   We just recapped everything from the previous ...         1   \n",
       "7401   Started the final documentation. Working on th...         1   \n",
       "1824        October meeting. Proposed project discussed.         1   \n",
       "11207               Meeting Dec Clearer idea of project.         1   \n",
       "10422   meeting April Discuss development of business...         1   \n",
       "10430  Discussed ethics form. Showed them where to fi...         1   \n",
       "4066   Initial meeting for discussion of the idea. Th...         1   \n",
       "2944   We switched from the Dementia UK dataset to AD...         1   \n",
       "10218  Discussed mid term delivery document Challenge...         1   \n",
       "7710   Students have started putting content into the...         1   \n",
       "8406   Background modelling traffic datasets foregrou...         2   \n",
       "11767  Metamask is working. A lot of work was require...         2   \n",
       "7921   Happy with progress. Now looking at using supe...         2   \n",
       "8762    Different SA packages If using prices think a...         1   \n",
       "\n",
       "       BERTlabel_1  BERTlabel_2  \n",
       "6537             2            1  \n",
       "9214             1            1  \n",
       "4311             2            1  \n",
       "1729             0            1  \n",
       "7655             2            2  \n",
       "1366             0            0  \n",
       "7326             2            1  \n",
       "3726             1            1  \n",
       "1723             2            1  \n",
       "9302             2            1  \n",
       "5755             2            1  \n",
       "9848             2            1  \n",
       "315              1            1  \n",
       "4490             0            1  \n",
       "10775            0            0  \n",
       "3081             0            1  \n",
       "4536             2            1  \n",
       "166              0            1  \n",
       "11582            2            2  \n",
       "1070             2            1  \n",
       "5803             1            1  \n",
       "8601             2            1  \n",
       "10981            0            0  \n",
       "7929             2            2  \n",
       "9724             2            1  \n",
       "5364             2            2  \n",
       "10427            2            1  \n",
       "3871             1            1  \n",
       "7024             2            1  \n",
       "783              2            1  \n",
       "9880             2            1  \n",
       "7567             1            1  \n",
       "4348             2            1  \n",
       "997              2            2  \n",
       "3971             1            1  \n",
       "5501             2            2  \n",
       "5369             2            2  \n",
       "7401             2            1  \n",
       "1824             2            1  \n",
       "11207            2            1  \n",
       "10422            2            1  \n",
       "10430            2            1  \n",
       "4066             2            1  \n",
       "2944             1            1  \n",
       "10218            2            1  \n",
       "7710             2            2  \n",
       "8406             1            1  \n",
       "11767            2            2  \n",
       "7921             2            2  \n",
       "8762             1            1  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dash_data[\"BERTlabel_1\"] = BERTlabel_1\n",
    "dash_data[\"BERTlabel_2\"] = BERTlabel_2\n",
    "dash_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "YjlGV60gNm72",
   "metadata": {
    "id": "YjlGV60gNm72"
   },
   "source": [
    "#### c. Save results in Excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "RaejEICEOPOd",
   "metadata": {
    "id": "RaejEICEOPOd"
   },
   "outputs": [],
   "source": [
    "# =======================================\n",
    "# Open file and initalise variables\n",
    "# =======================================\n",
    "#----- Open xlsx file\n",
    "os.chdir(PATH) #go to correct folder \n",
    "wb = load_workbook(filename = PATH + \"/result/BERT_eval_miniLabel.xlsx\")\n",
    "#----- Get the current Active Sheet\n",
    "ws = wb.active #or wb['SHEET_NAME']\n",
    "#----- Specify row index\n",
    "row = 2\n",
    "#----- If there is no first run (true only at the first use) \n",
    "if not(ws.cell(row,1).value): \n",
    "  ws.cell(row,1).value = 1 \n",
    "else: #increase number of runs \n",
    "  ws.cell(row,1).value = ws.cell(row,1).value + 1 \n",
    "#----- Update row index according to the number of runs and update col\n",
    "row = int(ws.cell(row,1).value) + 2\n",
    "\n",
    "# =======================================\n",
    "# Write information\n",
    "# =======================================\n",
    "#--Write model used for the predictions \n",
    "if CKP_NAME:\n",
    "  ws.cell(row,2).value = CKP_NAME\n",
    "else:\n",
    "   ws.cell(row,2).value = checkpoint_name[:-3]\n",
    "#--Write if the model was runned on the full dataset  or only on the Train set\n",
    "if FULL_RUN:\n",
    "  ws.cell(row,3).value = \"Full\"\n",
    "else:\n",
    "  ws.cell(row,3).value = \"Train\"\n",
    "\n",
    "#--Write number of labels\n",
    "ws.cell(row,11).value = NUM_LABELS\n",
    "\n",
    "########## Prediction RULE 1 \n",
    "#--Write Bert accuracy \n",
    "ws.cell(row,4).value = mini_accuracy\n",
    "#--Write Bert Cross Table \n",
    "ws.cell(row,5).value = str(mini_crossT)\n",
    "#--Write Bert F1-score \n",
    "ws.cell(row,6).value = mini_f1Score\n",
    "########## Prediction RULE 2 (BEST threshold) \n",
    "#--Write Best trheshold \n",
    "ws.cell(row,7).value = str(mini_BEST_T)\n",
    "#--Write Bert accuracy \n",
    "ws.cell(row,8).value = mini_accuracy_2\n",
    "#--Write Bert Cross Table \n",
    "ws.cell(row,9).value = str(mini_crossT_2)\n",
    "#--Write Bert F1-score \n",
    "ws.cell(row,10).value = mini_f1Score_2\n",
    "\n",
    "# =======================================\n",
    "# WRITE now all changes into the file \n",
    "# =======================================\n",
    "wb.save(PATH + \"/result/BERT_eval_miniLabel.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "209F6xeA1Icj",
   "metadata": {
    "id": "209F6xeA1Icj"
   },
   "source": [
    "### 5.4. Option B only: On testLabel dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "SSeqF_yR1NBK",
   "metadata": {
    "id": "SSeqF_yR1NBK"
   },
   "source": [
    "#### a. Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Ff6oiLy51f4y",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 267
    },
    "id": "Ff6oiLy51f4y",
    "outputId": "706faf45-4dfd-4c59-91fd-82af7cf628e3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation of the Bert classifier with prediction rule 1 on testLabel dataset:\n",
      "Accuracy: 80.00%\n",
      "F1-Score: 62.00%\n",
      "\n",
      "Contigency Table:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-0bb140ce-e86e-43b2-bdba-f97818eaa1b3\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>True_label</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Prediction</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0bb140ce-e86e-43b2-bdba-f97818eaa1b3')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-0bb140ce-e86e-43b2-bdba-f97818eaa1b3 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-0bb140ce-e86e-43b2-bdba-f97818eaa1b3');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "True_label  0   1  2\n",
       "Prediction          \n",
       "0           1   1  0\n",
       "1           2  34  4\n",
       "2           0   3  5"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the Bert classifier with the prediction rule 1 on testLabel dataset\n",
    "#-----------------------------------------------------------------------------\n",
    "print(\"Evaluation of the Bert classifier with prediction rule 1 on testLabel dataset:\")\n",
    "BERTlabel_1, crossT, test_accuracy, test_f1Score = evaluate_perf(dash_probs,\n",
    "                                                                 dash_data[\"TrueLabel\"].values)\n",
    "test_crossT = crossT.to_numpy().tolist() #convert crossT to list format for later use \n",
    "print(\"\\nContigency Table:\")\n",
    "crossT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "zzHcIJ9q1uIH",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 965
    },
    "id": "zzHcIJ9q1uIH",
    "outputId": "1914c419-27a8-4572-c614-3f00eed452ab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "threshold:  0.1\n",
      "Accuracy: 80.00%\n",
      "F1-Score: 62.00%\n",
      "\n",
      "threshold:  0.2\n",
      "Accuracy: 80.00%\n",
      "F1-Score: 62.00%\n",
      "\n",
      "threshold:  0.3\n",
      "Accuracy: 80.00%\n",
      "F1-Score: 62.00%\n",
      "\n",
      "threshold:  0.4\n",
      "Accuracy: 80.00%\n",
      "F1-Score: 62.00%\n",
      "\n",
      "threshold:  0.5\n",
      "Accuracy: 78.00%\n",
      "F1-Score: 58.69%\n",
      "\n",
      "threshold:  0.6\n",
      "Accuracy: 78.00%\n",
      "F1-Score: 58.69%\n",
      "\n",
      "threshold:  0.7\n",
      "Accuracy: 82.00%\n",
      "F1-Score: 62.01%\n",
      "\n",
      "threshold:  0.8\n",
      "Accuracy: 82.00%\n",
      "F1-Score: 62.01%\n",
      "\n",
      "threshold:  0.9\n",
      "Accuracy: 82.00%\n",
      "F1-Score: 62.01%\n",
      "\n",
      "test_BEST_T:  0.7\n",
      "\n",
      "Evaluation of the Bert classifier with prediction rule 2 using the Best Threshold on testLabel dataset:\n",
      "Accuracy: 82.00%\n",
      "F1-Score: 62.01%\n",
      "\n",
      "Contigency Table:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-d439dbef-fe3d-44b2-b6d4-5617372ae6fa\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>True_label</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Prediction</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>36</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d439dbef-fe3d-44b2-b6d4-5617372ae6fa')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-d439dbef-fe3d-44b2-b6d4-5617372ae6fa button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-d439dbef-fe3d-44b2-b6d4-5617372ae6fa');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "True_label  0   1  2\n",
       "Prediction          \n",
       "0           1   1  0\n",
       "1           2  36  5\n",
       "2           0   1  4"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the Bert classifier with the prediction rule 2  on testLabel dataset\n",
    "# using the Best Threshold found with function \"computeBest_T\"\n",
    "#---------------------------------------------------------\n",
    "T_grid = [.1,.2,.3,.4,.5,.6,.7,.8,.9] # grid of thresholds for the prediction rule 2 \n",
    "test_BEST_T = computeBest_T(T_grid,dash_probs,dash_data[\"TrueLabel\"].values)\n",
    "print(\"test_BEST_T: \", test_BEST_T)\n",
    "print(\"\")\n",
    "\n",
    "print(\"Evaluation of the Bert classifier with prediction rule 2 using the Best Threshold on testLabel dataset:\")\n",
    "BERTlabel_2, crossT_2, test_accuracy_2, test_f1Score_2 = evaluate_perf(dash_probs,\n",
    "                                                                       dash_data[\"TrueLabel\"].values,\n",
    "                                                                       rule=2,\n",
    "                                                                       T=test_BEST_T)\n",
    "test_crossT_2 = crossT_2.to_numpy().tolist() #convert crossT_2 to list format for later use \n",
    "print(\"\\nContigency Table:\")\n",
    "crossT_2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4KobxLXv1RSc",
   "metadata": {
    "id": "4KobxLXv1RSc"
   },
   "source": [
    "#### b. Add predicted labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "UV15h6pu1q3A",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "UV15h6pu1q3A",
    "outputId": "0156ca14-0f79-4488-beca-38392c103d6d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-2fd92d15-5eb5-426c-ac31-3d8d3f914714\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comments</th>\n",
       "      <th>TrueLabel</th>\n",
       "      <th>BERTlabel_1</th>\n",
       "      <th>BERTlabel_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6537</th>\n",
       "      <td>Met on</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9214</th>\n",
       "      <td>Meeting took place on February. this was bette...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4311</th>\n",
       "      <td>A lot of research into tech has been done. How...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1729</th>\n",
       "      <td>Meeting took place April MVP Minimum Viable Pr...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7655</th>\n",
       "      <td>Raspberry setup and can be connected to router...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1366</th>\n",
       "      <td>Progress Login Reg reset password done Bootstr...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7326</th>\n",
       "      <td>At the end of exams week we had a zoom call to...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3726</th>\n",
       "      <td>The proposal was discussed. Connor to think ab...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1723</th>\n",
       "      <td>Meeting took place on Met with student to disc...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9302</th>\n",
       "      <td>Meeting happened before Christmas Discussed et...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5755</th>\n",
       "      <td>Made on progress segmentation and setting up e...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9848</th>\n",
       "      <td>First meeting and an individual project. Plan ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>Bryan on balance a good amount of work has bee...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4490</th>\n",
       "      <td>Some hitches but now back on the track.</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10775</th>\n",
       "      <td>. There is no topic. .Topic must be narrow and...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3081</th>\n",
       "      <td>Currently looking at SNORT system. Problems in...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4536</th>\n",
       "      <td>Starting point Literature review finding relat...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>Monday November We have discussed with the stu...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11582</th>\n",
       "      <td>Upgraded mobile App Integrated code into Git M...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1070</th>\n",
       "      <td>Dillin has come back with an altered spec. He ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5803</th>\n",
       "      <td>Use of 'walk forward validation' for implied ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8601</th>\n",
       "      <td>Meeting note for Observation that more trainin...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10981</th>\n",
       "      <td>Capstone Interim Review Your explanation of th...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7929</th>\n",
       "      <td>Meeting Discussion of tools for construction o...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9724</th>\n",
       "      <td>They are proposing some kind of evolutionary n...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5364</th>\n",
       "      <td>Data has been obtained to begin experiments. S...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10427</th>\n",
       "      <td>meeting May The prototype is working. Still w...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3871</th>\n",
       "      <td>Initial meeting to discuss idea. Interested in...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7024</th>\n",
       "      <td>Date General update meeting with progress revi...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>783</th>\n",
       "      <td>GUI working. Collisions working. Cell wall thi...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9880</th>\n",
       "      <td>Meeting happened before Christmas Discussed et...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7567</th>\n",
       "      <td>project pitch feedback</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4348</th>\n",
       "      <td>Met check function completed events importance...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>Meeting took place in week of Semester Discuss...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3971</th>\n",
       "      <td>The proposal is in reasonably good shape. Try ...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5501</th>\n",
       "      <td>Literature review presented and is very approp...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5369</th>\n",
       "      <td>We just recapped everything from the previous ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7401</th>\n",
       "      <td>Started the final documentation. Working on th...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1824</th>\n",
       "      <td>October meeting. Proposed project discussed.</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11207</th>\n",
       "      <td>Meeting Dec Clearer idea of project.</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10422</th>\n",
       "      <td>meeting April Discuss development of business...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10430</th>\n",
       "      <td>Discussed ethics form. Showed them where to fi...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4066</th>\n",
       "      <td>Initial meeting for discussion of the idea. Th...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2944</th>\n",
       "      <td>We switched from the Dementia UK dataset to AD...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10218</th>\n",
       "      <td>Discussed mid term delivery document Challenge...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7710</th>\n",
       "      <td>Students have started putting content into the...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8406</th>\n",
       "      <td>Background modelling traffic datasets foregrou...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11767</th>\n",
       "      <td>Metamask is working. A lot of work was require...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7921</th>\n",
       "      <td>Happy with progress. Now looking at using supe...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8762</th>\n",
       "      <td>Different SA packages If using prices think a...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2fd92d15-5eb5-426c-ac31-3d8d3f914714')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-2fd92d15-5eb5-426c-ac31-3d8d3f914714 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-2fd92d15-5eb5-426c-ac31-3d8d3f914714');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "                                                comments TrueLabel  \\\n",
       "6537                                             Met on          1   \n",
       "9214   Meeting took place on February. this was bette...         0   \n",
       "4311   A lot of research into tech has been done. How...         2   \n",
       "1729   Meeting took place April MVP Minimum Viable Pr...         1   \n",
       "7655   Raspberry setup and can be connected to router...         1   \n",
       "1366   Progress Login Reg reset password done Bootstr...         1   \n",
       "7326   At the end of exams week we had a zoom call to...         1   \n",
       "3726   The proposal was discussed. Connor to think ab...         1   \n",
       "1723   Meeting took place on Met with student to disc...         1   \n",
       "9302   Meeting happened before Christmas Discussed et...         1   \n",
       "5755   Made on progress segmentation and setting up e...         1   \n",
       "9848   First meeting and an individual project. Plan ...         1   \n",
       "315    Bryan on balance a good amount of work has bee...         0   \n",
       "4490             Some hitches but now back on the track.         1   \n",
       "10775  . There is no topic. .Topic must be narrow and...         0   \n",
       "3081   Currently looking at SNORT system. Problems in...         1   \n",
       "4536   Starting point Literature review finding relat...         1   \n",
       "166    Monday November We have discussed with the stu...         1   \n",
       "11582  Upgraded mobile App Integrated code into Git M...         2   \n",
       "1070   Dillin has come back with an altered spec. He ...         1   \n",
       "5803    Use of 'walk forward validation' for implied ...         1   \n",
       "8601   Meeting note for Observation that more trainin...         1   \n",
       "10981  Capstone Interim Review Your explanation of th...         1   \n",
       "7929   Meeting Discussion of tools for construction o...         1   \n",
       "9724   They are proposing some kind of evolutionary n...         1   \n",
       "5364   Data has been obtained to begin experiments. S...         1   \n",
       "10427   meeting May The prototype is working. Still w...         1   \n",
       "3871   Initial meeting to discuss idea. Interested in...         2   \n",
       "7024   Date General update meeting with progress revi...         1   \n",
       "783    GUI working. Collisions working. Cell wall thi...         2   \n",
       "9880   Meeting happened before Christmas Discussed et...         1   \n",
       "7567                              project pitch feedback         1   \n",
       "4348   Met check function completed events importance...         1   \n",
       "997    Meeting took place in week of Semester Discuss...         1   \n",
       "3971   The proposal is in reasonably good shape. Try ...         2   \n",
       "5501   Literature review presented and is very approp...         2   \n",
       "5369   We just recapped everything from the previous ...         1   \n",
       "7401   Started the final documentation. Working on th...         1   \n",
       "1824        October meeting. Proposed project discussed.         1   \n",
       "11207               Meeting Dec Clearer idea of project.         1   \n",
       "10422   meeting April Discuss development of business...         1   \n",
       "10430  Discussed ethics form. Showed them where to fi...         1   \n",
       "4066   Initial meeting for discussion of the idea. Th...         1   \n",
       "2944   We switched from the Dementia UK dataset to AD...         1   \n",
       "10218  Discussed mid term delivery document Challenge...         1   \n",
       "7710   Students have started putting content into the...         1   \n",
       "8406   Background modelling traffic datasets foregrou...         2   \n",
       "11767  Metamask is working. A lot of work was require...         2   \n",
       "7921   Happy with progress. Now looking at using supe...         2   \n",
       "8762    Different SA packages If using prices think a...         1   \n",
       "\n",
       "       BERTlabel_1  BERTlabel_2  \n",
       "6537             1            1  \n",
       "9214             1            1  \n",
       "4311             2            1  \n",
       "1729             1            1  \n",
       "7655             2            2  \n",
       "1366             1            1  \n",
       "7326             1            1  \n",
       "3726             1            1  \n",
       "1723             1            1  \n",
       "9302             1            1  \n",
       "5755             1            1  \n",
       "9848             1            1  \n",
       "315              1            1  \n",
       "4490             1            1  \n",
       "10775            0            0  \n",
       "3081             1            1  \n",
       "4536             1            1  \n",
       "166              1            1  \n",
       "11582            2            2  \n",
       "1070             1            1  \n",
       "5803             1            1  \n",
       "8601             2            1  \n",
       "10981            0            0  \n",
       "7929             1            1  \n",
       "9724             1            1  \n",
       "5364             2            1  \n",
       "10427            1            1  \n",
       "3871             1            1  \n",
       "7024             1            1  \n",
       "783              1            1  \n",
       "9880             1            1  \n",
       "7567             1            1  \n",
       "4348             1            1  \n",
       "997              1            1  \n",
       "3971             2            2  \n",
       "5501             2            2  \n",
       "5369             1            1  \n",
       "7401             1            1  \n",
       "1824             1            1  \n",
       "11207            1            1  \n",
       "10422            1            1  \n",
       "10430            1            1  \n",
       "4066             1            1  \n",
       "2944             1            1  \n",
       "10218            1            1  \n",
       "7710             1            1  \n",
       "8406             2            2  \n",
       "11767            1            1  \n",
       "7921             1            1  \n",
       "8762             1            1  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dash_data[\"BERTlabel_1\"] = BERTlabel_1\n",
    "dash_data[\"BERTlabel_2\"] = BERTlabel_2\n",
    "dash_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8UFXtgwY1T-q",
   "metadata": {
    "id": "8UFXtgwY1T-q"
   },
   "source": [
    "#### c. Save results in Excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "xZYgUkzB19-R",
   "metadata": {
    "id": "xZYgUkzB19-R"
   },
   "outputs": [],
   "source": [
    "# =======================================\n",
    "# Open file and initalise variables\n",
    "# =======================================\n",
    "#----- Open xlsx file\n",
    "os.chdir(PATH) #go to correct folder \n",
    "wb = load_workbook(filename = PATH + \"/result/BERT_test_testLabel.xlsx\")\n",
    "#----- Get the current Active Sheet\n",
    "ws = wb.active #or wb['SHEET_NAME']\n",
    "#----- Specify row index\n",
    "row = 2\n",
    "#----- If there is no first run (true only at the first use) \n",
    "if not(ws.cell(row,1).value): \n",
    "  ws.cell(row,1).value = 1 \n",
    "else: #increase number of runs \n",
    "  ws.cell(row,1).value = ws.cell(row,1).value + 1 \n",
    "#----- Update row index according to the number of runs and update col\n",
    "row = int(ws.cell(row,1).value) + 2\n",
    "\n",
    "# =======================================\n",
    "# Write information\n",
    "# =======================================\n",
    "#--Write model used for the predictions \n",
    "if CKP_NAME:\n",
    "  ws.cell(row,2).value = CKP_NAME\n",
    "else:\n",
    "   ws.cell(row,2).value = checkpoint_name[:-3]\n",
    "#--Write if the model was runned on the full dataset  or only on the Train set\n",
    "if FULL_RUN:\n",
    "  ws.cell(row,3).value = \"Full\"\n",
    "else:\n",
    "  ws.cell(row,3).value = \"Train\"\n",
    "\n",
    "#--Write number of labels\n",
    "ws.cell(row,11).value = NUM_LABELS\n",
    "\n",
    "########## Prediction RULE 1 \n",
    "#--Write Bert accuracy \n",
    "ws.cell(row,4).value = test_accuracy\n",
    "#--Write Bert Cross Table \n",
    "ws.cell(row,5).value = str(test_crossT)\n",
    "#--Write Bert F1-score \n",
    "ws.cell(row,6).value = test_f1Score\n",
    "########## Prediction RULE 2 (BEST threshold) \n",
    "#--Write Best trheshold \n",
    "ws.cell(row,7).value = str(test_BEST_T)\n",
    "#--Write Bert accuracy \n",
    "ws.cell(row,8).value = test_accuracy_2\n",
    "#--Write Bert Cross Table \n",
    "ws.cell(row,9).value = str(test_crossT_2)\n",
    "#--Write Bert F1-score \n",
    "ws.cell(row,10).value = test_f1Score_2\n",
    "\n",
    "# =======================================\n",
    "# WRITE now all changes into the file \n",
    "# =======================================\n",
    "wb.save(PATH + \"/result/BERT_test_testLabel.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "COIr2uYaN06U",
   "metadata": {
    "id": "COIr2uYaN06U"
   },
   "source": [
    "### 5.5. Option C only: On dashbord dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "DdF0wK5zMZcG",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "DdF0wK5zMZcG",
    "outputId": "7f296f53-8b6a-4cd3-eeb6-e3bccde4d029"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-70eb6a90-bbcd-4d84-ac68-ba2850105ce0\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comments</th>\n",
       "      <th>BERTlabel_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This is a test</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Watch out for peer reviews journals looking fo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Discussed general outline of paper i.e. resear...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ed emailed the progress report below in advanc...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data preparation in terms of cleaning has been...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-70eb6a90-bbcd-4d84-ac68-ba2850105ce0')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-70eb6a90-bbcd-4d84-ac68-ba2850105ce0 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-70eb6a90-bbcd-4d84-ac68-ba2850105ce0');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "                                            comments  BERTlabel_1\n",
       "0                                     This is a test            1\n",
       "1  Watch out for peer reviews journals looking fo...            1\n",
       "2  Discussed general outline of paper i.e. resear...            1\n",
       "3  Ed emailed the progress report below in advanc...            1\n",
       "5  Data preparation in terms of cleaning has been...            1"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BERTlabel_1 = predictionRule(dash_probs,rule=1)\n",
    "#BERTlabel_2 = predictionRule(dash_probs,rule=2,T = 0.1)\n",
    "\n",
    "dash_data[\"BERTlabel_1\"] = BERTlabel_1\n",
    "#dash_data[\"BERTlabel_2\"] = BERTlabel_2\n",
    "dash_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mUduyOiWL2ev",
   "metadata": {
    "id": "mUduyOiWL2ev"
   },
   "source": [
    "### 5.5. Pickle results (run for A,B,C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dAJixTpJI6NN",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "dAJixTpJI6NN",
    "outputId": "59d6ecf6-dc4e-45b0-d572-a3ff93097c78"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-2ab183c3-3a07-49fe-9a74-3abbd6b131d8\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comments</th>\n",
       "      <th>BERTlabel_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This is a test</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Watch out for peer reviews journals looking fo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Discussed general outline of paper i.e. resear...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ed emailed the progress report below in advanc...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data preparation in terms of cleaning has been...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11784</th>\n",
       "      <td>Progress has stalled slightly due to losing co...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11785</th>\n",
       "      <td>Your ethics and GDPR submission has been appro...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11786</th>\n",
       "      <td>Rachel and Ryan making good progress. Design a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11787</th>\n",
       "      <td>Ethics document reviewed by Supervisor.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11788</th>\n",
       "      <td>All going well Autocomplete working Locally ar...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11356 rows × 2 columns</p>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2ab183c3-3a07-49fe-9a74-3abbd6b131d8')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-2ab183c3-3a07-49fe-9a74-3abbd6b131d8 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-2ab183c3-3a07-49fe-9a74-3abbd6b131d8');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "                                                comments  BERTlabel_1\n",
       "0                                         This is a test            1\n",
       "1      Watch out for peer reviews journals looking fo...            1\n",
       "2      Discussed general outline of paper i.e. resear...            1\n",
       "3      Ed emailed the progress report below in advanc...            1\n",
       "5      Data preparation in terms of cleaning has been...            1\n",
       "...                                                  ...          ...\n",
       "11784  Progress has stalled slightly due to losing co...            0\n",
       "11785  Your ethics and GDPR submission has been appro...            1\n",
       "11786  Rachel and Ryan making good progress. Design a...            1\n",
       "11787            Ethics document reviewed by Supervisor.            1\n",
       "11788  All going well Autocomplete working Locally ar...            1\n",
       "\n",
       "[11356 rows x 2 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dash_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "RYnUEy3CI6J1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "id": "RYnUEy3CI6J1",
    "outputId": "5bbccde2-204b-4cb0-8059-41bbd81e1cc0"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'\\ndash_data_name = \"dashData_from:2022-07-26_13:42:28_full_checkpoint\"\\n\\nos.chdir(PATH + \\'/6_ProbsDashbord_pkl\\') #go to correct folder \\ndash_data = pd.read_pickle(dash_data_name + \\'.pkl\\')\\nos.chdir(PATH)\\n'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#----- Pickle results for later use \n",
    "\n",
    "NAME_DATA = \"dash\"       # if the dataset is the entire dashbord\n",
    "#NAME_DATA = \"miniLabel\"  # if the dataset is the miniLabel\n",
    "#NAME_DATA = \"testLabel\"    # if the dataset is the testLabel\n",
    "\n",
    "#if dash_probs were calculated from a resumed fine-tuned model:\n",
    "if CKP_NAME: \n",
    "  dash_data_name = NAME_DATA + \"Data_from:\" + CKP_NAME + \".pkl\"\n",
    "#if dash_probs were calculated from a model fine-tuned in this notebook:\n",
    "else:\n",
    "  dash_data_name = NAME_DATA + \"Data_from:\" + checkpoint_name[:-3] + \".pkl\"\n",
    "\n",
    "os.chdir(PATH + '/6_ProbsDashbord_pkl') #go to correct folder \n",
    "dash_data.to_pickle(dash_data_name) #pickle dataset\n",
    "os.chdir(PATH) #return to main folder\n",
    "\n",
    "#----- Retrieve Probs results  \n",
    "\"\"\"\n",
    "dash_data_name = \"dashData_from:2022-07-26_13:42:28_full_checkpoint\"\n",
    "\n",
    "os.chdir(PATH + '/6_ProbsDashbord_pkl') #go to correct folder \n",
    "dash_data = pd.read_pickle(dash_data_name + '.pkl')\n",
    "os.chdir(PATH)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "DsIXaerfSoaj",
   "metadata": {
    "id": "DsIXaerfSoaj"
   },
   "source": [
    "## 6.Find the best dataset mix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27YaDvRzbXe6",
   "metadata": {
    "id": "27YaDvRzbXe6"
   },
   "outputs": [],
   "source": [
    "def computeRanking(display = True,sortByF1 = True,howMuchDisplay = 7,remove=[]):\n",
    "  \"\"\"\n",
    "  This function computes the ranking according to the Accuracy of F1-score\n",
    "  of the predictions on the miniLabel dataset.\n",
    "  ---> input:\n",
    "  - display(bool): if True displays the ranking\n",
    "  - sortByF1 (bool): if True sort by the F1-score, if False sort by the Accuracy\n",
    "  - howMuchDisplay (integer ranging from 1 to 7): indicates  how many results to show\n",
    "  - remove (list): list containing the dates of the rows we want to remove from the \n",
    "  ranking. Each element of this list must be of the form \"2022-08-11_09:41:30\"\n",
    "  ---> ouput:\n",
    "  - miniLabel_perf (list): list containing 4 dataframes:\n",
    "    * miniLabel_perf[0]: Ranking in the case of 3 labels with rule 1 \n",
    "    * miniLabel_perf[1]: Ranking in the case of 3 labels with rule 2 \n",
    "    * miniLabel_perf[2]: Ranking in the case of 2 labels with rule 1 \n",
    "    * miniLabel_perf[3]: Ranking in the case of 2 labels with rule 2 \n",
    "  \"\"\"\n",
    "  #========================================\n",
    "  # Retrieve results from all the runs (which are stored in excel file)\n",
    "  #========================================\n",
    "  os.chdir(PATH) #go to main folder\n",
    "  BERT_eval_miniLabel = pd.read_excel(\"result/BERT_eval_miniLabel.xlsx\", header=None)\n",
    "  BERT_runs_2 = pd.read_excel(\"result/BERT_runs_2.xlsx\", header=None)\n",
    "\n",
    "  #-- Formatting BERT_eval_miniLabel into miniLabel_perf\n",
    "  if sortByF1:\n",
    "    # columns 5 and 9 corresponds to F1-score: \n",
    "    BERT_eval_miniLabel =  BERT_eval_miniLabel[[10,1,5,9]].copy() #select only columns of interest\n",
    "    rule_name = \"F1score\"\n",
    "    BERT_eval_miniLabel.rename(columns = {10: \"numLabels\", 1: \"fromModel\",5 : rule_name+\"1\", 9 : rule_name+\"2\" },inplace = True)\n",
    "  else:  \n",
    "    BERT_eval_miniLabel =  BERT_eval_miniLabel[[10,1,3,7]].copy() #select only columns of interest\n",
    "    rule_name = \"accuracy\"\n",
    "    BERT_eval_miniLabel.rename(columns = {10: \"numLabels\", 1: \"fromModel\",3 : rule_name+\"1\", 7 : rule_name+\"2\" },inplace = True)\n",
    "    # columns 3 and 7 corresponds to accuracy\n",
    "  \n",
    "  \n",
    "  BERT_eval_miniLabel.drop([0,1],axis=0,inplace = True) #drop first 2 rows\n",
    "  BERT_eval_miniLabel.reset_index(drop=True,inplace=True) #reset indices\n",
    "\n",
    "  #-- Formatting BERT_runs_2\n",
    "  BERT_runs_2 = BERT_runs_2[[22,1,4,5,7]].copy() #select only columns of interest\n",
    "  BERT_runs_2.drop([0,1],axis = 0, inplace = True) #drop first 2 rows\n",
    "  BERT_runs_2.rename(columns = {22:\"numLabels\",1:\"date\",4:\"fullRun\",5:\"names\",7:\"mix\"},inplace = True)\n",
    "  BERT_runs_2.reset_index(drop=True,inplace=True) #reset indices\n",
    "  BERT_runs_2.drop(np.where(BERT_runs_2.fullRun == \"Train\")[0],axis = 0,inplace = True) #drop rows corresponding to fullRun = Train\n",
    "  BERT_runs_2.reset_index(drop=True,inplace=True) #reset indices again\n",
    "\n",
    "  #-- Remove certain rows from the ranking\n",
    "  if len(remove) != 0:\n",
    "    for i in range(len(remove)):\n",
    "      idx_rm_miniLabel = np.where(BERT_eval_miniLabel.fromModel == remove[i]+\"_full_checkpoint\")[0]\n",
    "      idx_rm_bertRuns2 = np.where(BERT_runs_2.date == remove[i])[0]\n",
    "      BERT_eval_miniLabel.drop(BERT_eval_miniLabel.index[idx_rm_miniLabel],axis=0,inplace = True)\n",
    "      BERT_runs_2.drop(BERT_runs_2.index[idx_rm_bertRuns2],axis=0,inplace = True)\n",
    "\n",
    "  #========================================\n",
    "  # Find the Names and Mix corresponding to each result\n",
    "  #========================================\n",
    "  Mix = []\n",
    "  Names = []\n",
    "  for i in range(len(BERT_eval_miniLabel)):\n",
    "    date = BERT_eval_miniLabel.fromModel.iloc[i][:19] #select the date of the model used for predictions\n",
    "    idx = np.where(BERT_runs_2.date == date)[0][0] #index to find in BERT_runs_2 the correct model\n",
    "    Names.append(BERT_runs_2.names.iloc[idx])\n",
    "    Mix.append(BERT_runs_2.mix.iloc[idx])\n",
    "\n",
    "  #-- Update miniLabel_perf\n",
    "  BERT_eval_miniLabel[\"Names\"] = Names\n",
    "  BERT_eval_miniLabel[\"Mix\"] = Mix\n",
    "\n",
    "  #========================================\n",
    "  # Create new dataframes to store each sorted result\n",
    "  #========================================\n",
    "  miniLabel_perf = [] #list containing dataframes with the performances of each prediction rule for each label\n",
    "  numLabels = [3,3,2,2] #number of labels in each case\n",
    "  rule = [1,2,1,2] #rule used in each case\n",
    "\n",
    "  for i in range(4):\n",
    "    #-- Update miniLabel_perf in case we want to use these results later\n",
    "    miniLabel_perf.append(\n",
    "        BERT_eval_miniLabel\n",
    "        .iloc[np.where(BERT_eval_miniLabel.numLabels == numLabels[i])]\n",
    "        .sort_values(by = [rule_name+str(rule[i])],ascending=False)\n",
    "        .copy()\n",
    "        ) \n",
    "\n",
    "  if display:\n",
    "    for k in range(len(miniLabel_perf)):\n",
    "      df = miniLabel_perf[k]\n",
    "      print(\"================================================\")\n",
    "      print(\"Ranking in the case of {} labels with rule n°{}:\".format(numLabels[k],rule[k]))\n",
    "      print(\"================================================\")\n",
    "      for i in range(howMuchDisplay):\n",
    "        print(\"position {}: \".format(i+1))\n",
    "        print(\"-----------\")\n",
    "        print(\"From: \",df.fromModel.iloc[i] )\n",
    "        print(\"Names: \",df.Names.iloc[i])\n",
    "        print(\"Mix: \",df.Mix.iloc[i])\n",
    "        print(rule_name + \": \",df[rule_name+str(rule[k])].iloc[i])\n",
    "        print(\"\")\n",
    "\n",
    "  return miniLabel_perf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sGIrDtdkFIs-",
   "metadata": {
    "id": "sGIrDtdkFIs-"
   },
   "outputs": [],
   "source": [
    " miniLabel_perf = computeRanking(\n",
    "    display=False,\n",
    "    sortByF1 = True,\n",
    "    howMuchDisplay=3,\n",
    "    remove=[\"2022-08-10_14:37:14\",\"2022-08-11_09:41:30\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5Zu42U5GHjm8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5Zu42U5GHjm8",
    "outputId": "c456034d-1f94-4724-97db-6af89800bb55"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================\n",
      "Ranking in the case of 3 labels with rule n°1:\n",
      "================================================\n",
      "position 1: \n",
      "-----------\n",
      "From:  2022-08-13_13:46:24_full_checkpoint\n",
      "Names:  dashbordLabel\n",
      "Mix:  200_original+200_eng-de+200_eng-fr+200_eng-zh+200_embeddings\n",
      "F1score:  0.7799135519959318\n",
      "\n",
      "position 2: \n",
      "-----------\n",
      "From:  2022-08-13_14:11:55_full_checkpoint\n",
      "Names:  dashbordLabel\n",
      "Mix:  200_original+200_eng-de+200_eng-fr+200_eng-zh+200_embeddings\n",
      "F1score:  0.7556067588325653\n",
      "\n",
      "================================================\n",
      "Ranking in the case of 3 labels with rule n°2:\n",
      "================================================\n",
      "position 1: \n",
      "-----------\n",
      "From:  2022-08-13_13:46:24_full_checkpoint\n",
      "Names:  dashbordLabel\n",
      "Mix:  200_original+200_eng-de+200_eng-fr+200_eng-zh+200_embeddings\n",
      "F1score:  0.7799135519959318\n",
      "\n",
      "position 2: \n",
      "-----------\n",
      "From:  2022-08-13_14:11:55_full_checkpoint\n",
      "Names:  dashbordLabel\n",
      "Mix:  200_original+200_eng-de+200_eng-fr+200_eng-zh+200_embeddings\n",
      "F1score:  0.7556067588325653\n",
      "\n",
      "================================================\n",
      "Ranking in the case of 2 labels with rule n°1:\n",
      "================================================\n",
      "position 1: \n",
      "-----------\n",
      "From:  2022-08-18_10:14:36_full_checkpoint\n",
      "Names:  dashbordLabel\n",
      "Mix:  5 copies of the 200 comments of dashbordLabel = 1000 comments\n",
      "F1score:  0.8319327731092439\n",
      "\n",
      "position 2: \n",
      "-----------\n",
      "From:  2022-08-18_10:50:40_full_checkpoint\n",
      "Names:  dashbordLabel\n",
      "Mix:  200_original+200_eng-de+200_eng-fr+200_eng-zh+200_embeddings\n",
      "F1score:  0.8319327731092439\n",
      "\n",
      "================================================\n",
      "Ranking in the case of 2 labels with rule n°2:\n",
      "================================================\n",
      "position 1: \n",
      "-----------\n",
      "From:  2022-08-18_10:14:36_full_checkpoint\n",
      "Names:  dashbordLabel\n",
      "Mix:  5 copies of the 200 comments of dashbordLabel = 1000 comments\n",
      "F1score:  0.8319327731092439\n",
      "\n",
      "position 2: \n",
      "-----------\n",
      "From:  2022-08-18_10:50:40_full_checkpoint\n",
      "Names:  dashbordLabel\n",
      "Mix:  200_original+200_eng-de+200_eng-fr+200_eng-zh+200_embeddings\n",
      "F1score:  0.8319327731092439\n",
      "\n"
     ]
    }
   ],
   "source": [
    "miniLabel_perf = computeRanking(display=True,sortByF1 = True,howMuchDisplay=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4vNWPakoQQE_",
   "metadata": {
    "id": "4vNWPakoQQE_"
   },
   "source": [
    "### 6.1. Analysis of the results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8-psI7e8GnpV",
   "metadata": {
    "id": "8-psI7e8GnpV"
   },
   "source": [
    "<font color = \"purple\" > Ranking of BERT fine-tuned models with **6000 comments** on the miniLabel dataset: </font> \n",
    "\n",
    "```\n",
    "================================================\n",
    "Ranking in the case of 3 labels with rule n°1:\n",
    "================================================\n",
    "position 1: \n",
    "-----------\n",
    "Names:  amazon_review_full_csv\n",
    "Mix:  6000 comments of dataset df3 (0.2%)\n",
    "F1score:  0.634920634920635\n",
    "\n",
    "position 2: \n",
    "-----------\n",
    "Names:  Amazon Kindle Book Review for Sentiment Analysis + Financial Sentiment Analysis + amazon_review_full_csv\n",
    "Mix:  2000 comments of dataset df0 (16.7%) + 2000 comments of dataset df2 (34.2%) + 2000 comments of dataset df3 (0.1%)\n",
    "F1score:  0.6168752744839702\n",
    "\n",
    "position 3: \n",
    "-----------\n",
    "Names:  Amazon Kindle Book Review for Sentiment Analysis + Financial Sentiment Analysis + amazon_review_full_csv\n",
    "Mix:  1000 comments of dataset df0 (8.3%) + 4000 comments of dataset df2 (68.5%) + 1000 comments of dataset df3 (0.0%)\n",
    "F1score:  0.6052323103154306\n",
    "\n",
    "================================================\n",
    "Ranking in the case of 3 labels with rule n°2:\n",
    "================================================\n",
    "position 1: \n",
    "-----------\n",
    "Names:  amazon_review_full_csv\n",
    "Mix:  6000 comments of dataset df3 (0.2%)\n",
    "F1score:  0.7173821548821548\n",
    "\n",
    "position 2: \n",
    "-----------\n",
    "Names:  Amazon Kindle Book Review for Sentiment Analysis + Financial Sentiment Analysis + amazon_review_full_csv\n",
    "Mix:  1000 comments of dataset df0 (8.3%) + 1000 comments of dataset df2 (17.1%) + 4000 comments of dataset df3 (0.1%)\n",
    "F1score:  0.6675381263616558\n",
    "\n",
    "position 3: \n",
    "-----------\n",
    "Names:  Amazon Kindle Book Review for Sentiment Analysis + Financial Sentiment Analysis + amazon_review_full_csv\n",
    "Mix:  2000 comments of dataset df0 (16.7%) + 2000 comments of dataset df2 (34.2%) + 2000 comments of dataset df3 (0.1%)\n",
    "F1score:  0.6388746803069054\n",
    "\n",
    "================================================\n",
    "Ranking in the case of 2 labels with rule n°1:\n",
    "================================================\n",
    "position 1: \n",
    "-----------\n",
    "Names:  Amazon Kindle Book Review for Sentiment Analysis + IMDB dataset Sentiment analysis + amazon_review_full_csv\n",
    "Mix:  1000 comments of dataset df0 (8.3%) + 4000 comments of dataset df1 (10.0%) + 1000 comments of dataset df2 (0.0%)\n",
    "F1score:  0.7591973244147158\n",
    "\n",
    "position 2: \n",
    "-----------\n",
    "Names:  IMDB dataset Sentiment analysis\n",
    "Mix:  6000 comments of dataset df1 (15.0%)\n",
    "F1score:  0.75\n",
    "\n",
    "position 3: \n",
    "-----------\n",
    "Names:  Amazon Kindle Book Review for Sentiment Analysis + IMDB dataset Sentiment analysis + amazon_review_full_csv\n",
    "Mix:  2000 comments of dataset df0 (16.7%) + 2000 comments of dataset df1 (5.0%) + 2000 comments of dataset df2 (0.1%)\n",
    "F1score:  0.7450826121164438\n",
    "\n",
    "================================================\n",
    "Ranking in the case of 2 labels with rule n°2:\n",
    "================================================\n",
    "position 1: \n",
    "-----------\n",
    "Names:  Amazon Kindle Book Review for Sentiment Analysis + IMDB dataset Sentiment analysis + amazon_review_full_csv\n",
    "Mix:  2000 comments of dataset df0 (16.7%) + 2000 comments of dataset df1 (5.0%) + 2000 comments of dataset df2 (0.1%)\n",
    "F1score:  0.8246753246753247\n",
    "\n",
    "position 2: \n",
    "-----------\n",
    "Names:  Amazon Kindle Book Review for Sentiment Analysis + IMDB dataset Sentiment analysis + amazon_review_full_csv\n",
    "Mix:  1000 comments of dataset df0 (8.3%) + 1000 comments of dataset df1 (2.5%) + 4000 comments of dataset df2 (0.1%)\n",
    "F1score:  0.7925925925925926\n",
    "\n",
    "position 3: \n",
    "-----------\n",
    "Names:  Amazon Kindle Book Review for Sentiment Analysis + IMDB dataset Sentiment analysis + amazon_review_full_csv\n",
    "Mix:  4000 comments of dataset df0 (33.3%) + 1000 comments of dataset df1 (2.5%) + 1000 comments of dataset df2 (0.0%)\n",
    "F1score:  0.785531914893617\n",
    "\n",
    "```\n",
    "\n",
    "**Analysis:** \n",
    "- With **3 labels**: we see that in both rules, the best result is obtained with for: \n",
    "```\n",
    "Names:  amazon_review_full_csv\n",
    "Mix:  6000 comments of dataset df3 (0.2%)\n",
    "```\n",
    "To see if the amount of data has an inpact on the results, we increase the number of comment from 6000 to 18000 in the ```amazon_review_full_csv``` dataset only, obtaining the mix: \n",
    "```\n",
    "Names:  amazon_review_full_csv\n",
    "Mix:  18000 comments of dataset df3 (0.6%)\n",
    "```\n",
    "\n",
    "- With **2 labels**: we see that in both rules, the best result is obtained with a mix of ```amazon_review_full_csv``` and ```IMDB dataset Sentiment analysis``` where amazon  comments is globally (ie over the 2 rules) more numerous than IMBD.\n",
    "To see if the amount of data has an inpact on the results, we increase the number of comment from 6000 to 18000, obtaining the mix: \n",
    "```\n",
    "Names: IMDB dataset Sentiment analysis + amazon_review_full_csv\n",
    "Mix: 6000 comments of dataset df1 (15.0%) + 12000 comments of dataset df2 (0.4%)\n",
    "```\n",
    "We also decided to put more text from ```amazon_review_full_csv``` as it is a more general dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "YN5dWTP1HJsc",
   "metadata": {
    "id": "YN5dWTP1HJsc"
   },
   "source": [
    "<font color = \"purple\" > Ranking of BERT fine-tuned models including **6000 and 18000 comments** on the miniLabel dataset: </font> \n",
    "\n",
    "```\n",
    "================================================\n",
    "Ranking in the case of 3 labels with rule n°1:\n",
    "================================================\n",
    "position 1: \n",
    "-----------\n",
    "Names:  amazon_review_full_csv\n",
    "Mix:  6000 comments of dataset df3 (0.2%)\n",
    "F1score:  0.634920634920635\n",
    "\n",
    "position 2: \n",
    "-----------\n",
    "Names:  Amazon Kindle Book Review for Sentiment Analysis + Financial Sentiment Analysis + amazon_review_full_csv\n",
    "Mix:  2000 comments of dataset df0 (16.7%) + 2000 comments of dataset df2 (34.2%) + 2000 comments of dataset df3 (0.1%)\n",
    "F1score:  0.6168752744839702\n",
    "\n",
    "================================================\n",
    "Ranking in the case of 3 labels with rule n°2:\n",
    "================================================\n",
    "position 1: \n",
    "-----------\n",
    "Names:  amazon_review_full_csv\n",
    "Mix:  6000 comments of dataset df3 (0.2%)\n",
    "F1score:  0.7173821548821548\n",
    "\n",
    "position 2: \n",
    "-----------\n",
    "Names:  amazon_review_full_csv\n",
    "Mix:  18000 comments of dataset df3 (0.6%)\n",
    "F1score:  0.6914786967418548\n",
    "\n",
    "================================================\n",
    "Ranking in the case of 2 labels with rule n°1:\n",
    "================================================\n",
    "position 1: \n",
    "-----------\n",
    "Names:  Amazon Kindle Book Review for Sentiment Analysis + IMDB dataset Sentiment analysis + amazon_review_full_csv\n",
    "Mix:  1000 comments of dataset df0 (8.3%) + 4000 comments of dataset df1 (10.0%) + 1000 comments of dataset df2 (0.0%)\n",
    "F1score:  0.7591973244147158\n",
    "\n",
    "position 2: \n",
    "-----------\n",
    "Names:  IMDB dataset Sentiment analysis\n",
    "Mix:  6000 comments of dataset df1 (15.0%)\n",
    "F1score:  0.75\n",
    "\n",
    "================================================\n",
    "Ranking in the case of 2 labels with rule n°2:\n",
    "================================================\n",
    "position 1: \n",
    "-----------\n",
    "Names:  Amazon Kindle Book Review for Sentiment Analysis + IMDB dataset Sentiment analysis + amazon_review_full_csv\n",
    "Mix:  2000 comments of dataset df0 (16.7%) + 2000 comments of dataset df1 (5.0%) + 2000 comments of dataset df2 (0.1%)\n",
    "F1score:  0.8246753246753247\n",
    "\n",
    "position 2: \n",
    "-----------\n",
    "Names:  Amazon Kindle Book Review for Sentiment Analysis + IMDB dataset Sentiment analysis + amazon_review_full_csv\n",
    "Mix:  1000 comments of dataset df0 (8.3%) + 1000 comments of dataset df1 (2.5%) + 4000 comments of dataset df2 (0.1%)\n",
    "F1score:  0.7925925925925926\n",
    "```\n",
    "\n",
    "\n",
    "**Analysis:** \n",
    "- With **3 labels**: we see that in both rules, the best result is obtained with for: \n",
    "```\n",
    "Names:  amazon_review_full_csv\n",
    "Mix:  6000 comments of dataset df3 (0.2%)\n",
    "```\n",
    "We will then fine-tune further on this Mix. \n",
    "\n",
    "- With **2 labels**: we see that the best results is obtained with a Mix in relatively equal proportions of 3 datasets.  We will choose the Mix: \n",
    "```\n",
    "Names:  Amazon Kindle Book Review for Sentiment Analysis + IMDB dataset Sentiment analysis + amazon_review_full_csv\n",
    "Mix:  1000 comments of dataset df0 (8.3%) + 4000 comments of dataset df1 (10.0%) + 1000 comments of dataset df2 (0.0%)\n",
    "```\n",
    "and then fine-tune further on this Mix. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16ChmBAvEHvQ",
   "metadata": {
    "id": "16ChmBAvEHvQ"
   },
   "source": [
    "<font color = \"purple\" > Ranking of BERT fine-tuned models with **the second phase of fine-tuning** evaluated on the miniLabel dataset: </font> \n",
    "\n",
    "```\n",
    "================================================\n",
    "Ranking in the case of 3 labels with rule n°1:\n",
    "================================================\n",
    "position 1: \n",
    "-----------\n",
    "From:  2022-08-13_13:46:24_full_checkpoint\n",
    "Names:  dashbordLabel\n",
    "Mix:  200_original+200_eng-de+200_eng-fr+200_eng-zh+200_embeddings\n",
    "F1score:  0.7799135519959318\n",
    "\n",
    "position 2: \n",
    "-----------\n",
    "From:  2022-08-13_14:11:55_full_checkpoint\n",
    "Names:  dashbordLabel\n",
    "Mix:  200_original+200_eng-de+200_eng-fr+200_eng-zh+200_embeddings\n",
    "F1score:  0.7556067588325653\n",
    "\n",
    "================================================\n",
    "Ranking in the case of 3 labels with rule n°2:\n",
    "================================================\n",
    "position 1: \n",
    "-----------\n",
    "From:  2022-08-13_13:46:24_full_checkpoint\n",
    "Names:  dashbordLabel\n",
    "Mix:  200_original+200_eng-de+200_eng-fr+200_eng-zh+200_embeddings\n",
    "F1score:  0.7799135519959318\n",
    "\n",
    "position 2: \n",
    "-----------\n",
    "From:  2022-08-13_14:11:55_full_checkpoint\n",
    "Names:  dashbordLabel\n",
    "Mix:  200_original+200_eng-de+200_eng-fr+200_eng-zh+200_embeddings\n",
    "F1score:  0.7556067588325653\n",
    "\n",
    "================================================\n",
    "Ranking in the case of 2 labels with rule n°1:\n",
    "================================================\n",
    "position 1: \n",
    "-----------\n",
    "From:  2022-08-18_10:14:36_full_checkpoint\n",
    "Names:  dashbordLabel\n",
    "Mix:  5 copies of the 200 comments of dashbordLabel = 1000 comments\n",
    "F1score:  0.8319327731092439\n",
    "\n",
    "position 2: \n",
    "-----------\n",
    "From:  2022-08-18_10:50:40_full_checkpoint\n",
    "Names:  dashbordLabel\n",
    "Mix:  200_original+200_eng-de+200_eng-fr+200_eng-zh+200_embeddings\n",
    "F1score:  0.8319327731092439\n",
    "\n",
    "================================================\n",
    "Ranking in the case of 2 labels with rule n°2:\n",
    "================================================\n",
    "position 1: \n",
    "-----------\n",
    "From:  2022-08-18_10:14:36_full_checkpoint\n",
    "Names:  dashbordLabel\n",
    "Mix:  5 copies of the 200 comments of dashbordLabel = 1000 comments\n",
    "F1score:  0.8319327731092439\n",
    "\n",
    "position 2: \n",
    "-----------\n",
    "From:  2022-08-18_10:50:40_full_checkpoint\n",
    "Names:  dashbordLabel\n",
    "Mix:  200_original+200_eng-de+200_eng-fr+200_eng-zh+200_embeddings\n",
    "F1score:  0.8319327731092439\n",
    "\n",
    "```\n",
    "\n",
    "**Analysis:** \n",
    "- With **3 labels**: we see that in both rules, the best result is obtained with: \n",
    "```\n",
    "From:  2022-08-13_13:46:24_full_checkpoint\n",
    "Names:  dashbordLabel\n",
    "Mix:  200_original+200_eng-de+200_eng-fr+200_eng-zh+200_embeddings\n",
    "F1score:  0.7799135519959318\n",
    "```\n",
    "We will then use this model for predict on the whole dashboard data. \n",
    "\n",
    "- With **2 labels**:  we see that in both rules, the best result is obtained with: \n",
    "```\n",
    "From:  2022-08-18_10:50:40_full_checkpoint\n",
    "Names:  dashbordLabel\n",
    "Mix:  200_original+200_eng-de+200_eng-fr+200_eng-zh+200_embeddings\n",
    "F1score:  0.8319327731092439\n",
    "```\n",
    "We will then use this model for predict on the whole dashboard data. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "WBeiB-tVbD7L",
   "metadata": {
    "id": "WBeiB-tVbD7L"
   },
   "source": [
    "___________\n",
    "__________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cOUmXODmZIKE",
   "metadata": {
    "id": "cOUmXODmZIKE"
   },
   "outputs": [],
   "source": [
    "dash_data_name1 = \"dashData_from:2022-08-13_13:46:24_full_checkpoint\"\n",
    "dash_data_name2 = \"dashData_from:2022-08-18_10:50:40_full_checkpoint\"\n",
    "\n",
    "\n",
    "os.chdir(PATH + '/6_ProbsDashbord_pkl') #go to correct folder \n",
    "dash_data1 = pd.read_pickle(dash_data_name1 + '.pkl')\n",
    "dash_data2 = pd.read_pickle(dash_data_name2 + '.pkl')\n",
    "os.chdir(PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "IwZSb4ydbdLz",
   "metadata": {
    "id": "IwZSb4ydbdLz"
   },
   "outputs": [],
   "source": [
    "dash_data2[\"progress\"] = dashbord[\"progress\"].iloc[idxNoNaN].copy()\n",
    "dash_data1[\"progress\"] = dashbord[\"progress\"].iloc[idxNoNaN].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "DsubSd6TZgcX",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DsubSd6TZgcX",
    "outputId": "f4b98ff5-c197-4486-a34c-122686b5ea46"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For 3 labels:\n",
      "----------------\n",
      "percentage of comments labeled 0: 0.125 %\n",
      "percentage of comments labeled 1: 0.7049 %\n",
      "percentage of comments labeled 2: 0.17 %\n",
      "\n",
      "For 2 labels:\n",
      "----------------\n",
      "percentage of comments labeled 0: 0.1245 %\n",
      "percentage of comments labeled 1: 0.8755 %\n"
     ]
    }
   ],
   "source": [
    "print (\"For 3 labels:\")\n",
    "print (\"----------------\")\n",
    "for i in range(3):\n",
    "  print(\"percentage of comments labeled {}: {} %\".format(i,\n",
    "  round(len(100*np.where(dash_data1.BERTlabel_1 == i)[0])/len(dash_data1),4)))\n",
    "\n",
    "print (\"\\nFor 2 labels:\")\n",
    "print (\"----------------\")\n",
    "for i in range(2):\n",
    "  print(\"percentage of comments labeled {}: {} %\".format(i,\n",
    "  round(len(100*np.where(dash_data2.BERTlabel_1 == i)[0])/len(dash_data2),4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "FutD9Ov9b3RC",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 356
    },
    "id": "FutD9Ov9b3RC",
    "outputId": "72387336-4660-4bcc-d233-7430a7e75cee"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "f,axs = plt.subplots(1,3,figsize=(15, 5))\n",
    "axs = axs.ravel()\n",
    "\n",
    "labs = [] #list containing extract of the dataframe \"annot\"\n",
    "                # labs[0] contains all values where label = 0\n",
    "                # labs[1] contains all values where label = 1\n",
    "                # labs[2] contains all values where label = 2\n",
    "\n",
    "annot = dash_data1.copy()\n",
    "idNA = np.where(annot.progress.isna() == False)\n",
    "annot = annot.iloc[idNA].copy()\n",
    "\n",
    "labs.append(annot[\"progress\"].iloc[np.where(annot.BERTlabel_1 == 0)])\n",
    "labs.append(annot[\"progress\"].iloc[np.where(annot.BERTlabel_1 == 1)])\n",
    "labs.append(annot[\"progress\"].iloc[np.where(annot.BERTlabel_1 == 2)])\n",
    "\n",
    "for i in range(3):\n",
    "    #--- plot histogram\n",
    "    weights = np.ones_like(labs[i])/float(len(labs[i])) #so that the histogram bars sum to 1\n",
    "    \"\"\"N, bins, patches = axs[i].hist(x = labs[i],bins = 9,weights=weights,\n",
    "                                  align = 'mid',alpha = .5,edgecolor='white',linewidth=1)  \"\"\"\n",
    "    N, bins, patches = axs[i].hist(x = labs[i],bins = 9,\n",
    "                                  align = 'mid',alpha = .5,edgecolor='white',linewidth=1)    \n",
    "   \n",
    "    #--- add color corresponding to progress\n",
    "    for k in range(0,3):\n",
    "        patches[k].set_facecolor('slateblue')\n",
    "    for k in range(3,5):    \n",
    "        patches[k].set_facecolor('slateblue')\n",
    "    for k in range(5, len(patches)):\n",
    "        patches[k].set_facecolor('slateblue')\n",
    "    #--- add title and labels\n",
    "    axs[i].set_title(\"Progress of comments labelled {}\".format(i))\n",
    "    axs[i].set_xlabel(\"progress\",labelpad = 10)\n",
    "    axs[i].set_ylabel(\"proportion of comments\",labelpad = 10)\n",
    "    #--- remove frames\n",
    "    axs[i].spines['top'].set_visible(False)\n",
    "    axs[i].spines['right'].set_visible(False)\n",
    "    axs[i].spines['bottom'].set_visible(False)\n",
    "    axs[i].spines['left'].set_visible(False)\n",
    "    #--- adjust subplots and background\n",
    "    plt.subplots_adjust(wspace=.4)\n",
    "    axs[i].patch.set_facecolor('grey')#background color\n",
    "    axs[i].patch.set_alpha(0.05)#background color\n",
    "    \n",
    "    #--- add values above each bar \n",
    "    for j,v in enumerate (N[np.where(N!=0)]):\n",
    "        axs[i].text(j, v, \"%.2f\" %v + \"\", ha=\"center\",color = 'black', size = 10) \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d-HVv-FsbneN",
   "metadata": {
    "id": "d-HVv-FsbneN"
   },
   "source": [
    "## TO DO:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9PEmhYZVx2E",
   "metadata": {
    "id": "c9PEmhYZVx2E"
   },
   "source": [
    "_______________________________________\n",
    "1000 of each dataset and increase the size of one dataset (3000) and see if there is change.\n",
    "\n",
    "- 6/9 experiments with subsets of this original dataset\n",
    "- try to see the correlation between BERTlabel/groundtruth labels/progress\n",
    "_______________________________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "IfsMZaOViib7",
   "metadata": {
    "id": "IfsMZaOViib7"
   },
   "outputs": [],
   "source": [
    "30: validation set: tune meta parameters\n",
    "50: evaluation set\n",
    "\n",
    "\n",
    "1 prediction mark with satisfactory level\n",
    "1 prediction mark with label bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Ue-22db23oml",
   "metadata": {
    "id": "Ue-22db23oml"
   },
   "outputs": [],
   "source": [
    "#---- check by hand the results\n",
    "#a = dash_data.iloc[np.where(dash_data.BERTlabel2 != dash_data.BERTlabel)]\n",
    "a = dash_data.iloc[np.where(dash_data.BERTlabel_1 == 2)]\n",
    "b = dash_probs[np.where(dash_data.BERTlabel_1 == 2),:][0]\n",
    "j=0\n",
    "for i in range(10):\n",
    "  print(a.comments.iloc[i])\n",
    "  #print(\"BERTlabel: \", a.BERTlabel.iloc[i])\n",
    "  print(b[j,:])\n",
    "  j+=1\n",
    "  print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "B7QLhk5bCfui",
   "metadata": {
    "id": "B7QLhk5bCfui"
   },
   "source": [
    "https://github.com/huggingface/transformers/issues/6263"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "heOfXoEgMKeP",
   "metadata": {
    "id": "heOfXoEgMKeP"
   },
   "source": [
    "\n",
    "- send dataset for annotation (30/50 texts) to A and V **OK**\n",
    "- check agreement between A and V if confusion a 3rd person annotates. \n",
    "- check annotation aggreeement between annotation (A,V) and progress on the dashboard. If I see there is an agreement, I can use the dahboard progress to annotate.\n",
    "Or looking at the agreement among classes (satisfactory/moderate/unsatisfactory).\n",
    "- data augmentation for text.\\\n",
    "https://neptune.ai/blog/data-augmentation-nlp \\\n",
    "https://arxiv.org/ftp/arxiv/papers/2107/2107.03158.pdf\n",
    "\n",
    "\n",
    "- see if BERT is sensitive on the size of the data -> later \n",
    "- find a way to train BERT twice: first time on dataset found on internet and second time on our label dataset: https://github.com/amaiya/ktrain/blob/master/FAQ.md#how-do-i-resume-training-from-a-saved-checkpoint\n",
    "\n",
    "- find a way to export the model BERT: (using PYTORCH) \n",
    "\n",
    "https://medium.com/analytics-vidhya/saving-and-loading-your-model-to-resume-training-in-pytorch-cb687352fa61\n",
    "\n",
    "https://pytorch.org/tutorials/recipes/recipes/saving_and_loading_a_general_checkpoint.html\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "PCjSny22PaJe",
   "metadata": {
    "id": "PCjSny22PaJe"
   },
   "source": [
    "questions: \n",
    "est-ce que c'est pareil de fine tune sur un seul dataset qui contient nos data + les data d'internet ou est-ce que c'est mieux de fine tune en 2 fois: le dataset d'internet et puis notre propre dataset après ? \n",
    "Si oui, je ne sais pas comment faire du transfer learning pour le moment...."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "A4LT9vN4RbIn",
   "metadata": {
    "id": "A4LT9vN4RbIn"
   },
   "source": [
    "peut-être pour mieux comprendre regarder ce que fait la passe forward et backward du modèle."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ENc91zZ9Q2bz",
   "metadata": {
    "id": "ENc91zZ9Q2bz"
   },
   "source": [
    "# Drafts and unfinished codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fZSRKFFHuAtM",
   "metadata": {
    "id": "fZSRKFFHuAtM"
   },
   "outputs": [],
   "source": [
    "l = [[ 4.2725e-02,  2.5470e-02,  3.8915e-01],\n",
    "        [ 1.8440e-02, -7.4700e-02,  2.8701e-01],\n",
    "        [ 7.0170e-02, -4.9360e-02,  2.7799e-01],\n",
    "        [ 6.9618e-05, -8.2011e-02,  2.4084e-01],\n",
    "        [ 9.1309e-02, -2.0337e-02,  2.6736e-01],\n",
    "        [ 1.0598e-01,  2.8469e-02,  2.2281e-01],\n",
    "        [ 1.3833e-02, -2.0461e-02,  1.8368e-01],\n",
    "        [-1.5404e-02, -6.1609e-02,  2.6482e-01]] #logits (output of function forward)\n",
    "logits = torch.Tensor(l); print(\"logits: \",logits); \n",
    "labels = torch.Tensor([ 1, -1,  1, -1,  0,  1, -1,  1]); print(\"labels: \", labels)\n",
    "labels = torch.Tensor([ 2, 0,  2, 0,  1,  2, 0,  2]); print(\"labels: \", labels) \n",
    "# CLASS MUST SPAN TO 0 to 3\n",
    "\n",
    "labels = labels.type(torch.LongTensor)\n",
    "#LongTensor is synonymous with integer. \n",
    "#PyTorch won't accept a FloatTensor as categorical target, \n",
    "#so it's telling you to cast your tensor to LongTensor. \n",
    "\n",
    "\n",
    "m = nn.Softmax(dim=1)\n",
    "output = m(logits) #apply softmax function to logits \n",
    "print(\"output: \",output)\n",
    "loss = nn.CrossEntropyLoss()\n",
    "print(\"loss CrossEntropyLoss:\")\n",
    "loss(output,labels)\n",
    "#nn.BCEWithLogitsLoss(logits,labels)\n",
    "\n",
    "#The input is expected to contain raw, unnormalized scores for each class.\n",
    "#Thus, for TRAINING we don't use SOFTMAX \n",
    "# for GETTING PREDICTIONS from our model we use SOFTMAX"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1rlHeNE-3d_0",
   "metadata": {
    "id": "1rlHeNE-3d_0"
   },
   "source": [
    "Common Error: Most likely there is mismatch between vocabulary size of tokenizer and bert model ( in bert config). Try setting vocab size of your tokenizer in bert config while initializing your model. https://github.com/huggingface/transformers/issues/5611\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sZXPfG99Q0yp",
   "metadata": {
    "id": "sZXPfG99Q0yp"
   },
   "outputs": [],
   "source": [
    "def preprocessingForBert_long(data):\n",
    "  \"\"\"\n",
    "  This function performs required preprocessing steps for pretrained BERT \n",
    "  for long texts (more than 510 tokens).\n",
    "  ---> input: data (np.array): Array of texts to be processed.\n",
    "  ---> ouput: \n",
    "  - input_ids (torch.Tensor): Tensor of token ids to be fed to a model.\n",
    "  - attention_masks (torch.Tensor): Tensor of indices specifying which\n",
    "  tokens should be attended to by the model.\n",
    "\n",
    " If the input text exceeds 510 tokens (text without SEP and CLS tokens) then the \n",
    " firsts 'nbFirst' and lasts 'nbLast' tokens are selected to match a length of 510 tokens. \n",
    "  \"\"\"\n",
    "\n",
    "  chunksize = 512 # define target chunksize\n",
    "  nbFirst = 128 # number of tokens to take from the beginning of the text\n",
    "  nbLast = 382  # number of tokens to take from the end of the text\n",
    "                # nbFirst + nbLast = 510 (SEP and CLS tokens not present)\n",
    "\n",
    "  # Create empty lists to store outputs\n",
    "  input_ids = [] \n",
    "  attention_masks = [] \n",
    "\n",
    "  for comment in data:\n",
    "\n",
    "    # create dictionary of 'input_ids' (=tokens) and 'attention_mask' and send it to pythorch\n",
    "    encoded_c = tokenizer.encode_plus(comment, add_special_tokens=False,return_tensors='pt') \n",
    "\n",
    "    # if the number of tokens exceeds 510 then the firsts 'nbFirst'\n",
    "    # and lasts 'nbLast' tokens are selected \n",
    "    if encoded_c[\"input_ids\"][0].shape[0] > chunksize - 2: #-2 since SEP and CLS tokens are not present yet\n",
    "      firstTok = encoded_c[\"input_ids\"][0][:nbFirst]\n",
    "      lastTok = encoded_c[\"input_ids\"][0][-nbLast:]\n",
    "      firstMask = encoded_c[\"attention_mask\"][0][:nbFirst]\n",
    "      lastMask = encoded_c[\"attention_mask\"][0][-nbLast:]\n",
    "\n",
    "      tokens = torch.cat((firstTok, lastTok))\n",
    "      masks = torch.cat((firstMask, lastMask))\n",
    "    else: # otherwise, let the tokens inchanged\n",
    "      tokens =  encoded_c[\"input_ids\"][0]\n",
    "      masks = encoded_c[\"attention_mask\"][0]\n",
    "\n",
    "    # add SEP (token ID 101) and CLS (token ID 102)\n",
    "    tokens = torch.cat([torch.tensor([101]), tokens, torch.tensor([102])])\n",
    "\n",
    "    # add attention tokens to attention mask\n",
    "    masks = torch.cat([torch.tensor([1]), masks, torch.tensor([1])])\n",
    "\n",
    "    # get required padding length\n",
    "    pad_len = chunksize  - len(tokens)\n",
    "\n",
    "    # if padding length is more than 0 (ie the number of tokens < 512)\n",
    "    # we must add padding so that each token has a size of 512\n",
    "    if pad_len > 0: \n",
    "      tokens = torch.cat([tokens, torch.Tensor([0] * pad_len)]) #add 0s (which  is the token ID for [PAD])\n",
    "      masks  = torch.cat([masks , torch.Tensor([0] * pad_len)]) #add 0s (which  is the token ID for [PAD])\n",
    "\n",
    "    # Add the tokens of the encoded comment to the list.    \n",
    "    input_ids.append(tokens.long()) ###\n",
    "\n",
    "    # And its attention mask (simply differentiates padding from non-padding).\n",
    "    attention_masks.append(masks.int()) ###\n",
    "\n",
    "  return input_ids,attention_masks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "whhl5ZWuuCF8",
   "metadata": {
    "id": "whhl5ZWuuCF8"
   },
   "source": [
    "### data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "I_enV2k8uEn_",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I_enV2k8uEn_",
    "outputId": "be5172e5-677c-47d1-b228-2429661f97a6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (1.21.6)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (2.23.0)\n",
      "Requirement already satisfied: nlpaug in /usr/local/lib/python3.7/dist-packages (1.1.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests) (2022.6.15)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests) (1.25.11)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests) (3.0.4)\n",
      "Requirement already satisfied: gdown>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from nlpaug) (4.4.0)\n",
      "Requirement already satisfied: pandas>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from nlpaug) (1.3.5)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from gdown>=4.0.0->nlpaug) (4.64.0)\n",
      "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from gdown>=4.0.0->nlpaug) (4.6.3)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from gdown>=4.0.0->nlpaug) (1.15.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from gdown>=4.0.0->nlpaug) (3.7.1)\n",
      "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.2.0->nlpaug) (2022.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.2.0->nlpaug) (2.8.2)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.7/dist-packages (from requests) (1.7.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy requests nlpaug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bwhzDhst2y4",
   "metadata": {
    "id": "5bwhzDhst2y4"
   },
   "outputs": [],
   "source": [
    "import nlpaug.augmenter.word as naw #works with version 3.0.2 of transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "EVBXEZSyuPA_",
   "metadata": {
    "id": "EVBXEZSyuPA_"
   },
   "outputs": [],
   "source": [
    "text = 'The quick brown fox jumps over the lazy dog .'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "yOL98zafvUhE",
   "metadata": {
    "id": "yOL98zafvUhE"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"MODEL_DIR\"] = '../model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7tQ-x0ouxXO",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187,
     "referenced_widgets": [
      "8d4ef526c1c7470b9628eb6a205da9c1",
      "225fcf95ad6b49debc431e809162d98e",
      "72f554ddaf2041649ef72c62a5652571",
      "7e610cf12b694931a89e43633871cd4a",
      "f1d2c5383db94e4fbd69b0ea6ec026e9",
      "e853963f73c24d51b28e3eba4c0ac4b2",
      "a47a9fe4699e409c8fcd143b9b7212fc",
      "0f2f3080c98d4f3abe13b85a3fbaa438",
      "f9c0494b0a5140a3a02f424830713be7",
      "ee0bb7d628bc4dbc8ab41ab1142dcd0b",
      "3b202a5ccb0b4e098e841cf6e0b21df7",
      "77a0827e8a5649f6849a77c37de0cff9",
      "9e7510c5f8b54e14b711c4d741728810",
      "9dff2660a64b49319653d430efd8bf1f",
      "993f6a2f1d154840bb0b2196bb2cfad6",
      "937b99b4f4ac4b4b971b60eae83f5dd9",
      "3ba5f3d06f6f43739a24edc8f77c6bd0",
      "f109772146774fca9206d8bdbbf439e7",
      "5b413ed735574e2e91b8612bea32ed86",
      "bb371fa55a9048a0963ebc61667253af",
      "7abbba5462504d1e9148d77b3a86e2fa",
      "7458953c7b784aa5be8873a1d507cf4b",
      "63fec4552090431f95a82b458c0687c4",
      "4acd46200b9f43958ffdf53bb08f3fd3",
      "5015d03654bf42a0bbf4e02d3f673d74",
      "e5ea02543f05499f89bbfb1c8e47c4f2",
      "4fd0d14204ff49c287976a6e759eb7f7",
      "df0eb8499abf4be3a1401b205d4758d1",
      "86b3b2b690d3480ab98bf2186b6002ed",
      "3ee5fc7f73f347d99b7c7ace04ea86e0",
      "15d7b044a63d4d76998bac3195152bea",
      "eb01ea39b3ff41d38bb944f7034afedb",
      "e16695049eea47b79a1da7d48201d462"
     ]
    },
    "id": "f7tQ-x0ouxXO",
    "outputId": "f1a7d5a2-c9ea-4329-c700-c791c50d6ff6"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d4ef526c1c7470b9628eb6a205da9c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/433 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77a0827e8a5649f6849a77c37de0cff9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63fec4552090431f95a82b458c0687c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:\n",
      "The quick brown fox jumps over the lazy dog .\n",
      "Augmented Text:\n",
      "['the three quick brown fox nearly jumps over the tiny lazy dog.']\n"
     ]
    }
   ],
   "source": [
    "#Insert word by contextual word embeddings (BERT, DistilBERT, RoBERTA or XLNet)\n",
    "aug = naw.ContextualWordEmbsAug(\n",
    "    model_path='bert-base-uncased', action=\"insert\")\n",
    "augmented_text = aug.augment(text)\n",
    "print(\"Original:\")\n",
    "print(text)\n",
    "print(\"Augmented Text:\")\n",
    "print(augmented_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "xAYLCMccxmfm",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xAYLCMccxmfm",
    "outputId": "500a24cd-f633-48fc-ef89-17e5447919c6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:\n",
      "The quick brown fox jumps over the lazy dog .\n",
      "Augmented Text:\n",
      "['the baby brown fox jumps over a frightened dog.']\n"
     ]
    }
   ],
   "source": [
    "#Substitute word by contextual word embeddings (BERT, DistilBERT, RoBERTA or XLNet)\n",
    "\n",
    "aug = naw.ContextualWordEmbsAug(\n",
    "    model_path='bert-base-uncased', action=\"substitute\")\n",
    "augmented_text = aug.augment(text)\n",
    "print(\"Original:\")\n",
    "print(text)\n",
    "print(\"Augmented Text:\")\n",
    "print(augmented_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "G62lNHS2uZf9",
   "metadata": {
    "id": "G62lNHS2uZf9"
   },
   "source": [
    "_____________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "IQ-VOcZ2SnJb",
   "metadata": {
    "id": "IQ-VOcZ2SnJb"
   },
   "source": [
    "\n",
    "Documentation: for text data augmentation for sentiment analysis (we have to make sure that the augmentation does not change the main sentiment of the texts)\n",
    "\n",
    "- https://computationalsocialnetworks.springeropen.com/track/pdf/10.1186/s40649-020-00080-x.pdf\n",
    "\n",
    "- https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9543519&casa_token=EnD1Wh4tj90AAAAA:KcT6IIJj8O73B8ZIVc0LVk10aj_K2DgVUD0vgbi5Yi7TjxI9O9gH492UDcC0gDD_9BlyFNAuafiD (best paper)\n",
    "\n",
    "- https://github.com/makcedward/nlpaug#augmenter (github repo)\n",
    "\n",
    "=> **conclusion of these papers**: USE **BT (back-translation)** for data augmentation in the case of **small** and **imbalanced** datasets with **BERT**.\n",
    "\n",
    "\n",
    "\n",
    "https://aclanthology.org/2021.emnlp-main.362.pdf -> new approach but maybe complicated\n",
    "\n",
    "\n",
    "However, increasing the text with the BT is not enough as we want to reach at least 5*200 comments = 1000 comments.\n",
    "We then use textual augmentation by Word embeddings which may not be the best solution but will increase the data further.  After several tests on our comments, I think that the method with Word embedding is still more efficient than the simple synonym replacement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "m91Tt5_dotEO",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m91Tt5_dotEO",
    "outputId": "c7179581-2282-4154-d330-5d06d149b594"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting git+https://github.com/huggingface/transformers\n",
      "  Cloning https://github.com/huggingface/transformers to /tmp/pip-req-build-vo1_9ic5\n",
      "  Running command git clone -q https://github.com/huggingface/transformers /tmp/pip-req-build-vo1_9ic5\n",
      "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
      "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
      "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.22.0.dev0) (2022.6.2)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers==4.22.0.dev0) (0.12.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.22.0.dev0) (3.7.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from transformers==4.22.0.dev0) (0.8.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.22.0.dev0) (1.21.6)\n",
      "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers==4.22.0.dev0) (4.12.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers==4.22.0.dev0) (6.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.22.0.dev0) (2.23.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers==4.22.0.dev0) (21.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==4.22.0.dev0) (4.64.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.8.1->transformers==4.22.0.dev0) (4.1.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers==4.22.0.dev0) (3.0.9)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers==4.22.0.dev0) (3.8.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.22.0.dev0) (2022.6.15)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.22.0.dev0) (1.25.11)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.22.0.dev0) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.22.0.dev0) (2.10)\n",
      "Building wheels for collected packages: transformers\n",
      "  Building wheel for transformers (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for transformers: filename=transformers-4.22.0.dev0-py3-none-any.whl size=4728143 sha256=09e57476cbb38c6f23f2e6c19b6e7cb7f494f2692bd59e1b7181c69589a83629\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-8l2i3j2y/wheels/35/2e/a7/d819e3310040329f0f47e57c9e3e7a7338aa5e74c49acfe522\n",
      "Successfully built transformers\n",
      "Installing collected packages: transformers\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 2.8.0\n",
      "    Uninstalling transformers-2.8.0:\n",
      "      Successfully uninstalled transformers-2.8.0\n",
      "Successfully installed transformers-4.22.0.dev0\n"
     ]
    }
   ],
   "source": [
    "# Install Transformers from source with the following command:  \n",
    "# - We need to do this to use \"back_translation\" with \"nlpaug\", otherwise it does not work.\n",
    "# - May need to restart runtime environment since \"transformers==2.8.0\" version has  \n",
    "#   been previously loaded for BERT fine-tuning. \n",
    "#-------------------------------------------------\n",
    "!pip install git+https://github.com/huggingface/transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb43nLXtsK8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 401,
     "referenced_widgets": [
      "1fcfc06fb4f74c43b3ee37874797e2bf",
      "ed91a32b50cb44efb83c48d902471fe7",
      "8732bc1f48584414978838710d51efe7",
      "21527f14de0b48bd86c2827e880caea3",
      "b52b0d9ef7144f7bba4edb8c7f2c4037",
      "b1722ede78dd4fd281306c0a41054f9e",
      "047a353b8a3d43a4b12ffb69bd2cc7ca",
      "46956cc7cc22400ea0810e5c3775f7ab",
      "5b8d418f764c4e2cbee71f7561303422",
      "288164d139b7425ab9a4d7361352bf50",
      "389601841ea146399bc968b20081b775",
      "1c83f8d5cebf4cd0a55b5efce1fa0553",
      "ab240c8bb0264781addb1c7adcf45d2a",
      "ce38efdc0611411aab6ccb49343da2c7",
      "b180b33c276a4d2baa258e9c428df45f",
      "cd263572af6b46ce81ea18e29bfd8a72",
      "9b64b0dda456466288e1ece519207b53",
      "dd3a0ed672d44227b45ac6536e5b0986",
      "ec2940914e144d1ba57d781de3879519",
      "ba6f611d1c3043c8b362e5e1a803e974",
      "cab69e336c7d4c4da67a8d200b4bf7c3",
      "80787272cccd48c286df91f3f7b44623",
      "1a54aea32d004194a41034aaf66b06ce",
      "3eb18e8f462f458c81e9b78076f1184b",
      "2659ca8f88bc4637a970737045b34c6b",
      "27d4e4f1186b41c286cb45b09a1d3cbb",
      "303df19736ab46aa92d74d7e80fe587c",
      "cbc05828881a4c5482907e7a39220fd9",
      "c062d231866f416d907c714a8e8ac9fd",
      "faecf1a959e849fc926213d7430abb66",
      "cb6407a7e2304eb5a5c4a8223822d0fd",
      "0b27f9ac960c439f849eb315751a4301",
      "2d0bb9b1be704d6ca80329fd0c0d586f",
      "e194fc6070214eb5b0bebef0270eac4b",
      "c94fa6299d44482692219a338ab46389",
      "bf58738e9cf94a0483e2e580582aface",
      "301ebef502394bb58efb1884fda77e4b",
      "431b9eee96c14cb38f161bc38a4fdc5c",
      "6b0e769481bf413a94d51812cb3f7344",
      "c1c6a35b85294c91b5ebef0df04758ce",
      "41ce66280af54fc9aa9fefc93f2b2618",
      "1e0759762ca5464b90c972ce11fc8cbc",
      "a489cc3e5e714d58bda5473622d4a723",
      "a4e8090f53e24deb9b103e44658deab8",
      "71578ef1dd0f402e8913f3291e6709e3",
      "ff7c05e0fe8947a8917ab5e52eae59ab",
      "c09ef55a074846e185a806654c2cbaf2",
      "4fe1850faf8f457e9bbadd8da0d2d4f6",
      "09ec4ee275ee4a0bbaaed8ad6965f1cf",
      "1742f90b184d402899a8591187d058f2",
      "48954a17d26f40c69aedabe315cfa970",
      "362f6afcd9d64786a54cc65165656895",
      "83b9db1f64534be5be3f9b7429a69278",
      "4288ef39a9f14e24ae0b127077ca2e38",
      "f47bb3855a134751840e3106c55be3a8",
      "d4b162c9b44640f29a01a15cfef6ecd5",
      "e7fc95e0a7884f5e9619dd3ff9cb8ba4",
      "4850baaabd3d4b1da905aac4169886e6",
      "28f361d1637d453d938cfc0fd450499c",
      "f6ce00ccc5f44e7c8355d1dc99b36ab8",
      "c9195a2570234405a00a90aa0cded2a1",
      "ab6cb4f2eef44cb58d7586a27f52ce05",
      "13e1b6caf3af4a80881c36785a1362fb",
      "c1ee1dae783b4732be245cd0f596ef8e",
      "4450cc35701a409c81d29c056c5aefae",
      "9aefb299fe294c2dbcf8bc1d739b2b45",
      "0e14803f157a4e07b0bc413258eb0b41",
      "d8fb8ef864dd4861aff9771caf96c6f8",
      "438fb60d697b4220afdf5de25c57d112",
      "7207906283c74e4db49077092980d55f",
      "ba56be2f668e454e9015104c0524ed42",
      "d97da4b207ca4775bdb2997e8d16603a",
      "26dc81317a3e4956a98817d61e708053",
      "d0a448d38a74438e8017e39f93da88f7",
      "5acfc915769f41bbb5979f6fc3d3a90b",
      "e68d1ef2b5f748638be4a51ee5891e8c",
      "f8bf929721844352a87803f89eec2cab",
      "0638e2e36cf04c7786cd0861a5443a2e",
      "d66e304031c7430dbb2401269e44ab0e",
      "a155365163e545788dc5ce36b61c7c11",
      "667acf386a594652912281c832c555d8",
      "1db0672fd3a34232bb20f4f832009331",
      "b97e0f619dea45f8bfeaeccb96afa79f",
      "a7f26145316445879a13fbc498949ebb",
      "2e4837cd99d7461c805683c5bc679260",
      "19f1a43e2b954777a7985e3e1dbe1f99",
      "cb199a8c4a00474baed049f3bdb903b9",
      "bc4662eaa2304857b5d56f58d3d96418",
      "5c5c01bb411d43288d052c0b06f71beb",
      "1e087dd0cf7e48789124b92b574296bf",
      "bb2472d60eb04510a088ab46666d90b5",
      "f2a1698861ef44d6ad09156f622aa773",
      "bfa82d5bdc0244f9bae0e9dab63c8d00",
      "d90e48c6f071486899f875715973bf07",
      "677ab05fe6c24653999d0810a386414c",
      "302461a2fd104b1c9420e489749c3319",
      "b106cbdad1b445d586a84e53752300c1",
      "2bf716a9285444c2b7c25fb4cd5d26b3",
      "9b4bc9be8d7a4d67880ef3bf4b79a139",
      "593d4d3233f246f197cfce0f5a9ff895",
      "322fd033c726427c8d70a950805d424d",
      "b646da4054de4cfd8cf6170ae52eb8fc",
      "5ee5dacb4a5743a3a6d365a643deae86",
      "6463fed1d02c4804b332273087a2b835",
      "f41110567ab9417faff75de0ce7ab068",
      "3d48a73f53384fa382cafa950d9084aa",
      "9a28295ee2a04858bf391e779db511fb",
      "bd4dce92072f405f8ec75cf7e8eeb7cf",
      "fe9b65930d1a4091a54e272d0f6f72a6",
      "b5333a4b868e4b56a3b513eddcfee8b6",
      "a0e1289f7d134b3798cc9b11ec607dc8",
      "a0408f29fa1243dcb9ca0ca93ed097b6",
      "39d3efda498a4af7a47fb16f45d1b1a5",
      "21b3c89fe37f4999bc6538fbed993dd8",
      "26fa44f3cf734770859a25304b4e5631",
      "482814332c0b403a9682c95ae42f1aa0",
      "3207c62077aa43caaca1eeb91eec6139",
      "778aeee4e56f4906847aa3f2a4912abf",
      "5824febc56824822b85e9f41435da435",
      "545ed3cb7e614992bd41cf39150b7d2a",
      "d63d0d3de0c04963b20394192aab7659",
      "1b5fdfeae53841788c43f138707d4c10",
      "767137b046a04ef88810d23cdc11c168",
      "7f8a76d542254de8938a93102f05a1f1",
      "c0ec0710b6fc40099990bd9188aa72ed",
      "97b5cde75ce647a58a4608c734a3272c",
      "351d477f56a64686a3898870faa4fd0c",
      "e331408f40244432a4ea95a80e9c0a96",
      "dda77b1660764f7a8767eb1fa008013d",
      "c2fea66ed9574f57b632c5263899da53",
      "8a353b4de7574bdaacc029599a3c83f8",
      "4fa651eca01b47389b89ab24a12860ad"
     ]
    },
    "id": "8bb43nLXtsK8",
    "outputId": "378bb425-da71-4840-9787-3ae2bd5bd0a0"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fcfc06fb4f74c43b3ee37874797e2bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.40k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c83f8d5cebf4cd0a55b5efce1fa0553",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/312M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a54aea32d004194a41034aaf66b06ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.15k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e194fc6070214eb5b0bebef0270eac4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/312M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71578ef1dd0f402e8913f3291e6709e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/44.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4b162c9b44640f29a01a15cfef6ecd5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/806k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e14803f157a4e07b0bc413258eb0b41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/805k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0638e2e36cf04c7786cd0861a5443a2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.62M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c5c01bb411d43288d052c0b06f71beb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/44.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "593d4d3233f246f197cfce0f5a9ff895",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/805k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0e1289f7d134b3798cc9b11ec607dc8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/807k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b5fdfeae53841788c43f138707d4c10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.62M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Import nlpaug library\n",
    "#-------------------------------------------------\n",
    "import nlpaug.augmenter.word as naw\n",
    "\n",
    "# Dowload the back_translation model.\n",
    "#-------------------------------------------------\n",
    "#---  Use english_german translation (default model) \n",
    "back_translation_aug_de = naw.BackTranslationAug(\n",
    "    from_model_name='facebook/wmt19-en-de', #english-deutch \n",
    "    to_model_name='facebook/wmt19-de-en'    #deutch-english \n",
    ")\n",
    "#--- Use english-french translation \n",
    "back_translation_aug_fr = naw.BackTranslationAug(\n",
    "    from_model_name='Helsinki-NLP/opus-mt-en-fr', #english-french \n",
    "    to_model_name='Helsinki-NLP/opus-mt-fr-en'    #french-english \n",
    ")\n",
    "\n",
    "#--- Use english-chinese translation \n",
    "back_translation_aug_zh = naw.BackTranslationAug(\n",
    "    from_model_name='Helsinki-NLP/opus-mt-en-zh', #english-chinese \n",
    "    to_model_name='Helsinki-NLP/opus-mt-zh-en'    #chinese-english \n",
    ")\n",
    "\n",
    "# documentation on naw.BackTranslationAug: \n",
    "# https://nlpaug.readthedocs.io/en/latest/augmenter/word/back_translation.html\n",
    "\n",
    "\n",
    "# Dowload the contextual word embeddings model.\n",
    "# Substitute word by contextual word embeddings (here with BERT)\n",
    "#-------------------------------------------------\n",
    "context_embedding_aug = naw.ContextualWordEmbsAug(\n",
    "    model_path='bert-base-uncased', action=\"substitute\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "JBcTMwklwCAw",
   "metadata": {
    "id": "JBcTMwklwCAw"
   },
   "outputs": [],
   "source": [
    "def augmentText(data2,method_aug):\n",
    "  \"\"\"\n",
    "  this function augments the text data with the method provided\n",
    "  ---> input:\n",
    "  - data2 (dataFrame): dataframe containing 2 columns {\"commments\", \"label\"}\n",
    "  - method_aug: method for text augmentation\n",
    "  ---> ouput:\n",
    "  - aug_data2 (dataFrame): dataframe with the same dimensions as data2 containing\n",
    "  the modified \"comments\" with the augmented method and the corresponding label\n",
    "  \"\"\"\n",
    "\n",
    "  aug = [] #list of the augmented comments in the same order as the comments in data2\n",
    "\n",
    "  for i in range(len(data2)):\n",
    "    text = data2.comments.iloc[i]\n",
    "    aug.append(method_aug.augment(text))  \n",
    "\n",
    "  aug_data2 = pd.DataFrame(aug)\n",
    "  aug_data2.rename(columns={0:\"comments\"},inplace=True)\n",
    "  aug_data2.index = data2.index\n",
    "  aug_data2[\"label\"] = data2[\"label\"].copy()\n",
    "  return aug_data2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "_VYuy8Im1hNd",
   "metadata": {
    "id": "_VYuy8Im1hNd"
   },
   "outputs": [],
   "source": [
    "NUM_COPIES = 5\n",
    "aug_dataS = [] #list containing different augmentations with \n",
    "\n",
    "\n",
    "for i in range(NUM_COPIES):\n",
    "  aug_dataS.append(augmentBT(data2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "CHrIB8962I1p",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "CHrIB8962I1p",
    "outputId": "0ce8b6a8-4de9-4c57-924b-3543cbdeacaa"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-d7352d09-f390-4d2f-8425-9853ace21db6\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comments</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7474</th>\n",
       "      <td>Were investigating DB design MySQL Django Acco...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6542</th>\n",
       "      <td>Draft of functional spec sent as per deliverab...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2832</th>\n",
       "      <td>November via Skype Discussed shared dataset E...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6464</th>\n",
       "      <td>Met on group call</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1384</th>\n",
       "      <td>Finished the AI!!! Tweaking the bugs wrt the ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2664</th>\n",
       "      <td>So has progressed well and now has tslearn wor...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>Implemented Linear Regression with small datas...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8745</th>\n",
       "      <td>math model and DRL model is general done, next...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9829</th>\n",
       "      <td>Met discussed project implementation, needs to...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6837</th>\n",
       "      <td>The past week:\\nJack:\\nresearched the Met Eire...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 2 columns</p>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d7352d09-f390-4d2f-8425-9853ace21db6')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-d7352d09-f390-4d2f-8425-9853ace21db6 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-d7352d09-f390-4d2f-8425-9853ace21db6');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "                                               comments label\n",
       "7474  Were investigating DB design MySQL Django Acco...     1\n",
       "6542  Draft of functional spec sent as per deliverab...     1\n",
       "2832   November via Skype Discussed shared dataset E...     1\n",
       "6464                                 Met on group call      1\n",
       "1384   Finished the AI!!! Tweaking the bugs wrt the ...     1\n",
       "...                                                 ...   ...\n",
       "2664  So has progressed well and now has tslearn wor...     2\n",
       "178   Implemented Linear Regression with small datas...     1\n",
       "8745  math model and DRL model is general done, next...     0\n",
       "9829  Met discussed project implementation, needs to...     0\n",
       "6837  The past week:\\nJack:\\nresearched the Met Eire...     1\n",
       "\n",
       "[1000 rows x 2 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " pd.concat(aug_dataS, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "q1Lv2PJQjDgi",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q1Lv2PJQjDgi",
    "outputId": "462fd643-5af5-4fb9-b600-ade1a10f39e0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original text:\n",
      "BT english-deutch:\n",
      "['The speedy brown fox leapt over the lazy dog']\n",
      "BT english-french:\n",
      "['The fast brown fox jumped on the lazy dog']\n",
      "BT english-chinese:\n",
      "['Fast brown fox skips a lazy dog, skips a lazy dog.']\n",
      "context word embedding (BERT):\n",
      "['her same brown fox jumped over another lazy dog']\n"
     ]
    }
   ],
   "source": [
    "print(\"--- Original text:\")\n",
    "print(text = 'The quick brown fox jumped over the lazy dog')\n",
    "print(\"--- BT english-deutch:\")\n",
    "print(back_translation_aug_de.augment(text))\n",
    "print(\"--- BT english-french:\")\n",
    "print(back_translation_aug_fr.augment(text))\n",
    "print(\"--- BT english-chinese:\")\n",
    "print(back_translation_aug_zh.augment(text))\n",
    "print(\"--- Context word embedding (BERT):\")\n",
    "print(context_embedding_aug.augment(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aHoZMor85LDX",
   "metadata": {
    "id": "aHoZMor85LDX"
   },
   "source": [
    "il y a un pb avec la librarie predator: il y a une méthode qui a besoin d'être upgradée donc je ne peux pas l'utiliser..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "IEbxqgwO59hC",
   "metadata": {
    "id": "IEbxqgwO59hC"
   },
   "source": [
    "Synonym Augmenter \\\n",
    "Substitute word by WordNet's synonym \\\n",
    "\n",
    "Je n'ai pas très envie d'utiliser les embeddings comme synonyme car: \"bad\" \"good\" pourraient avoir des embeddings similaires (car ils sont utilisés dans les mêmes cas de figure) alors que le sentiment est totalement différent. Mais avec plusieurs exemples, on dirait que le synonyme marche moins bien que word embedding"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": [],
   "toc_visible": true
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "298px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "047a353b8a3d43a4b12ffb69bd2cc7ca": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0638e2e36cf04c7786cd0861a5443a2e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_d66e304031c7430dbb2401269e44ab0e",
       "IPY_MODEL_a155365163e545788dc5ce36b61c7c11",
       "IPY_MODEL_667acf386a594652912281c832c555d8"
      ],
      "layout": "IPY_MODEL_1db0672fd3a34232bb20f4f832009331"
     }
    },
    "09ec4ee275ee4a0bbaaed8ad6965f1cf": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0b27f9ac960c439f849eb315751a4301": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0e14803f157a4e07b0bc413258eb0b41": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_d8fb8ef864dd4861aff9771caf96c6f8",
       "IPY_MODEL_438fb60d697b4220afdf5de25c57d112",
       "IPY_MODEL_7207906283c74e4db49077092980d55f"
      ],
      "layout": "IPY_MODEL_ba56be2f668e454e9015104c0524ed42"
     }
    },
    "0f2f3080c98d4f3abe13b85a3fbaa438": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "13e1b6caf3af4a80881c36785a1362fb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1416b16857284c919e26571b7727250d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "15d7b044a63d4d76998bac3195152bea": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "1742f90b184d402899a8591187d058f2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "19f1a43e2b954777a7985e3e1dbe1f99": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "1a54aea32d004194a41034aaf66b06ce": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_3eb18e8f462f458c81e9b78076f1184b",
       "IPY_MODEL_2659ca8f88bc4637a970737045b34c6b",
       "IPY_MODEL_27d4e4f1186b41c286cb45b09a1d3cbb"
      ],
      "layout": "IPY_MODEL_303df19736ab46aa92d74d7e80fe587c"
     }
    },
    "1b5fdfeae53841788c43f138707d4c10": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_767137b046a04ef88810d23cdc11c168",
       "IPY_MODEL_7f8a76d542254de8938a93102f05a1f1",
       "IPY_MODEL_c0ec0710b6fc40099990bd9188aa72ed"
      ],
      "layout": "IPY_MODEL_97b5cde75ce647a58a4608c734a3272c"
     }
    },
    "1c6373b7d4054fd098c22b3ce76dcdf9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a6a654f333534caea912de7e24879cd9",
      "placeholder": "​",
      "style": "IPY_MODEL_1416b16857284c919e26571b7727250d",
      "value": "Downloading: 100%"
     }
    },
    "1c83f8d5cebf4cd0a55b5efce1fa0553": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ab240c8bb0264781addb1c7adcf45d2a",
       "IPY_MODEL_ce38efdc0611411aab6ccb49343da2c7",
       "IPY_MODEL_b180b33c276a4d2baa258e9c428df45f"
      ],
      "layout": "IPY_MODEL_cd263572af6b46ce81ea18e29bfd8a72"
     }
    },
    "1db0672fd3a34232bb20f4f832009331": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1e0759762ca5464b90c972ce11fc8cbc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "1e087dd0cf7e48789124b92b574296bf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d90e48c6f071486899f875715973bf07",
      "placeholder": "​",
      "style": "IPY_MODEL_677ab05fe6c24653999d0810a386414c",
      "value": "Downloading: 100%"
     }
    },
    "1fcfc06fb4f74c43b3ee37874797e2bf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ed91a32b50cb44efb83c48d902471fe7",
       "IPY_MODEL_8732bc1f48584414978838710d51efe7",
       "IPY_MODEL_21527f14de0b48bd86c2827e880caea3"
      ],
      "layout": "IPY_MODEL_b52b0d9ef7144f7bba4edb8c7f2c4037"
     }
    },
    "21527f14de0b48bd86c2827e880caea3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_288164d139b7425ab9a4d7361352bf50",
      "placeholder": "​",
      "style": "IPY_MODEL_389601841ea146399bc968b20081b775",
      "value": " 1.40k/1.40k [00:00&lt;00:00, 8.97kB/s]"
     }
    },
    "21b3c89fe37f4999bc6538fbed993dd8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_545ed3cb7e614992bd41cf39150b7d2a",
      "placeholder": "​",
      "style": "IPY_MODEL_d63d0d3de0c04963b20394192aab7659",
      "value": " 807k/807k [00:00&lt;00:00, 1.22MB/s]"
     }
    },
    "225fcf95ad6b49debc431e809162d98e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e853963f73c24d51b28e3eba4c0ac4b2",
      "placeholder": "​",
      "style": "IPY_MODEL_a47a9fe4699e409c8fcd143b9b7212fc",
      "value": "Downloading: 100%"
     }
    },
    "2659ca8f88bc4637a970737045b34c6b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_faecf1a959e849fc926213d7430abb66",
      "max": 1146,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_cb6407a7e2304eb5a5c4a8223822d0fd",
      "value": 1146
     }
    },
    "26dc81317a3e4956a98817d61e708053": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "26fa44f3cf734770859a25304b4e5631": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "27d4e4f1186b41c286cb45b09a1d3cbb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0b27f9ac960c439f849eb315751a4301",
      "placeholder": "​",
      "style": "IPY_MODEL_2d0bb9b1be704d6ca80329fd0c0d586f",
      "value": " 1.15k/1.15k [00:00&lt;00:00, 27.0kB/s]"
     }
    },
    "288164d139b7425ab9a4d7361352bf50": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "28f361d1637d453d938cfc0fd450499c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4450cc35701a409c81d29c056c5aefae",
      "placeholder": "​",
      "style": "IPY_MODEL_9aefb299fe294c2dbcf8bc1d739b2b45",
      "value": " 806k/806k [00:00&lt;00:00, 3.25MB/s]"
     }
    },
    "2bf716a9285444c2b7c25fb4cd5d26b3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2cadababb4174c7e987b56e402266b76": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2d0bb9b1be704d6ca80329fd0c0d586f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2e4837cd99d7461c805683c5bc679260": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "301ebef502394bb58efb1884fda77e4b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a489cc3e5e714d58bda5473622d4a723",
      "placeholder": "​",
      "style": "IPY_MODEL_a4e8090f53e24deb9b103e44658deab8",
      "value": " 312M/312M [00:10&lt;00:00, 29.0MB/s]"
     }
    },
    "302461a2fd104b1c9420e489749c3319": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "303df19736ab46aa92d74d7e80fe587c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3207c62077aa43caaca1eeb91eec6139": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "322fd033c726427c8d70a950805d424d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f41110567ab9417faff75de0ce7ab068",
      "placeholder": "​",
      "style": "IPY_MODEL_3d48a73f53384fa382cafa950d9084aa",
      "value": "Downloading: 100%"
     }
    },
    "351d477f56a64686a3898870faa4fd0c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "362f6afcd9d64786a54cc65165656895": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "389601841ea146399bc968b20081b775": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "39d3efda498a4af7a47fb16f45d1b1a5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_778aeee4e56f4906847aa3f2a4912abf",
      "max": 806530,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_5824febc56824822b85e9f41435da435",
      "value": 806530
     }
    },
    "3b202a5ccb0b4e098e841cf6e0b21df7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3ba5f3d06f6f43739a24edc8f77c6bd0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3d48a73f53384fa382cafa950d9084aa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3eb18e8f462f458c81e9b78076f1184b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cbc05828881a4c5482907e7a39220fd9",
      "placeholder": "​",
      "style": "IPY_MODEL_c062d231866f416d907c714a8e8ac9fd",
      "value": "Downloading: 100%"
     }
    },
    "3ee5fc7f73f347d99b7c7ace04ea86e0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "41ce66280af54fc9aa9fefc93f2b2618": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4288ef39a9f14e24ae0b127077ca2e38": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "431b9eee96c14cb38f161bc38a4fdc5c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "438fb60d697b4220afdf5de25c57d112": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d0a448d38a74438e8017e39f93da88f7",
      "max": 804600,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_5acfc915769f41bbb5979f6fc3d3a90b",
      "value": 804600
     }
    },
    "4450cc35701a409c81d29c056c5aefae": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "46929dc91a9e4c3883fa08c57b44f358": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a33c4dbf05f54c4abf0c491f70d21b63",
      "max": 440473133,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_553be9992ac1461e886e38697c907c07",
      "value": 440473133
     }
    },
    "46956cc7cc22400ea0810e5c3775f7ab": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "482814332c0b403a9682c95ae42f1aa0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4850baaabd3d4b1da905aac4169886e6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_13e1b6caf3af4a80881c36785a1362fb",
      "max": 806435,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_c1ee1dae783b4732be245cd0f596ef8e",
      "value": 806435
     }
    },
    "48954a17d26f40c69aedabe315cfa970": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4acd46200b9f43958ffdf53bb08f3fd3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_df0eb8499abf4be3a1401b205d4758d1",
      "placeholder": "​",
      "style": "IPY_MODEL_86b3b2b690d3480ab98bf2186b6002ed",
      "value": "Downloading: 100%"
     }
    },
    "4fa651eca01b47389b89ab24a12860ad": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4fd0d14204ff49c287976a6e759eb7f7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4fe1850faf8f457e9bbadd8da0d2d4f6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4288ef39a9f14e24ae0b127077ca2e38",
      "placeholder": "​",
      "style": "IPY_MODEL_f47bb3855a134751840e3106c55be3a8",
      "value": " 44.0/44.0 [00:00&lt;00:00, 1.00kB/s]"
     }
    },
    "5015d03654bf42a0bbf4e02d3f673d74": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3ee5fc7f73f347d99b7c7ace04ea86e0",
      "max": 440473133,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_15d7b044a63d4d76998bac3195152bea",
      "value": 440473133
     }
    },
    "545ed3cb7e614992bd41cf39150b7d2a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "553be9992ac1461e886e38697c907c07": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "5824febc56824822b85e9f41435da435": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "593d4d3233f246f197cfce0f5a9ff895": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_322fd033c726427c8d70a950805d424d",
       "IPY_MODEL_b646da4054de4cfd8cf6170ae52eb8fc",
       "IPY_MODEL_5ee5dacb4a5743a3a6d365a643deae86"
      ],
      "layout": "IPY_MODEL_6463fed1d02c4804b332273087a2b835"
     }
    },
    "5acfc915769f41bbb5979f6fc3d3a90b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "5b413ed735574e2e91b8612bea32ed86": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5b8d418f764c4e2cbee71f7561303422": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "5c5c01bb411d43288d052c0b06f71beb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_1e087dd0cf7e48789124b92b574296bf",
       "IPY_MODEL_bb2472d60eb04510a088ab46666d90b5",
       "IPY_MODEL_f2a1698861ef44d6ad09156f622aa773"
      ],
      "layout": "IPY_MODEL_bfa82d5bdc0244f9bae0e9dab63c8d00"
     }
    },
    "5ee5dacb4a5743a3a6d365a643deae86": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fe9b65930d1a4091a54e272d0f6f72a6",
      "placeholder": "​",
      "style": "IPY_MODEL_b5333a4b868e4b56a3b513eddcfee8b6",
      "value": " 805k/805k [00:00&lt;00:00, 1.47MB/s]"
     }
    },
    "63fec4552090431f95a82b458c0687c4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_4acd46200b9f43958ffdf53bb08f3fd3",
       "IPY_MODEL_5015d03654bf42a0bbf4e02d3f673d74",
       "IPY_MODEL_e5ea02543f05499f89bbfb1c8e47c4f2"
      ],
      "layout": "IPY_MODEL_4fd0d14204ff49c287976a6e759eb7f7"
     }
    },
    "6463fed1d02c4804b332273087a2b835": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "667acf386a594652912281c832c555d8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cb199a8c4a00474baed049f3bdb903b9",
      "placeholder": "​",
      "style": "IPY_MODEL_bc4662eaa2304857b5d56f58d3d96418",
      "value": " 1.62M/1.62M [00:00&lt;00:00, 2.53MB/s]"
     }
    },
    "677ab05fe6c24653999d0810a386414c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6b0e769481bf413a94d51812cb3f7344": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "71578ef1dd0f402e8913f3291e6709e3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ff7c05e0fe8947a8917ab5e52eae59ab",
       "IPY_MODEL_c09ef55a074846e185a806654c2cbaf2",
       "IPY_MODEL_4fe1850faf8f457e9bbadd8da0d2d4f6"
      ],
      "layout": "IPY_MODEL_09ec4ee275ee4a0bbaaed8ad6965f1cf"
     }
    },
    "7207906283c74e4db49077092980d55f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e68d1ef2b5f748638be4a51ee5891e8c",
      "placeholder": "​",
      "style": "IPY_MODEL_f8bf929721844352a87803f89eec2cab",
      "value": " 805k/805k [00:00&lt;00:00, 1.11MB/s]"
     }
    },
    "72f554ddaf2041649ef72c62a5652571": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0f2f3080c98d4f3abe13b85a3fbaa438",
      "max": 433,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_f9c0494b0a5140a3a02f424830713be7",
      "value": 433
     }
    },
    "7458953c7b784aa5be8873a1d507cf4b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "767137b046a04ef88810d23cdc11c168": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_351d477f56a64686a3898870faa4fd0c",
      "placeholder": "​",
      "style": "IPY_MODEL_e331408f40244432a4ea95a80e9c0a96",
      "value": "Downloading: 100%"
     }
    },
    "778aeee4e56f4906847aa3f2a4912abf": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "77a0827e8a5649f6849a77c37de0cff9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_9e7510c5f8b54e14b711c4d741728810",
       "IPY_MODEL_9dff2660a64b49319653d430efd8bf1f",
       "IPY_MODEL_993f6a2f1d154840bb0b2196bb2cfad6"
      ],
      "layout": "IPY_MODEL_937b99b4f4ac4b4b971b60eae83f5dd9"
     }
    },
    "7abbba5462504d1e9148d77b3a86e2fa": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7e610cf12b694931a89e43633871cd4a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ee0bb7d628bc4dbc8ab41ab1142dcd0b",
      "placeholder": "​",
      "style": "IPY_MODEL_3b202a5ccb0b4e098e841cf6e0b21df7",
      "value": " 433/433 [00:00&lt;00:00, 4.21kB/s]"
     }
    },
    "7f8a76d542254de8938a93102f05a1f1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_dda77b1660764f7a8767eb1fa008013d",
      "max": 1617902,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_c2fea66ed9574f57b632c5263899da53",
      "value": 1617902
     }
    },
    "80787272cccd48c286df91f3f7b44623": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "83b9db1f64534be5be3f9b7429a69278": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "86b3b2b690d3480ab98bf2186b6002ed": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "86fdafd575604762a8a95a98111978c1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8732bc1f48584414978838710d51efe7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_46956cc7cc22400ea0810e5c3775f7ab",
      "max": 1403,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_5b8d418f764c4e2cbee71f7561303422",
      "value": 1403
     }
    },
    "8a353b4de7574bdaacc029599a3c83f8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8d4ef526c1c7470b9628eb6a205da9c1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_225fcf95ad6b49debc431e809162d98e",
       "IPY_MODEL_72f554ddaf2041649ef72c62a5652571",
       "IPY_MODEL_7e610cf12b694931a89e43633871cd4a"
      ],
      "layout": "IPY_MODEL_f1d2c5383db94e4fbd69b0ea6ec026e9"
     }
    },
    "937b99b4f4ac4b4b971b60eae83f5dd9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "97b5cde75ce647a58a4608c734a3272c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "993f6a2f1d154840bb0b2196bb2cfad6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7abbba5462504d1e9148d77b3a86e2fa",
      "placeholder": "​",
      "style": "IPY_MODEL_7458953c7b784aa5be8873a1d507cf4b",
      "value": " 232k/232k [00:00&lt;00:00, 701kB/s]"
     }
    },
    "9a28295ee2a04858bf391e779db511fb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9aefb299fe294c2dbcf8bc1d739b2b45": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9b4bc9be8d7a4d67880ef3bf4b79a139": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9b64b0dda456466288e1ece519207b53": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9cf008d0995e4795ab843abbd97ed846": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9dff2660a64b49319653d430efd8bf1f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5b413ed735574e2e91b8612bea32ed86",
      "max": 231508,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_bb371fa55a9048a0963ebc61667253af",
      "value": 231508
     }
    },
    "9e7510c5f8b54e14b711c4d741728810": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3ba5f3d06f6f43739a24edc8f77c6bd0",
      "placeholder": "​",
      "style": "IPY_MODEL_f109772146774fca9206d8bdbbf439e7",
      "value": "Downloading: 100%"
     }
    },
    "a0408f29fa1243dcb9ca0ca93ed097b6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_482814332c0b403a9682c95ae42f1aa0",
      "placeholder": "​",
      "style": "IPY_MODEL_3207c62077aa43caaca1eeb91eec6139",
      "value": "Downloading: 100%"
     }
    },
    "a0e1289f7d134b3798cc9b11ec607dc8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_a0408f29fa1243dcb9ca0ca93ed097b6",
       "IPY_MODEL_39d3efda498a4af7a47fb16f45d1b1a5",
       "IPY_MODEL_21b3c89fe37f4999bc6538fbed993dd8"
      ],
      "layout": "IPY_MODEL_26fa44f3cf734770859a25304b4e5631"
     }
    },
    "a155365163e545788dc5ce36b61c7c11": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2e4837cd99d7461c805683c5bc679260",
      "max": 1617791,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_19f1a43e2b954777a7985e3e1dbe1f99",
      "value": 1617791
     }
    },
    "a33c4dbf05f54c4abf0c491f70d21b63": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a47a9fe4699e409c8fcd143b9b7212fc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a489cc3e5e714d58bda5473622d4a723": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a4e8090f53e24deb9b103e44658deab8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a6a654f333534caea912de7e24879cd9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a7f26145316445879a13fbc498949ebb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ab240c8bb0264781addb1c7adcf45d2a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9b64b0dda456466288e1ece519207b53",
      "placeholder": "​",
      "style": "IPY_MODEL_dd3a0ed672d44227b45ac6536e5b0986",
      "value": "Downloading: 100%"
     }
    },
    "ab6cb4f2eef44cb58d7586a27f52ce05": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ac59508ba83c485a8e34a6ce4f6293e6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_1c6373b7d4054fd098c22b3ce76dcdf9",
       "IPY_MODEL_46929dc91a9e4c3883fa08c57b44f358",
       "IPY_MODEL_c29dc12cbe4043ddad242c9a5f54518a"
      ],
      "layout": "IPY_MODEL_2cadababb4174c7e987b56e402266b76"
     }
    },
    "b106cbdad1b445d586a84e53752300c1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "b1722ede78dd4fd281306c0a41054f9e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b180b33c276a4d2baa258e9c428df45f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cab69e336c7d4c4da67a8d200b4bf7c3",
      "placeholder": "​",
      "style": "IPY_MODEL_80787272cccd48c286df91f3f7b44623",
      "value": " 312M/312M [00:18&lt;00:00, 22.2MB/s]"
     }
    },
    "b52b0d9ef7144f7bba4edb8c7f2c4037": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b5333a4b868e4b56a3b513eddcfee8b6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b646da4054de4cfd8cf6170ae52eb8fc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9a28295ee2a04858bf391e779db511fb",
      "max": 804677,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_bd4dce92072f405f8ec75cf7e8eeb7cf",
      "value": 804677
     }
    },
    "b97e0f619dea45f8bfeaeccb96afa79f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ba56be2f668e454e9015104c0524ed42": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ba6f611d1c3043c8b362e5e1a803e974": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "bb2472d60eb04510a088ab46666d90b5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_302461a2fd104b1c9420e489749c3319",
      "max": 44,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_b106cbdad1b445d586a84e53752300c1",
      "value": 44
     }
    },
    "bb371fa55a9048a0963ebc61667253af": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "bc4662eaa2304857b5d56f58d3d96418": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "bd4dce92072f405f8ec75cf7e8eeb7cf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "bf58738e9cf94a0483e2e580582aface": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_41ce66280af54fc9aa9fefc93f2b2618",
      "max": 312087009,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_1e0759762ca5464b90c972ce11fc8cbc",
      "value": 312087009
     }
    },
    "bfa82d5bdc0244f9bae0e9dab63c8d00": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c062d231866f416d907c714a8e8ac9fd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c09ef55a074846e185a806654c2cbaf2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_362f6afcd9d64786a54cc65165656895",
      "max": 44,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_83b9db1f64534be5be3f9b7429a69278",
      "value": 44
     }
    },
    "c0ec0710b6fc40099990bd9188aa72ed": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8a353b4de7574bdaacc029599a3c83f8",
      "placeholder": "​",
      "style": "IPY_MODEL_4fa651eca01b47389b89ab24a12860ad",
      "value": " 1.62M/1.62M [00:00&lt;00:00, 7.73MB/s]"
     }
    },
    "c1c6a35b85294c91b5ebef0df04758ce": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c1ee1dae783b4732be245cd0f596ef8e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "c29dc12cbe4043ddad242c9a5f54518a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9cf008d0995e4795ab843abbd97ed846",
      "placeholder": "​",
      "style": "IPY_MODEL_86fdafd575604762a8a95a98111978c1",
      "value": " 440M/440M [00:11&lt;00:00, 42.6MB/s]"
     }
    },
    "c2fea66ed9574f57b632c5263899da53": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "c9195a2570234405a00a90aa0cded2a1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c94fa6299d44482692219a338ab46389": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6b0e769481bf413a94d51812cb3f7344",
      "placeholder": "​",
      "style": "IPY_MODEL_c1c6a35b85294c91b5ebef0df04758ce",
      "value": "Downloading: 100%"
     }
    },
    "cab69e336c7d4c4da67a8d200b4bf7c3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cb199a8c4a00474baed049f3bdb903b9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cb6407a7e2304eb5a5c4a8223822d0fd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "cbc05828881a4c5482907e7a39220fd9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cd263572af6b46ce81ea18e29bfd8a72": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ce38efdc0611411aab6ccb49343da2c7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ec2940914e144d1ba57d781de3879519",
      "max": 312087009,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_ba6f611d1c3043c8b362e5e1a803e974",
      "value": 312087009
     }
    },
    "d0a448d38a74438e8017e39f93da88f7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d4b162c9b44640f29a01a15cfef6ecd5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_e7fc95e0a7884f5e9619dd3ff9cb8ba4",
       "IPY_MODEL_4850baaabd3d4b1da905aac4169886e6",
       "IPY_MODEL_28f361d1637d453d938cfc0fd450499c"
      ],
      "layout": "IPY_MODEL_f6ce00ccc5f44e7c8355d1dc99b36ab8"
     }
    },
    "d63d0d3de0c04963b20394192aab7659": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d66e304031c7430dbb2401269e44ab0e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b97e0f619dea45f8bfeaeccb96afa79f",
      "placeholder": "​",
      "style": "IPY_MODEL_a7f26145316445879a13fbc498949ebb",
      "value": "Downloading: 100%"
     }
    },
    "d8fb8ef864dd4861aff9771caf96c6f8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d97da4b207ca4775bdb2997e8d16603a",
      "placeholder": "​",
      "style": "IPY_MODEL_26dc81317a3e4956a98817d61e708053",
      "value": "Downloading: 100%"
     }
    },
    "d90e48c6f071486899f875715973bf07": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d97da4b207ca4775bdb2997e8d16603a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dd3a0ed672d44227b45ac6536e5b0986": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "dda77b1660764f7a8767eb1fa008013d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "df0eb8499abf4be3a1401b205d4758d1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e16695049eea47b79a1da7d48201d462": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e194fc6070214eb5b0bebef0270eac4b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_c94fa6299d44482692219a338ab46389",
       "IPY_MODEL_bf58738e9cf94a0483e2e580582aface",
       "IPY_MODEL_301ebef502394bb58efb1884fda77e4b"
      ],
      "layout": "IPY_MODEL_431b9eee96c14cb38f161bc38a4fdc5c"
     }
    },
    "e331408f40244432a4ea95a80e9c0a96": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e5ea02543f05499f89bbfb1c8e47c4f2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_eb01ea39b3ff41d38bb944f7034afedb",
      "placeholder": "​",
      "style": "IPY_MODEL_e16695049eea47b79a1da7d48201d462",
      "value": " 440M/440M [00:16&lt;00:00, 30.0MB/s]"
     }
    },
    "e68d1ef2b5f748638be4a51ee5891e8c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e7fc95e0a7884f5e9619dd3ff9cb8ba4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c9195a2570234405a00a90aa0cded2a1",
      "placeholder": "​",
      "style": "IPY_MODEL_ab6cb4f2eef44cb58d7586a27f52ce05",
      "value": "Downloading: 100%"
     }
    },
    "e853963f73c24d51b28e3eba4c0ac4b2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "eb01ea39b3ff41d38bb944f7034afedb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ec2940914e144d1ba57d781de3879519": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ed91a32b50cb44efb83c48d902471fe7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b1722ede78dd4fd281306c0a41054f9e",
      "placeholder": "​",
      "style": "IPY_MODEL_047a353b8a3d43a4b12ffb69bd2cc7ca",
      "value": "Downloading: 100%"
     }
    },
    "ee0bb7d628bc4dbc8ab41ab1142dcd0b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f109772146774fca9206d8bdbbf439e7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f1d2c5383db94e4fbd69b0ea6ec026e9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f2a1698861ef44d6ad09156f622aa773": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2bf716a9285444c2b7c25fb4cd5d26b3",
      "placeholder": "​",
      "style": "IPY_MODEL_9b4bc9be8d7a4d67880ef3bf4b79a139",
      "value": " 44.0/44.0 [00:00&lt;00:00, 665B/s]"
     }
    },
    "f41110567ab9417faff75de0ce7ab068": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f47bb3855a134751840e3106c55be3a8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f6ce00ccc5f44e7c8355d1dc99b36ab8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f8bf929721844352a87803f89eec2cab": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f9c0494b0a5140a3a02f424830713be7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "faecf1a959e849fc926213d7430abb66": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fe9b65930d1a4091a54e272d0f6f72a6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ff7c05e0fe8947a8917ab5e52eae59ab": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1742f90b184d402899a8591187d058f2",
      "placeholder": "​",
      "style": "IPY_MODEL_48954a17d26f40c69aedabe315cfa970",
      "value": "Downloading: 100%"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
