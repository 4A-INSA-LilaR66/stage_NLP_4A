{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e87c6f70",
   "metadata": {},
   "source": [
    "# Dashbord Project Part 3: Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4a754da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#libraries\n",
    "#----------------------------------------------\n",
    "import pandas as pd\n",
    "from pylab import * \n",
    "import numpy as np\n",
    "import numpy.linalg as npl\n",
    "import matplotlib.pyplot as plt #to plot graphs\n",
    "import matplotlib.patches as mpatches #to customize legend\n",
    "import seaborn as sns #to plot graphs\n",
    "import math \n",
    "import re #to find integers & floats in a string \n",
    "from statsmodels.graphics.mosaicplot import mosaic #for mosaic plot\n",
    "from collections import Counter #to count values in a dataframe or array\n",
    "from datetime import date, timedelta, datetime #for the date\n",
    "import datetime as dt\n",
    "import pylab \n",
    "import scipy.stats as stats\n",
    "import statsmodels\n",
    "import os\n",
    "\n",
    "# To import missingpy: \n",
    "# When importing missingpy it tries to import automatically 'sklearn.neighbors.base' however in the new versions \n",
    "# of sklearn it has been renamed to 'sklearn.neighbors._base' so we have to manually import it to work. \n",
    "import sklearn.neighbors._base\n",
    "sys.modules['sklearn.neighbors.base'] = sklearn.neighbors._base\n",
    "from missingpy import MissForest\n",
    "\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0288703",
   "metadata": {},
   "source": [
    "Run: \n",
    "\n",
    "1) everythig without satisfactoriness & sentiment analysis (OK 3 labels)\\\n",
    "2) everything without sentiment analysis features (OK 3 labels) \\\n",
    "3) everything without satisfactoriness features (OK 3 labels)\\\n",
    "4) everything (added by me) (OK 3 labels, 2 labels)\n",
    "\n",
    "Try NN: 4-5 layers "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73d878f8",
   "metadata": {},
   "source": [
    "## File Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "33f95060",
   "metadata": {},
   "outputs": [],
   "source": [
    "# File loading. The file must be in the current directory\n",
    "#---------------------------------------\n",
    "dfPredC_3 = pd.read_pickle(\"data/dfPredC_3.pkl\") #3 labels\n",
    "dfPredC_2 = pd.read_pickle(\"data/dfPredC_2.pkl\") #2 labels\n",
    "\n",
    "#dfPredC_3 = pd.read_excel(os.getcwd() + \"\\\\dfPredC_3.xslx\") #3 labels\n",
    "#dfPredC_2 = pd.read_excel(\"dfPredC_2.xslx\") #2 labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "054eb6ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Student</th>\n",
       "      <th>Marks</th>\n",
       "      <th>module</th>\n",
       "      <th>Year</th>\n",
       "      <th>Supervisor</th>\n",
       "      <th>nbMeetings</th>\n",
       "      <th>worstProgress</th>\n",
       "      <th>meanTimeBetweenMeet</th>\n",
       "      <th>meanTimeMeet</th>\n",
       "      <th>timeFirstDecay</th>\n",
       "      <th>mainSentiment</th>\n",
       "      <th>is0Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>H4</td>\n",
       "      <td>mcm</td>\n",
       "      <td>2018</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>satisfactory</td>\n",
       "      <td>72</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14</td>\n",
       "      <td>H5</td>\n",
       "      <td>mcm</td>\n",
       "      <td>2018</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>satisfactory</td>\n",
       "      <td>0</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>66</td>\n",
       "      <td>H5</td>\n",
       "      <td>mcm</td>\n",
       "      <td>2018</td>\n",
       "      <td>27</td>\n",
       "      <td>5</td>\n",
       "      <td>unsatisfactory</td>\n",
       "      <td>29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>176.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>79</td>\n",
       "      <td>H5</td>\n",
       "      <td>mcm</td>\n",
       "      <td>2018</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>unsatisfactory</td>\n",
       "      <td>21</td>\n",
       "      <td>31.428571</td>\n",
       "      <td>143.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>109</td>\n",
       "      <td>N</td>\n",
       "      <td>mcm</td>\n",
       "      <td>2018</td>\n",
       "      <td>45</td>\n",
       "      <td>5</td>\n",
       "      <td>satisfactory</td>\n",
       "      <td>34</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Student Marks module  Year  Supervisor  nbMeetings   worstProgress  \\\n",
       "0         4    H4    mcm  2018          17           2    satisfactory   \n",
       "4        14    H5    mcm  2018          41           1    satisfactory   \n",
       "7        66    H5    mcm  2018          27           5  unsatisfactory   \n",
       "15       79    H5    mcm  2018           5           8  unsatisfactory   \n",
       "22      109     N    mcm  2018          45           5    satisfactory   \n",
       "\n",
       "    meanTimeBetweenMeet  meanTimeMeet  timeFirstDecay mainSentiment  \\\n",
       "0                    72           NaN             0.0           1.0   \n",
       "4                     0     10.000000             0.0           2.0   \n",
       "7                    29           NaN           176.0           0.0   \n",
       "15                   21     31.428571           143.0           1.0   \n",
       "22                   34           NaN             0.0           1.0   \n",
       "\n",
       "   is0Sentiment  \n",
       "0         False  \n",
       "4         False  \n",
       "7          True  \n",
       "15         True  \n",
       "22        False  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfPredC_3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8265e5f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Student</th>\n",
       "      <th>Marks</th>\n",
       "      <th>module</th>\n",
       "      <th>Year</th>\n",
       "      <th>Supervisor</th>\n",
       "      <th>nbMeetings</th>\n",
       "      <th>worstProgress</th>\n",
       "      <th>meanTimeBetweenMeet</th>\n",
       "      <th>meanTimeMeet</th>\n",
       "      <th>timeFirstDecay</th>\n",
       "      <th>mainSentiment</th>\n",
       "      <th>is0Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>H4</td>\n",
       "      <td>mcm</td>\n",
       "      <td>2018</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>satisfactory</td>\n",
       "      <td>72</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14</td>\n",
       "      <td>H5</td>\n",
       "      <td>mcm</td>\n",
       "      <td>2018</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>satisfactory</td>\n",
       "      <td>0</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>66</td>\n",
       "      <td>H5</td>\n",
       "      <td>mcm</td>\n",
       "      <td>2018</td>\n",
       "      <td>27</td>\n",
       "      <td>5</td>\n",
       "      <td>unsatisfactory</td>\n",
       "      <td>29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>176.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>79</td>\n",
       "      <td>H5</td>\n",
       "      <td>mcm</td>\n",
       "      <td>2018</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>unsatisfactory</td>\n",
       "      <td>21</td>\n",
       "      <td>31.428571</td>\n",
       "      <td>143.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>109</td>\n",
       "      <td>N</td>\n",
       "      <td>mcm</td>\n",
       "      <td>2018</td>\n",
       "      <td>45</td>\n",
       "      <td>5</td>\n",
       "      <td>satisfactory</td>\n",
       "      <td>34</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Student Marks module  Year  Supervisor  nbMeetings   worstProgress  \\\n",
       "0         4    H4    mcm  2018          17           2    satisfactory   \n",
       "4        14    H5    mcm  2018          41           1    satisfactory   \n",
       "7        66    H5    mcm  2018          27           5  unsatisfactory   \n",
       "15       79    H5    mcm  2018           5           8  unsatisfactory   \n",
       "22      109     N    mcm  2018          45           5    satisfactory   \n",
       "\n",
       "    meanTimeBetweenMeet  meanTimeMeet  timeFirstDecay mainSentiment  \\\n",
       "0                    72           NaN             0.0           1.0   \n",
       "4                     0     10.000000             0.0           1.0   \n",
       "7                    29           NaN           176.0           0.0   \n",
       "15                   21     31.428571           143.0           1.0   \n",
       "22                   34           NaN             0.0           1.0   \n",
       "\n",
       "   is0Sentiment  \n",
       "0         False  \n",
       "4         False  \n",
       "7          True  \n",
       "15         True  \n",
       "22        False  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfPredC_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2377ef6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------\n",
      "dfPredC_3:\n",
      "---------\n",
      "Student                   int32\n",
      "Marks                  category\n",
      "module                 category\n",
      "Year                      int64\n",
      "Supervisor                int32\n",
      "nbMeetings                int64\n",
      "worstProgress          category\n",
      "meanTimeBetweenMeet       int64\n",
      "meanTimeMeet            float64\n",
      "timeFirstDecay          float64\n",
      "mainSentiment          category\n",
      "is0Sentiment           category\n",
      "dtype: object\n",
      "---------\n",
      "dfPredC_2:\n",
      "---------\n",
      "Student                   int32\n",
      "Marks                  category\n",
      "module                 category\n",
      "Year                      int64\n",
      "Supervisor                int32\n",
      "nbMeetings                int64\n",
      "worstProgress          category\n",
      "meanTimeBetweenMeet       int64\n",
      "meanTimeMeet            float64\n",
      "timeFirstDecay          float64\n",
      "mainSentiment          category\n",
      "is0Sentiment           category\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(\"---------\\ndfPredC_3:\\n---------\")\n",
    "print(dfPredC_3.dtypes)\n",
    "print(\"---------\\ndfPredC_2:\\n---------\")\n",
    "print(dfPredC_2.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "045de143",
   "metadata": {},
   "source": [
    "## Create Dummy variables \n",
    "To transform categorical variables into real numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6bf49a2",
   "metadata": {},
   "source": [
    "<font color = 'blue'> **Modify this cell** </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9720dd1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- 3 labels\n",
    "dfPredC = dfPredC_3\n",
    "#-- 2 labels\n",
    "#dfPredC = dfPredC_2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77a76b9f",
   "metadata": {},
   "source": [
    "<font color = 'blue'> **Modify this cell** </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8b5d4ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Remove some features from dfPredC if necessary\n",
    "#------------------------------------------------\n",
    "# Remove features related to sentiment analysis \n",
    "#dfPredC.drop([\"mainSentiment\",\"is0Sentiment\"],axis=1,inplace = True)\n",
    "             \n",
    "# Remove features related to satisfactoriness\n",
    "#dfPredC.drop([\"worstProgress\",\"timeFirstDecay\"],axis=1,inplace = True)\n",
    "\n",
    "# Remove features related to satisfactoriness and sentiment analysis\n",
    "#dfPredC.drop([\"mainSentiment\",\"is0Sentiment\",\"worstProgress\",\"timeFirstDecay\"],axis=1,inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "490f531e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Student</th>\n",
       "      <th>Marks</th>\n",
       "      <th>module</th>\n",
       "      <th>Year</th>\n",
       "      <th>Supervisor</th>\n",
       "      <th>nbMeetings</th>\n",
       "      <th>worstProgress</th>\n",
       "      <th>meanTimeBetweenMeet</th>\n",
       "      <th>meanTimeMeet</th>\n",
       "      <th>timeFirstDecay</th>\n",
       "      <th>mainSentiment</th>\n",
       "      <th>is0Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>H4</td>\n",
       "      <td>mcm</td>\n",
       "      <td>2018</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>satisfactory</td>\n",
       "      <td>72</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14</td>\n",
       "      <td>H5</td>\n",
       "      <td>mcm</td>\n",
       "      <td>2018</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>satisfactory</td>\n",
       "      <td>0</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>66</td>\n",
       "      <td>H5</td>\n",
       "      <td>mcm</td>\n",
       "      <td>2018</td>\n",
       "      <td>27</td>\n",
       "      <td>5</td>\n",
       "      <td>unsatisfactory</td>\n",
       "      <td>29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>176.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>79</td>\n",
       "      <td>H5</td>\n",
       "      <td>mcm</td>\n",
       "      <td>2018</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>unsatisfactory</td>\n",
       "      <td>21</td>\n",
       "      <td>31.428571</td>\n",
       "      <td>143.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>109</td>\n",
       "      <td>N</td>\n",
       "      <td>mcm</td>\n",
       "      <td>2018</td>\n",
       "      <td>45</td>\n",
       "      <td>5</td>\n",
       "      <td>satisfactory</td>\n",
       "      <td>34</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Student Marks module  Year  Supervisor  nbMeetings   worstProgress  \\\n",
       "0         4    H4    mcm  2018          17           2    satisfactory   \n",
       "4        14    H5    mcm  2018          41           1    satisfactory   \n",
       "7        66    H5    mcm  2018          27           5  unsatisfactory   \n",
       "15       79    H5    mcm  2018           5           8  unsatisfactory   \n",
       "22      109     N    mcm  2018          45           5    satisfactory   \n",
       "\n",
       "    meanTimeBetweenMeet  meanTimeMeet  timeFirstDecay mainSentiment  \\\n",
       "0                    72           NaN             0.0           1.0   \n",
       "4                     0     10.000000             0.0           2.0   \n",
       "7                    29           NaN           176.0           0.0   \n",
       "15                   21     31.428571           143.0           1.0   \n",
       "22                   34           NaN             0.0           1.0   \n",
       "\n",
       "   is0Sentiment  \n",
       "0         False  \n",
       "4         False  \n",
       "7          True  \n",
       "15         True  \n",
       "22        False  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfPredC.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "43b40cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = dfPredC[\"Marks\"] #variable response\n",
    "X = dfPredC.drop(\"Marks\",axis=1) #explanatory variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "42030f37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of variables: 20\n"
     ]
    }
   ],
   "source": [
    "X = pd.get_dummies(X) #create dummy variables\n",
    "print(\"number of variables:\",np.shape(X)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1a71c3f0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Student</th>\n",
       "      <th>Year</th>\n",
       "      <th>Supervisor</th>\n",
       "      <th>nbMeetings</th>\n",
       "      <th>meanTimeBetweenMeet</th>\n",
       "      <th>meanTimeMeet</th>\n",
       "      <th>timeFirstDecay</th>\n",
       "      <th>module_ca326</th>\n",
       "      <th>module_ca400</th>\n",
       "      <th>module_ca472</th>\n",
       "      <th>module_mcm</th>\n",
       "      <th>module_pnu</th>\n",
       "      <th>worstProgress_moderate</th>\n",
       "      <th>worstProgress_satisfactory</th>\n",
       "      <th>worstProgress_unsatisfactory</th>\n",
       "      <th>mainSentiment_0.0</th>\n",
       "      <th>mainSentiment_1.0</th>\n",
       "      <th>mainSentiment_2.0</th>\n",
       "      <th>is0Sentiment_False</th>\n",
       "      <th>is0Sentiment_True</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>2018</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>72</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14</td>\n",
       "      <td>2018</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>66</td>\n",
       "      <td>2018</td>\n",
       "      <td>27</td>\n",
       "      <td>5</td>\n",
       "      <td>29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>176.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>79</td>\n",
       "      <td>2018</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>21</td>\n",
       "      <td>31.428571</td>\n",
       "      <td>143.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>109</td>\n",
       "      <td>2018</td>\n",
       "      <td>45</td>\n",
       "      <td>5</td>\n",
       "      <td>34</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Student  Year  Supervisor  nbMeetings  meanTimeBetweenMeet  meanTimeMeet  \\\n",
       "0         4  2018          17           2                   72           NaN   \n",
       "4        14  2018          41           1                    0     10.000000   \n",
       "7        66  2018          27           5                   29           NaN   \n",
       "15       79  2018           5           8                   21     31.428571   \n",
       "22      109  2018          45           5                   34           NaN   \n",
       "\n",
       "    timeFirstDecay  module_ca326  module_ca400  module_ca472  module_mcm  \\\n",
       "0              0.0             0             0             0           1   \n",
       "4              0.0             0             0             0           1   \n",
       "7            176.0             0             0             0           1   \n",
       "15           143.0             0             0             0           1   \n",
       "22             0.0             0             0             0           1   \n",
       "\n",
       "    module_pnu  worstProgress_moderate  worstProgress_satisfactory  \\\n",
       "0            0                       0                           1   \n",
       "4            0                       0                           1   \n",
       "7            0                       0                           0   \n",
       "15           0                       0                           0   \n",
       "22           0                       0                           1   \n",
       "\n",
       "    worstProgress_unsatisfactory  mainSentiment_0.0  mainSentiment_1.0  \\\n",
       "0                              0                  0                  1   \n",
       "4                              0                  0                  0   \n",
       "7                              1                  1                  0   \n",
       "15                             1                  0                  1   \n",
       "22                             0                  0                  1   \n",
       "\n",
       "    mainSentiment_2.0  is0Sentiment_False  is0Sentiment_True  \n",
       "0                   0                   1                  0  \n",
       "4                   1                   1                  0  \n",
       "7                   0                   0                  1  \n",
       "15                  0                   0                  1  \n",
       "22                  0                   1                  0  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fac962dd",
   "metadata": {},
   "source": [
    "## Data imputation\n",
    "\n",
    "- Apparently, the Random Forest algorithm (RF) cannot handle missing (NaN) values. The reason is beacause this RF algorithm is not build on CART trees (which we know can handle missing values) but on other decision trees for computation reasons: https://stats.stackexchange.com/questions/98953/why-doesnt-random-forest-handle-missing-values-in-predictors\n",
    "\n",
    "- Multinomial logistic regression cannot handle missing values too. \n",
    "\n",
    "We need to imput data.\\\n",
    "Tutorial used: https://towardsdatascience.com/how-to-use-python-and-missforest-algorithm-to-impute-missing-data-ed45eb47cb9a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ad2dc62",
   "metadata": {},
   "source": [
    "<font color = 'blue'> **Modify this cell** </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a6523869",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n"
     ]
    }
   ],
   "source": [
    "# Ignore all warnings produced by \"MissForest\". Those are \"future warnings\"\n",
    "#---------------------------------------\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Make an instance and perform the imputation\n",
    "# For imputation, we can use all explanaroty variables (even columns without mising values)\n",
    "#---------------------------------------\n",
    "imputer = MissForest()#data imputation with missForest\n",
    "#================================\n",
    "imputer.fit(X,cat_vars = np.arange(6,len(X.columns))) #specify categorical variables \n",
    "#================================\n",
    "\n",
    "X_imp = pd.DataFrame(imputer.transform(X)) \n",
    "\n",
    "# Note: the categorical variables need to be one-hot-encoded (also known as dummy encoded)\n",
    "# and they need to be explicitly identified during the imputer's fit() method call\n",
    "# documentation: \n",
    "# https://github.com/epsilon-machine/missingpy\n",
    "# https://towardsdatascience.com/how-to-use-python-and-missforest-algorithm-to-impute-missing-data-ed45eb47cb9a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a79efdcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename all columns with the correct name:\n",
    "#---------------------------------------\n",
    "for i in range(X_imp.shape[1]):\n",
    "    X_imp.rename(columns = {i:X.columns[i]},inplace=True)\n",
    "    \n",
    "# Assign Student IDs to index:\n",
    "#---------------------------------------\n",
    "X_imp.index = X_imp.Student #indices are now Student IDs\n",
    "X_imp.drop(\"Student\",axis=1,inplace=True) #drop Student IDs column\n",
    "\n",
    "# Assign correct type to data:\n",
    "#---------------------------------------\n",
    "X_imp.index= X_imp.index.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cd0c7d6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Year                            float64\n",
       "Supervisor                      float64\n",
       "nbMeetings                      float64\n",
       "meanTimeBetweenMeet             float64\n",
       "meanTimeMeet                    float64\n",
       "timeFirstDecay                  float64\n",
       "module_ca326                    float64\n",
       "module_ca400                    float64\n",
       "module_ca472                    float64\n",
       "module_mcm                      float64\n",
       "module_pnu                      float64\n",
       "worstProgress_moderate          float64\n",
       "worstProgress_satisfactory      float64\n",
       "worstProgress_unsatisfactory    float64\n",
       "mainSentiment_0.0               float64\n",
       "mainSentiment_1.0               float64\n",
       "mainSentiment_2.0               float64\n",
       "is0Sentiment_False              float64\n",
       "is0Sentiment_True               float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_imp.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "53982466",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Supervisor</th>\n",
       "      <th>nbMeetings</th>\n",
       "      <th>meanTimeBetweenMeet</th>\n",
       "      <th>meanTimeMeet</th>\n",
       "      <th>timeFirstDecay</th>\n",
       "      <th>module_ca326</th>\n",
       "      <th>module_ca400</th>\n",
       "      <th>module_ca472</th>\n",
       "      <th>module_mcm</th>\n",
       "      <th>module_pnu</th>\n",
       "      <th>worstProgress_moderate</th>\n",
       "      <th>worstProgress_satisfactory</th>\n",
       "      <th>worstProgress_unsatisfactory</th>\n",
       "      <th>mainSentiment_0.0</th>\n",
       "      <th>mainSentiment_1.0</th>\n",
       "      <th>mainSentiment_2.0</th>\n",
       "      <th>is0Sentiment_False</th>\n",
       "      <th>is0Sentiment_True</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Student</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>135.535429</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2018.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>2018.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>53.163905</td>\n",
       "      <td>176.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>2018.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>31.428571</td>\n",
       "      <td>143.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>2018.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>30.316699</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Year  Supervisor  nbMeetings  meanTimeBetweenMeet  meanTimeMeet  \\\n",
       "Student                                                                      \n",
       "4        2018.0        17.0         2.0                 72.0    135.535429   \n",
       "14       2018.0        41.0         1.0                  0.0     10.000000   \n",
       "66       2018.0        27.0         5.0                 29.0     53.163905   \n",
       "79       2018.0         5.0         8.0                 21.0     31.428571   \n",
       "109      2018.0        45.0         5.0                 34.0     30.316699   \n",
       "\n",
       "         timeFirstDecay  module_ca326  module_ca400  module_ca472  module_mcm  \\\n",
       "Student                                                                         \n",
       "4                   0.0           0.0           0.0           0.0         1.0   \n",
       "14                  0.0           0.0           0.0           0.0         1.0   \n",
       "66                176.0           0.0           0.0           0.0         1.0   \n",
       "79                143.0           0.0           0.0           0.0         1.0   \n",
       "109                 0.0           0.0           0.0           0.0         1.0   \n",
       "\n",
       "         module_pnu  worstProgress_moderate  worstProgress_satisfactory  \\\n",
       "Student                                                                   \n",
       "4               0.0                     0.0                         1.0   \n",
       "14              0.0                     0.0                         1.0   \n",
       "66              0.0                     0.0                         0.0   \n",
       "79              0.0                     0.0                         0.0   \n",
       "109             0.0                     0.0                         1.0   \n",
       "\n",
       "         worstProgress_unsatisfactory  mainSentiment_0.0  mainSentiment_1.0  \\\n",
       "Student                                                                       \n",
       "4                                 0.0                0.0                1.0   \n",
       "14                                0.0                0.0                0.0   \n",
       "66                                1.0                1.0                0.0   \n",
       "79                                1.0                0.0                1.0   \n",
       "109                               0.0                0.0                1.0   \n",
       "\n",
       "         mainSentiment_2.0  is0Sentiment_False  is0Sentiment_True  \n",
       "Student                                                            \n",
       "4                      0.0                 1.0                0.0  \n",
       "14                     1.0                 1.0                0.0  \n",
       "66                     0.0                 0.0                1.0  \n",
       "79                     0.0                 0.0                1.0  \n",
       "109                    0.0                 1.0                0.0  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_imp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a5014b7",
   "metadata": {},
   "source": [
    "## Split between train and test set\n",
    "\n",
    "documentation: https://www.malicksarr.com/split-train-test-validation-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2de279d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset between train set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_imp, y, test_size=0.2, shuffle = True, random_state = 2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "23e4d620",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#print(\"shape of X_train: {} | shape of y_train: {}\".format(X_train.shape,y_train.shape))\n",
    "#print(\"shape of X_test:  {} | shape of y_test:  {}\".format(X_test.shape,y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bd45439",
   "metadata": {},
   "source": [
    "## Standardisation\n",
    "\n",
    "The next step is a data standardisation step. The variables are divided by their standard deviation. This is not useful in the case of an elementary linear model because the solution is the same, but it is essential for many other non-linear methods (SVMs, neural networks, models with penalties). **Note:**, the same parameters (means, standard deviations) estimated on the training sample are used to normalise the test sample. \n",
    "\n",
    "\n",
    "*Exemple:* Standardization isn't always required for logistic regression. The main goal of standardizing features is to help convergence of the technique used for optimization. For example, if Newton-Raphson is used to maximize the likelihood, standardizing the features makes the convergence faster. Otherwise, we can run your logistic regression without any standardization treatment on the features. However, if we use Ridge or Lasso regression, we should standardize the data: \"The ridge solutions are not equivariant under scaling of the inputs, and so one normally standardizes the inputs before solving\".\\\n",
    "(source: https://stats.stackexchange.com/questions/48360/is-standardization-needed-before-fitting-logistic-regression)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7942875",
   "metadata": {},
   "source": [
    "<font color = 'blue'> **Modify this cell** </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7813a58e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardisation of explanatory variables\n",
    "#-----------------------------------------\n",
    "# store the indices which are the students' IDs\n",
    "StudentIDs_train = X_train.index\n",
    "StudentIDs_test = X_test.index\n",
    "# reset indices to make StandardScaler work\n",
    "X_train.reset_index(drop=True,inplace=True)\n",
    "X_test.reset_index(drop=True,inplace=True)\n",
    "# define scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# features to standardise\n",
    "# ====================================\n",
    "#features = [\"nbMeetings\",\"meanTimeBetweenMeet\",\"meanTimeMeet\",\"timeFirstDecay\"] #everything & without sentiment\n",
    "features = [\"nbMeetings\",\"meanTimeBetweenMeet\",\"meanTimeMeet\"] #without satisfactoriness\n",
    "# ====================================\n",
    "\n",
    "# standardise features\n",
    "scaler.fit(X_train[features]) #fit with the train set only\n",
    "X_train[features] = scaler.transform(X_train[features]) #apply the fit on the train set...\n",
    "X_test[features] = scaler.transform(X_test[features])   #...and on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5994195b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-assign indices to Students' IDs:\n",
    "#---------------------------------------\n",
    "X_train.index = StudentIDs_train #indices are now Student IDs\n",
    "X_test.index = StudentIDs_test #indices are now Student IDs\n",
    "\n",
    "# Assign correct type to data:\n",
    "#---------------------------------------\n",
    "X_train.index= X_train.index.astype(int)\n",
    "X_test.index= X_test.index.astype(int)\n",
    "\n",
    "l = [\"Year\",\"Supervisor\"]\n",
    "X_train[l]= X_train[l].astype(int)\n",
    "X_test[l]= X_test[l].astype(int)\n",
    "\n",
    "#Beware to keep \"nbMeetings\",\"meanTimeBetweenMeet\",\"meanTimeMeet\",\"timeFirstDecay\" to float \n",
    "#since they have been standardised."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "99a1a85a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define multinomial logistic regression model with L2 (Ridge) penalty\n",
    "#----------------------------------------------\n",
    "model_LR = LogisticRegression(multi_class='multinomial', solver='lbfgs', penalty='l2') \n",
    "\n",
    "# Note:\n",
    "# \"solver\": algorithm used in the optimization pb\n",
    "# \"penalty\": by default, python's LogisticRegression function applies a L2 (or Ridge) \n",
    "# regularisation to select the most important features (= explanatory variables)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b641e67d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the scoring method that will be used in the regression and CV\n",
    "#----------------------------------------------\n",
    "#Scoring = 'accuracy' #accuracy is the default score \n",
    "Scoring = 'f1_macro' #macroscopic f1-score (better than accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "887e0960",
   "metadata": {},
   "source": [
    "Which is better **lasso** or **ridge** regression? \n",
    "\n",
    "Source: https://www.datacamp.com/tutorial/tutorial-ridge-lasso-elastic-net \\\n",
    "Lasso tends to do well if there are a small number of significant parameters and the others are close to zero (ergo: when only a few predictors actually influence the response). Ridge works well if there are many large parameters of about the same value.\n",
    "\n",
    "Source: https://www.geeksforgeeks.org/lasso-vs-ridge-vs-elastic-net-ml/ \n",
    "- Limitation of Ridge Regression: Ridge regression decreases the complexity of a model but does not reduce the number of variables since it never leads to a coefficient been zero rather only minimizes it. Hence, this model is not good for feature reduction.\n",
    "\n",
    "\n",
    "- Limitation of Lasso Regression: Lasso sometimes struggles with some types of data. If the number of predictors (p) is greater than the number of observations (n), Lasso will pick at most n predictors as non-zero, even if all predictors are relevant (or may be used in the test set). If there are two or more highly collinear variables then LASSO regression select one of them randomly which is not good for the interpretation of data\n",
    "    \n",
    "Here, with **multinomial** logistic regression:\n",
    "- if we want **penality = 'l2'** (Ridge penality) one can use the solver is **'lbfgs'.**\n",
    "- if we want **penality = 'l1'** (Lasso penality) the only available solver is **'saga'.**\n",
    "\n",
    "doc: https://github.com/scikit-learn/scikit-learn/issues/8797"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d916cd50",
   "metadata": {},
   "source": [
    "### Without feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4f35f93",
   "metadata": {},
   "source": [
    "##### Tune Penalty for Multinomial Logistic Regression\n",
    "\n",
    "By default, python's LogisticRegression function applies a L2 (or Ridge) regularisation to emphasize the most important features (= explanatory variables). L2 regularisation does not perform features selection since it does not set the coefficients of least important variables to 0 but to almost 0.\n",
    "\n",
    "We will now optimize the penalty parameter C, which is used in the L2 (Ridge) regression. By defalut, C = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "372aae0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best f1_macro score = 0.139362, Best parameter = {'C': 0.55}\n"
     ]
    }
   ],
   "source": [
    "# Define grid of values for parameter C in L1 (Lasso) regression\n",
    "param=[{\"C\":np.arange(.5,2,.05)}] \n",
    "\n",
    "# Define and fit GridSearch to find best parameter\n",
    "GridSearch_LR = GridSearchCV(estimator=model_LR, param_grid=param ,cv=5,n_jobs=-1,scoring = Scoring)  #by defalut, the score is sklearn.metrics.accuracy_score, here we use the variable Scoring.\n",
    "LR_params = GridSearch_LR.fit(X_train, y_train)\n",
    "\n",
    "# Display optimal parameter\n",
    "print(\"Best \" + Scoring + \" score = %f, Best parameter = %s\" % (LR_params.best_score_,LR_params.best_params_))\n",
    "      #best_params_= parameter setting that gave the best results on the hold out data\n",
    "      #best_score_= mean cross-validated score of the best_estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "749617b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Redefine the multinomial logistic regression model with best parameter\n",
    "model_LR = LogisticRegression(multi_class='multinomial', solver='lbfgs', penalty='l2',C = LR_params.best_params_[\"C\"]) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b524ed1",
   "metadata": {},
   "source": [
    "#####  Cross-Validation Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d77c2669",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============= Model performance =============\n",
      "CV error: mean f1_macro=0.139 (std=0.024)\n",
      "=============================================\n"
     ]
    }
   ],
   "source": [
    "# Define the model evaluation procedure with CV\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=2022) #n_repeats=3 CV repeats with n_splits=10 folds\n",
    "\n",
    "# Evaluate the model and collect the scores\n",
    "n_scores_LR = cross_val_score(model_LR, X_train, y_train, scoring=Scoring, cv=cv, n_jobs=-1,error_score='raise')\n",
    "\n",
    "# Report the model performance\n",
    "print(\"============= Model performance =============\")\n",
    "print('CV error: mean ' + Scoring + '=%.3f (std=%.3f)' % (mean(n_scores_LR), std(n_scores_LR)))\n",
    "print(\"=============================================\")\n",
    "# this is the mean classification accuracy across all folds and repeats of the evaluation procedure."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e845e07b",
   "metadata": {},
   "source": [
    "### With feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2e7414a",
   "metadata": {},
   "source": [
    "For feature selection, there is no global agreement but it may be better to do in the following order:\n",
    "1) Select features: select the most important explanatory variables to obtain a reduced model\n",
    "\n",
    "2) Optimise hyperparameters on the reduced model\n",
    "\n",
    "documentation: https://stats.stackexchange.com/questions/264533/how-should-feature-selection-and-hyperparameter-optimization-be-ordered-in-the-m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92f6403b",
   "metadata": {},
   "source": [
    "#### Select feature with regularisation L1 (LASSO)\n",
    "\n",
    "L1 (or Lasso) regularisation to select the most important features (= explanatory variables) since it sets the coefficients of least important variables to 0. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ac18231e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define multinomial logistic regression model with L1 (Lasso) penalty \n",
    "# which carries out a feature selection\n",
    "#--------------------------------------------\n",
    "model_LR_lasso = LogisticRegression(multi_class='multinomial', solver='saga', penalty='l1') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b431146",
   "metadata": {},
   "source": [
    "##### Tune Penalty for Multinomial Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "25c3b5a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best f1_macro score = 0.135637, Best parameter = {'C': 1.8500000000000008}\n"
     ]
    }
   ],
   "source": [
    "# Define grid of values for parameter C in L1 (Lasso) regression\n",
    "param=[{\"C\":np.arange(0.1,2,.05)}]\n",
    "\n",
    "# Define and fit GridSearch\n",
    "GridSearch_LR_lasso = GridSearchCV(estimator=model_LR_lasso, param_grid=param ,cv=5,n_jobs=-1,scoring = Scoring)  #by defalut, the score is sklearn.metrics.accuracy_score, here we use the variable Scoring.\n",
    "LR_lasso_params = GridSearch_LR_lasso.fit(X_train, y_train)\n",
    "\n",
    "# Display optimal parameter\n",
    "print(\"Best \" + Scoring + \" score = %f, Best parameter = %s\" % (LR_lasso_params.best_score_,LR_lasso_params.best_params_))\n",
    "      #best_params_= parameter setting that gave the best results on the hold out data\n",
    "      #best_score_= mean cross-validated score of the best_estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "af4a78e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Redefine the multinomial logistic regression model with best parameters\n",
    "model_LR_lasso = LogisticRegression(multi_class='multinomial', solver='saga', penalty='l1',C = LR_lasso_params.best_params_[\"C\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c94407",
   "metadata": {},
   "source": [
    "##### Display selected features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b02c7e4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso regression keeps 12 explanatory variables out of 19 and removes 7 variables.\n",
      "\n",
      "Selected variables:\n",
      "Index(['Year', 'Supervisor', 'meanTimeBetweenMeet', 'timeFirstDecay',\n",
      "       'module_ca326', 'module_ca400', 'module_ca472',\n",
      "       'worstProgress_moderate', 'worstProgress_satisfactory',\n",
      "       'mainSentiment_1.0', 'is0Sentiment_False', 'is0Sentiment_True'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# \"GridSearch\" does not store the coefficients, they need to be re-estimated:\n",
    "Coef_lasso = model_LR_lasso.fit(X_train,y_train).coef_  #coef_: array of shape (n_classes, n_features) containing the coefficient of the features in the decision function\n",
    "Coef_lasso = pd.Series(Coef_lasso[0], index = X_train.columns)\n",
    "\n",
    "print(\"Lasso regression keeps {} explanatory variables out of {} and removes {} variables.\"\n",
    "      .format(sum(Coef_lasso != 0) , X_train.shape[1], sum(Coef_lasso == 0)))\n",
    "print()\n",
    "print(\"Selected variables:\")\n",
    "print(Coef_lasso.index[Coef_lasso!= 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "817118f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot of the selected features\n",
    "#-----------------------------------------\n",
    "f, ax = plt.subplots(figsize=(7,7))\n",
    "imp_coef = Coef_lasso.sort_values()\n",
    "imp_coef.plot(kind = \"barh\")\n",
    "plt.title(u\"Coefficient of Lasso model\\n\"\n",
    "          +\"The selected features are those for which the coefficients are non-zero\\n\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b4b10e0",
   "metadata": {},
   "source": [
    "The array \"coeff_\" contains the coefficients found for each input variable. These coefficients can provide the basis for a crude feature importance score. This assumes that the input variables have the same scale or have been scaled prior to fitting a model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a784195f",
   "metadata": {},
   "source": [
    "#####  Cross-Validation Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6ace8bb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============= Model performance =============\n",
      "CV error: mean f1_macro=0.129 (std=0.024)\n",
      "=============================================\n"
     ]
    }
   ],
   "source": [
    "# Define the model evaluation procedure with CV\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=2022) #n_repeats=3 CV repeats with n_splits=10 folds\n",
    "\n",
    "# Evaluate the model and collect the scores\n",
    "n_scores_lasso = cross_val_score(model_LR_lasso, X_train, y_train, scoring=Scoring, cv=cv, n_jobs=-1,error_score='raise')\n",
    "\n",
    "# Report the model performance\n",
    "print(\"============= Model performance =============\")\n",
    "print('CV error: mean ' + Scoring + '=%.3f (std=%.3f)' % (mean(n_scores_lasso), std(n_scores_lasso)))\n",
    "print(\"=============================================\")\n",
    "# this is the mean classification accuracy across all folds and repeats of the evaluation procedure."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bf16687",
   "metadata": {},
   "source": [
    "#### Select feature with RFE\n",
    "\n",
    "documentation:\n",
    "- https://scikit-learn.org/stable/modules/feature_selection.html\n",
    "\n",
    "- https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.RFE.html#sklearn.feature_selection.RFE\n",
    "\n",
    "- https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.RFECV.html\n",
    "\n",
    "tutorial: \n",
    "- https://machinelearningmastery.com/rfe-feature-selection-in-python/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e4b24e",
   "metadata": {},
   "source": [
    "RFE (`sklearn.feature_selection.RFE`) select features based on how they affect a particular models performance. RFE needs to be given the number of features to select.\n",
    "\n",
    "It is possible to automatically select the number of features chosen by RFE. This can be achieved by performing cross-validation evaluation of different numbers of features and automatically selecting the number of features that resulted in the best mean score. The RFECV class implements this for us.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "443622f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define multinomial logistic regression model with L2 (Ridge) penalty\n",
    "#----------------------------------------------\n",
    "model_LR_rfe = LogisticRegression(multi_class='multinomial', solver='lbfgs', penalty='none') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a87a72f4",
   "metadata": {},
   "source": [
    "##### Find and display selected features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d5d07ef9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_macro: 0.163 (0.044)\n"
     ]
    }
   ],
   "source": [
    "# Automatically Select the Number of Features using RFECV \n",
    "#----------------------------------------------\n",
    "# create pipeline\n",
    "rfe = RFECV(estimator=model_LR_rfe)\n",
    "model = model_LR_rfe\n",
    "pipeline = Pipeline(steps=[('s',rfe),('m',model)])\n",
    "# evaluate model\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "n_scores = cross_val_score(pipeline, X_train, y_train, scoring=Scoring, cv=cv, n_jobs=-1, error_score='raise')\n",
    "# report performance\n",
    "print(Scoring + ': %.3f (%.3f)' % (mean(n_scores), std(n_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "bd4b2999",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features in order of ranking:\n",
      "1 Year\n",
      "1 Supervisor\n",
      "1 nbMeetings\n",
      "1 timeFirstDecay\n",
      "2 meanTimeBetweenMeet\n",
      "3 meanTimeMeet\n",
      "4 module_mcm\n",
      "5 worstProgress_satisfactory\n",
      "6 mainSentiment_1.0\n",
      "7 module_ca400\n",
      "8 worstProgress_unsatisfactory\n",
      "9 module_pnu\n",
      "10 is0Sentiment_False\n",
      "11 worstProgress_moderate\n",
      "12 mainSentiment_0.0\n",
      "13 module_ca472\n",
      "14 module_ca326\n",
      "15 mainSentiment_2.0\n",
      "16 is0Sentiment_True\n",
      "-----------------------------------\n",
      "The selected 4 features are:\n",
      "['Year' 'Supervisor' 'nbMeetings' 'timeFirstDecay']\n"
     ]
    }
   ],
   "source": [
    "# Print out the  selected features in order of ranking\n",
    "#------------------------------------------\n",
    "rfe.fit(X_train, y_train)\n",
    "from operator import itemgetter\n",
    "features = np.array(X_train.columns.to_list())\n",
    "print(\"Features in order of ranking:\")\n",
    "for x, y in (sorted(zip(rfe.ranking_ , features), key=itemgetter(0))):\n",
    "    print(x, y)\n",
    "print(\"-----------------------------------\")\n",
    "print(\"The selected {} features are:\\n{}\".format(rfe.n_features_,features[rfe.support_]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5535f2c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Redefine X_train & X_test with only the selected features\n",
    "#------------------------------------------\n",
    "X_train_rfe = X_train[features[rfe.support_]]\n",
    "X_test_rfe = X_test[features[rfe.support_]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a97121a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_rfe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac1f8580",
   "metadata": {},
   "source": [
    "#####  Cross-Validation Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8256ce15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model evaluation procedure with CV\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=2022) #n_repeats=3 CV repeats with n_splits=10 folds\n",
    "\n",
    "# Evaluate the model and collect the scores\n",
    "n_scores_rfe = cross_val_score(model_LR_rfe, X_train_rfe, y_train, scoring=Scoring, cv=cv, n_jobs=-1,error_score='raise')\n",
    "\n",
    "# Report the model performance\n",
    "print(\"============= Model performance =============\")\n",
    "print('CV error: mean ' + Scoring + '=%.3f (std=%.3f)' % (mean(n_scores_rfe), std(n_scores_rfe)))\n",
    "print(\"=============================================\")\n",
    "# this is the mean classification accuracy across all folds and repeats of the evaluation procedure."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48341d85",
   "metadata": {},
   "source": [
    "## Neural Network\n",
    "\n",
    "There are several python libraries for neural networks (Scikit-learn,TensorFlow,PyTorch,Keras). We will use Scikit-learn, which is less powerful but simpler to implement.\n",
    "\n",
    "tutorial: https://michael-fuchs-python.netlify.app/2021/02/03/nn-multi-layer-perceptron-classifier-mlpclassifier/\n",
    "\n",
    "**How many hidden layers and neurons in that hidden layer?** \\\n",
    "For most problems, one could probably get decent performance (even without a second optimization step) by setting the hidden layer configuration using just two rules: \n",
    "\n",
    "**Rule 1**: The number of hidden layers = 1 or 2;\n",
    " \n",
    "- 0 - Only capable of representing linear separable functions or decisions.\n",
    "\n",
    "- 1 - Can approximate any function that contains a continuous mapping\n",
    "from one finite space to another.\n",
    "\n",
    "- 2 - Can represent an arbitrary decision boundary to arbitrary accuracy\n",
    "with rational activation functions and can approximate any smooth\n",
    "mapping to any accuracy.\n",
    "\n",
    "**Rule 2**: There are many rule-of-thumb methods for determining the correct number of neurons to use in the hidden layers, such as the following:\n",
    "\n",
    "- a. The number of hidden neurons should be between the size of the input layer and the size of the output layer.\n",
    "- b. The number of hidden neurons should be 2/3 the size of the input layer, plus the size of the output layer.\n",
    "- c. The number of hidden neurons should be less than twice the size of the input layer.\n",
    "- d. The number of hidden neurons should be the mean of the neurons in the input and output layers. \n",
    "\n",
    "And we have: \n",
    "- number of neurons in the input layer = number of features (columns) in our data = 19 \n",
    "- number of neurons in the output layer = 1 single neuron unless softmax is used in which case the output layer has one neuron per class label in our model. Apparently, with MLPClassifier method from Scikit-learn, the softmax function is already used.\n",
    "\n",
    "\n",
    "Therefore, we will use as a first guess **2 hidden layers** with **14 neurons** (rule 2.b) and **10 neurons** (rule 2.d). \n",
    "\n",
    "\n",
    "\n",
    "source: https://stats.stackexchange.com/questions/181/how-to-choose-the-number-of-hidden-layers-and-nodes-in-a-feedforward-neural-netw (very good explanation with references. Read all page)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e874804",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialisation of a first neural network \n",
    "#------------------------------------------\n",
    "model_nn = MLPClassifier(hidden_layer_sizes=(14,10),\n",
    "                        max_iter = 300,activation = 'relu',\n",
    "                        solver = 'adam')\n",
    "#hidden_layer_sizes: default value is (100,) which means 1 input layer, \n",
    "#1 hidden layer with 100 neurons and 1 output layer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef32fe4",
   "metadata": {},
   "source": [
    "### Without feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ae75731",
   "metadata": {},
   "source": [
    "##### Tune neural network parameters\n",
    "<font color = \"red\"> **Beware:** the cell below is long to run </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f9c363",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define grid of values for parameters the neural network\n",
    "# After several runs, the grid of values has been adapted to find the best parameters\n",
    "param = {\n",
    "    'hidden_layer_sizes': [(14,4),(14,6),(14,5),(16,5),(16,6)], \n",
    "    'alpha': np.arange(0.001,1,0.05),\n",
    "    'learning_rate': ['constant','adaptive'],\n",
    "}\n",
    "\n",
    "# Define and fit GridSearch\n",
    "GridSearch_nn = GridSearchCV(estimator=model_nn, param_grid=param,cv=5, n_jobs= -1,scoring = Scoring)\n",
    "params_nn = GridSearch_nn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a158c944",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display optimal parameter\n",
    "print(\"Best \" + Scoring + \" score = %f, Best parameters = %s\" % (params_nn.best_score_,params_nn.best_params_))\n",
    "    #best_params_= parameter setting that gave the best results on the hold out data\n",
    "    #best_score_= mean cross-validated score of the best_estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f9605a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Redefine the neural network with best parameters\n",
    "model_nn = MLPClassifier(hidden_layer_sizes= params_nn.best_params_[\"hidden_layer_sizes\"],\n",
    "                        alpha = params_nn.best_params_[\"alpha\"],\n",
    "                        learning_rate = params_nn.best_params_[\"learning_rate\"],\n",
    "                        max_iter = 300,activation = 'relu',\n",
    "                        solver = 'adam')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0e0a78d",
   "metadata": {},
   "source": [
    "#####  Cross-Validation Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6021d81a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model evaluation procedure with CV\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=2022) #n_repeats=3 CV repeats with n_splits=10 folds\n",
    "\n",
    "# Evaluate the model and collect the scores\n",
    "n_scores_nn = cross_val_score(model_nn, X_train, y_train, scoring=Scoring, cv=cv, n_jobs=-1,error_score='raise')\n",
    "\n",
    "# Report the model performance\n",
    "print(\"============= Model performance =============\")\n",
    "print('CV error: mean ' + Scoring + '=%.3f (std=%.3f)' % (mean(n_scores_nn), std(n_scores_nn)))\n",
    "print(\"=============================================\")\n",
    "# this is the mean classification accuracy across all folds and repeats of the evaluation procedure."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc8082ad",
   "metadata": {},
   "source": [
    "#### Select feature with SFS\n",
    "\n",
    "\n",
    "Since the neural network does not give specific attributes of importance such as `coef_` or `feature_importances_` we cannot use `RFE` (`sklearn.feature_selection.RFE`). Intead, we will use `SFS` (`sklearn.feature_selection.SequentialFeatureSelector`). SFS differs from RFE and SelectFromModel in that it does not require the underlying model to expose a coef_ or feature_importances_ attribute. It may however be slower considering that more models need to be evaluated, compared to the other approaches\n",
    "\n",
    "source:\n",
    "- https://scikit-learn.org/stable/modules/feature_selection.html\n",
    "- https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SequentialFeatureSelector.html#sklearn.feature_selection.SequentialFeatureSelector\n",
    "\n",
    "Unlike RFE using RFECV, there is no method to automatically determine the number of features. We will start with **10 features** here since **8 features** where previously selected in the case of logistic multinomial regression. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "668f0e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a new neural network \n",
    "#----------------------------------------------\n",
    "model_nn_sfs = MLPClassifier(hidden_layer_sizes=(14,10),\n",
    "                        max_iter = 300,activation = 'relu',\n",
    "                        solver = 'adam')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a83d40c",
   "metadata": {},
   "source": [
    "##### Find and display selected features\n",
    "<font color = \"red\"> **Beware:** the cell below is long to run </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12a04b82",
   "metadata": {},
   "source": [
    "<font color = 'blue'> **Modify this cell** </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ab67d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature selection with SFS\n",
    "#------------------------------------------\n",
    "sfs = SequentialFeatureSelector(estimator = model_nn_sfs, \n",
    "                                n_features_to_select=6,\n",
    "                                direction='backward',\n",
    "                               scoring = Scoring,\n",
    "                               cv=5,\n",
    "                               n_jobs=-1)\n",
    "sfs.fit(X_train, y_train) #Learn the features to select from X_train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a358b4db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print out the  selected features in order of ranking\n",
    "#------------------------------------------\n",
    "print(\"Features selected by the SFS method:\\n\")\n",
    "print(sfs.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28eb83bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Redefine X_train and X_test with only the selected features\n",
    "#------------------------------------------\n",
    "X_train_sfs = X_train[sfs.get_feature_names_out()]\n",
    "X_test_sfs = X_test[sfs.get_feature_names_out()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6033cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sfs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13be33a0",
   "metadata": {},
   "source": [
    "##### Tune neural network parameters\n",
    "<font color = \"red\"> **Beware:** the cell below is long to run </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0baf13dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define grid of values for parameters the neural network\n",
    "# After several runs, the grid of values has been adapted to find the best parameters\n",
    "param = {\n",
    "    'hidden_layer_sizes': [(14,4),(14,6),(16,6),(16,10),(16,14)], \n",
    "    'alpha': np.arange(0.001,1,0.05),\n",
    "    'learning_rate': ['constant','adaptive'],\n",
    "}\n",
    "\n",
    "# Define and fit GridSearch\n",
    "GridSearch_nn_sfs = GridSearchCV(estimator=model_nn_sfs, param_grid=param,cv=5, n_jobs= -1,scoring = Scoring)\n",
    "params_nn_sfs = GridSearch_nn_sfs.fit(X_train_sfs, y_train) #use only SELECTED FEATURES by sfs in X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b286f50b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Display optimal parameter\n",
    "print(\"Best \" + Scoring + \" score = %f, Best parameter = %s\" % (params_nn_sfs.best_score_,params_nn_sfs.best_params_))\n",
    "    #best_params_= parameter setting that gave the best results on the hold out data\n",
    "    #best_score_= mean cross-validated score of the best_estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f1185f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Redefine the neural network with best parameters\n",
    "model_nn_sfs = MLPClassifier(hidden_layer_sizes= params_nn_sfs.best_params_[\"hidden_layer_sizes\"],\n",
    "                        alpha = params_nn_sfs.best_params_[\"alpha\"],\n",
    "                        learning_rate = params_nn_sfs.best_params_[\"learning_rate\"],\n",
    "                        max_iter = 300,activation = 'relu',\n",
    "                        solver = 'adam')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5e6cdc6",
   "metadata": {},
   "source": [
    "#####  Cross-Validation Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e4a5011",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model evaluation procedure with CV\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=2022) #n_repeats=3 CV repeats with n_splits=10 folds\n",
    "\n",
    "# Evaluate the model and collect the scores\n",
    "n_scores_sfs = cross_val_score(model_nn_sfs, X_train_sfs, y_train, scoring=Scoring, cv=cv, n_jobs=-1,error_score='raise')\n",
    "\n",
    "\n",
    "# Report the model performance\n",
    "print(\"============= Model =============\")\n",
    "print('CV error: mean ' + Scoring + '=%.3f (std=%.3f)' % (mean(n_scores_sfs), std(n_scores_sfs)))\n",
    "print(\"=============================================\")\n",
    "# this is the mean classification accuracy across all folds and repeats of the evaluation procedure."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cea2456b",
   "metadata": {},
   "source": [
    "### Compute predictions on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c99bccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataFrame to store the results on the test set\n",
    "#---------------------------------------------------\n",
    "dfResult = pd.DataFrame(y_test)\n",
    "dfResult.rename(columns={\"Marks\": \"trueLabel\"},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a19c4f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multinomial Logistic Regression \n",
    "#---------------------------------------------------\n",
    "#----- Without feature selection\n",
    "model_LR.fit(X_train, y_train) #fit the model on the whole dataset\n",
    "pred_LR = model_LR.predict(X_test) #compute predictions on the test set\n",
    "dfResult[\"mlr\"] = pred_LR #add prediction to dataFrame\n",
    "\n",
    "#----- With feature selection using Lasso\n",
    "model_LR_lasso.fit(X_train,y_train) #fit the model on the whole dataset\n",
    "pred_LR_lasso= model_LR_lasso.predict(X_test) #compute predictions on the test set\n",
    "dfResult[\"mlr_lasso\"] = pred_LR_lasso #add prediction to dataFrame\n",
    "\n",
    "#----- With feature selection using RFE\n",
    "model_LR_rfe.fit(X_train_rfe,y_train) #fit the model on the selected features \n",
    "pred_LR_rfe= model_LR_rfe.predict(X_test_rfe) #compute predictions on the test set\n",
    "dfResult[\"mlr_rfe\"] = pred_LR_rfe #add prediction to dataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "507255dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural Network \n",
    "#---------------------------------------------------\n",
    "#----- Without feature selection\n",
    "model_nn.fit(X_train, y_train) #fit the model on the whole dataset\n",
    "pred_nn = model_nn.predict(X_test) #compute predictions on the test set\n",
    "dfResult[\"nn\"] = pred_nn #add prediction to dataFrame\n",
    "\n",
    "#----- With feature selection using SFS\n",
    "model_nn_sfs.fit(X_train_sfs,y_train) #fit the model on the selected features \n",
    "pred_nn_sfs= model_nn_sfs.predict(X_test_sfs) #compute predictions on the test set\n",
    "dfResult[\"nn_sfs\"] = pred_nn_sfs #add prediction to dataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "237b44da",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfResult.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a593007c",
   "metadata": {},
   "source": [
    "### Contigency Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dabc368b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Contigency Tables\")\n",
    "print()\n",
    "\n",
    "print(\"-------------------------------\")\n",
    "print(\"Multinomial Logistic Regression without feature selection\")\n",
    "print(\"-------------------------------\")\n",
    "print(pd.crosstab(index=dfResult[\"trueLabel\"], columns=dfResult[\"mlr\"]))\n",
    "print()\n",
    "\n",
    "print(\"-------------------------------\")\n",
    "print(\"Multinomial Logistic Regression feature selection with Lasso\")\n",
    "print(\"-------------------------------\")\n",
    "print(pd.crosstab(index=dfResult[\"trueLabel\"], columns=dfResult[\"mlr_lasso\"]))\n",
    "print()\n",
    "\n",
    "print(\"-------------------------------\")\n",
    "print(\"Multinomial Logistic Regression feature selection with RFE\")\n",
    "print(\"-------------------------------\")\n",
    "print(pd.crosstab(index=dfResult[\"trueLabel\"], columns=dfResult[\"mlr_rfe\"]))\n",
    "print()\n",
    "\n",
    "print(\"-------------------------------\")\n",
    "print(\"Neural Network without feature selection\")\n",
    "print(\"-------------------------------\")\n",
    "print(pd.crosstab(index=dfResult[\"trueLabel\"], columns=dfResult[\"nn\"]))\n",
    "print()\n",
    "\n",
    "print(\"-------------------------------\")\n",
    "print(\"Neural Network feature selection with SFS\")\n",
    "print(\"-------------------------------\")\n",
    "print(pd.crosstab(index=dfResult[\"trueLabel\"], columns=dfResult[\"nn_sfs\"]))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "921e536c",
   "metadata": {},
   "source": [
    "### F1-scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d36a8c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"F1-Scores\")\n",
    "print()\n",
    "\n",
    "print(\"-------------------------------\")\n",
    "print(\"Multinomial Logistic Regression without feature selection\")\n",
    "print(\"-------------------------------\")\n",
    "print(f1_score(dfResult[\"trueLabel\"], dfResult[\"mlr\"],average='macro'))\n",
    "print()\n",
    "\n",
    "print(\"-------------------------------\")\n",
    "print(\"Multinomial Logistic Regression feature selection with Lasso\")\n",
    "print(\"-------------------------------\")\n",
    "print(f1_score(dfResult[\"trueLabel\"], dfResult[\"mlr_lasso\"],average='macro'))\n",
    "print()\n",
    "\n",
    "print(\"-------------------------------\")\n",
    "print(\"Multinomial Logistic Regression feature selection with RFE\")\n",
    "print(\"-------------------------------\")\n",
    "print(f1_score(dfResult[\"trueLabel\"], dfResult[\"mlr_rfe\"],average='macro'))\n",
    "print()\n",
    "\n",
    "print(\"-------------------------------\")\n",
    "print(\"Neural Network without feature selection\")\n",
    "print(\"-------------------------------\")\n",
    "print(f1_score(dfResult[\"trueLabel\"], dfResult[\"nn\"],average='macro'))\n",
    "print()\n",
    "\n",
    "print(\"-------------------------------\")\n",
    "print(\"Neural Network feature selection with SFS\")\n",
    "print(\"-------------------------------\")\n",
    "print(f1_score(dfResult[\"trueLabel\"], dfResult[\"nn_sfs\"],average='macro'))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9207f80a",
   "metadata": {},
   "source": [
    "### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd9a8e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy\")\n",
    "print()\n",
    "\n",
    "print(\"-------------------------------\")\n",
    "print(\"Multinomial Logistic Regression without feature selection\")\n",
    "print(\"-------------------------------\")\n",
    "print(accuracy_score(dfResult[\"trueLabel\"], dfResult[\"mlr\"]))\n",
    "print()\n",
    "\n",
    "print(\"-------------------------------\")\n",
    "print(\"Multinomial Logistic Regression feature selection with Lasso\")\n",
    "print(\"-------------------------------\")\n",
    "print(accuracy_score(dfResult[\"trueLabel\"], dfResult[\"mlr_lasso\"]))\n",
    "print()\n",
    "\n",
    "print(\"-------------------------------\")\n",
    "print(\"Multinomial Logistic Regression feature selection with RFE\")\n",
    "print(\"-------------------------------\")\n",
    "print(accuracy_score(dfResult[\"trueLabel\"], dfResult[\"mlr_rfe\"]))\n",
    "print()\n",
    "\n",
    "print(\"-------------------------------\")\n",
    "print(\"Neural Network without feature selection\")\n",
    "print(\"-------------------------------\")\n",
    "print(accuracy_score(dfResult[\"trueLabel\"], dfResult[\"nn\"]))\n",
    "print()\n",
    "\n",
    "print(\"-------------------------------\")\n",
    "print(\"Neural Network feature selection with SFS\")\n",
    "print(\"-------------------------------\")\n",
    "print(accuracy_score(dfResult[\"trueLabel\"], dfResult[\"nn_sfs\"]))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85ada300",
   "metadata": {},
   "source": [
    "### Drafts and unfinished codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d2185f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore the number of features du select \n",
    "# Get a list of models to evaluate\n",
    "def get_models(model):\n",
    "    models = dict()\n",
    "    for i in range(2, 19):\n",
    "        rfe = RFE(estimator=model, n_features_to_select=i)\n",
    "        model = model\n",
    "        models[str(i)] = Pipeline(steps=[('s',rfe),('m',model)])\n",
    "    return models\n",
    " \n",
    "# Evaluate a give model using cross-validation\n",
    "def evaluate_model(model, X, y):\n",
    "    cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "    scores = cross_val_score(model, X, y, scoring=Scoring, cv=cv, n_jobs=-1, error_score='raise')\n",
    "    return scores\n",
    " \n",
    "# get the models to evaluate\n",
    "models = get_models(model_LR)\n",
    "# evaluate the models and store results\n",
    "results, names = list(), list()\n",
    "for name, model in models.items():\n",
    "    scores = evaluate_model(model, X_train, y_train)\n",
    "    results.append(scores)\n",
    "    names.append(name)\n",
    "    print(name + ' features -> CV error: mean ' + Scoring + '={} (std={})'\n",
    "          .format(round(mean(scores),3), round(std(scores),3)))\n",
    "\n",
    "# plot model performance for comparison\n",
    "#-----------------------------------------------------\n",
    "f, ax = plt.subplots(figsize=(15,7))\n",
    "ax.set_title(\"Bloxplot of the distribution of \" + Scoring +\" scores for each configured number of features\")\n",
    "ax.set_xlabel(\"number of features\")\n",
    "ax.set_ylabel(\"distribution of \" + Scoring +\" scores\")\n",
    "plt.boxplot(results, labels=names, showmeans=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b07b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform a scikit-learn Recursive Feature Elimination (RFE)\n",
    "#------------------------------------------\n",
    "RFE_selector = RFE(model_LR, n_features_to_select=6, step=1) #step=1: nb of features to remove at each iteration\n",
    "RFE_selector = RFE_selector.fit(X_train, y_train)\n",
    "#print(RFE_selector.support_)\n",
    "#print(RFE_selector.ranking_)\n",
    "\n",
    "\n",
    "# Now print out the features in order of ranking\n",
    "#------------------------------------------\n",
    "from operator import itemgetter\n",
    "features = np.array(X_train.columns.to_list())\n",
    "print(\"Features in order of ranking:\")\n",
    "for x, y in (sorted(zip(RFE_selector.ranking_ , features), key=itemgetter(0))):\n",
    "    print(x, y)\n",
    "print(\"-----------------------------------\")\n",
    "print(\"The selected {} features are:\\n{}\".format(RFE_selector.n_features_,features[RFE_selector.support_]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "287px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
